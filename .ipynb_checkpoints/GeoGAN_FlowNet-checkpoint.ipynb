{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, 'Not enough GPU hardware devices available'\n",
    "for physical_device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras import activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8 \n",
    "IMG_SIZE = (128,128,3)\n",
    "EPOCHS = 100\n",
    "NUMIMAGES = 1000\n",
    "BUFFER_SIZE = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_cls = 0.5\n",
    "lambda_flow = 1\n",
    "lambda_mask = 0.1\n",
    "lambda_landmark = 10\n",
    "lambda_reco = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SectionImageLoad import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AutoEncoderModel import *\n",
    "from STNFunction import *\n",
    "from GeoGAN_losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ax_filenames_ds,By_filenames_ds,landmark_dict = load_csvdata_weneed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Ax,Ax_landmark),(By,By_landmark) = get_raw_image(Ax_filenames_ds,By_filenames_ds,landmark_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmark_face(raw_img,raw_landmark):\n",
    "    img = np.clip((raw_img+1)/2,0,1)\n",
    "    X = np.clip((raw_landmark[:,0]+1)/2*128,0,128)\n",
    "    Y = np.clip((raw_landmark[:,1]+1)/2*128,0,128)\n",
    "    implot = plt.imshow(img)\n",
    "    plt.scatter(X,Y,c='r',s=5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ax = Ax[:NUMIMAGES]\n",
    "Ax_landmark = Ax_landmark[:NUMIMAGES]\n",
    "By = By[:NUMIMAGES]\n",
    "By_landmark = By_landmark[:NUMIMAGES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ax_ds = tf.data.Dataset.from_tensor_slices((Ax, Ax_landmark))\n",
    "Ax_ds = Ax_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "By_ds = tf.data.Dataset.from_tensor_slices((By, By_landmark))\n",
    "By_ds = By_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator_model(Model):\n",
    "    def __init__(self, img_size, batch_size, num_filter=32):\n",
    "        super(generator_model, self).__init__()\n",
    "        self.flowNet = autoencoder_model(num_filter,2,img_size,\"channels_last\",\"flowNet\")\n",
    "        self.grid_np = np.float32(np.mgrid[-1:1 + 1e-7 :2 / (img_size[0] - 1), -1:1 + 1e-7:2 / (img_size[1] - 1)])\n",
    "        self.grid_np = np.moveaxis(self.grid_np, [-2,-1], [0, 1])\n",
    "        self.flow_grid_np = tf.convert_to_tensor(\\\n",
    "                                tf.constant(np.stack([self.grid_np]*batch_size)),\n",
    "                                                dtype=tf.float32)\n",
    "        self.test_grid_np = tf.convert_to_tensor(tf.constant(self.grid_np), dtype=tf.float32)\n",
    "        \n",
    "        self.maskNet = autoencoder_model(num_filter,1,img_size,\"channels_last\",\"maskNet\")\n",
    "        self.refinementNet = autoencoder_model(num_filter,3,img_size,\"channels_last\",\"RefinementNet\")\n",
    "        # ------------\n",
    "        self.removeResidualNet = autoencoder_model(num_filter,3,img_size,\"channels_last\",\"RemovalNet\")\n",
    "        \n",
    "        self.removeconcat = Concatenate(axis=3)\n",
    "        self.flowconcat = Concatenate(axis=3)\n",
    "        self.maskconcat = Concatenate(axis=3)\n",
    "        self.refineconcat = Concatenate(axis=3)\n",
    "    def call(self, Ax, By, epoch, training=True):\n",
    "        # Ax_flow is zeros\n",
    "        fake_Ay, By_flow, raw_By_mask, By_warpped, By_mask, raw_fake_Ay, residual_Ay = self.addAttribute(Ax,By,epoch,training)\n",
    "        fake_Bx = self.removeAttribute(By,raw_By_mask,training)\n",
    "        \n",
    "        # fakeBx_flow is zeros\n",
    "        # (Testing)fake_Ay -> raw_Ay\n",
    "        fakeBx_to_By, fakeAy_flow, raw_fakeAx_mask, _, _, raw_fakeBx_to_By, _ = \\\n",
    "                    self.addAttribute(fake_Bx,fake_Ay,epoch,training)\n",
    "        fakeAy_to_Ax = self.removeAttribute(fake_Ay,raw_fakeAx_mask,training)\n",
    "        \n",
    "        return_items = {}\n",
    "        return_items['fake_Ay'] = fake_Ay\n",
    "        return_items['fakeAy_to_Ax'] = fakeAy_to_Ax\n",
    "        return_items['fakeBx_to_By'] = fakeBx_to_By\n",
    "        return_items['fake_Bx'] = fake_Bx\n",
    "        return_items['flows'] = [By_flow, fakeAy_flow]\n",
    "        return_items['masks'] = [raw_By_mask, raw_fakeAx_mask, By_mask]\n",
    "        return_items['raw_fake_Ay'] = raw_fake_Ay\n",
    "        return_items['By_warpped'] = By_warpped\n",
    "        return_items['residual_Ay'] = residual_Ay\n",
    "        \n",
    "        return return_items\n",
    "    # ----------------------------------------------------------\n",
    "    def addAttribute(self,Ax,By,epoch,training):\n",
    "        Ax_flow_front, By_flow_front, By_flow, By_warpped = self.callflowNet(Ax,By)\n",
    "        raw_Ay, By_mask = self.callmaskNet(Ax,By_warpped)\n",
    "        # make mask not to be warpped aka. converting to original one\n",
    "        return_By_mask = self.warp_flow(By_mask,-By_flow, training)\n",
    "        Ay, residual_Ay = self.callrefineNet(raw_Ay, By_mask, epoch)\n",
    "        return Ay, By_flow, return_By_mask, By_warpped, By_mask, raw_Ay, residual_Ay\n",
    "    \n",
    "    def removeAttribute(self,By,mask,training):\n",
    "        # mask_input = tf.stop_gradient(mask)\n",
    "        # rBy = self.removeResidualNet(self.removeconcat([By,mask_input]))\n",
    "        rBy = self.removeResidualNet(By)\n",
    "        Bx = tf.clip_by_value(By + tf.keras.activations.tanh(rBy) * (1-mask),-1,1)\n",
    "        # Bx = tf.clip_by_value(By + tf.keras.activations.tanh(rBy),-1,1)\n",
    "        return Bx\n",
    "    # ----------------------------------------------------------\n",
    "    def callflowNet(self, Ax, By, training=True):\n",
    "        Ax_front = self.flowNet.Encoder(Ax)\n",
    "        By_front = self.flowNet.Encoder(By)\n",
    "        fusion_BottleNeck = self.flowconcat([Ax_front, By_front])\n",
    "        By_flow = self.flowNet.Decoder(fusion_BottleNeck)\n",
    "        By_warpped = self.warp_flow(By, By_flow, training)\n",
    "        return Ax_front, By_front, By_flow, By_warpped\n",
    "    \n",
    "    def callmaskNet(self,Ax,By_warpped,training=True):\n",
    "        # maskNet\n",
    "        Ax_front = self.maskNet.Encoder(Ax)\n",
    "        By_warpped_front = self.maskNet.Encoder(By_warpped)\n",
    "        # Blend\n",
    "        bottleneck_fusion = self.maskconcat([Ax_front,By_warpped_front])\n",
    "        By_mask = self.maskNet.Decoder(bottleneck_fusion)\n",
    "        By_mask = Activation('sigmoid')(By_mask)\n",
    "        # By_mask = tf.clip_by_value(By_mask,0,1)\n",
    "        Ay = self.blend(By_mask,Ax,By_warpped)\n",
    "        return Ay, By_mask\n",
    "    def callrefineNet(self,Ay,By_mask,epoch):\n",
    "        # let raw_Ay not to be returned to flow sub-net \n",
    "        # because refinement sub-net isn't one of flow sub-net member\n",
    "        #mask_input = tf.stop_gradient(By_mask)\n",
    "        #residual_Ay = self.refinementNet(self.refineconcat([Ay, mask_input]))\n",
    "        residual_Ay = self.refinementNet(Ay)\n",
    "        residual_Ay = tf.keras.activations.tanh(residual_Ay) * 0.1\n",
    "        # refineWeight = tf.minimum(0.1,0.1*max(epoch-10,0))\n",
    "        # residual_Ay = 2 * tf.keras.activations.tanh(residual_Ay) * refineWeight * By_mask\n",
    "        Ay = tf.clip_by_value(Ay+residual_Ay,-1,1)\n",
    "        return Ay, residual_Ay\n",
    "    # ----------------------------------------------------------\n",
    "    def warp_flow(self, image, flow, training):\n",
    "        # flow_grid = self.flow_grid_np + flow\n",
    "        x_s = self.flow_grid_np[:, :, :, 1] + flow[:,:,:,0]\n",
    "        y_s = self.flow_grid_np[:, :, :, 0] + flow[:,:,:,1]\n",
    "        warp_image = self.bilinearSampler(image,x_s,y_s)\n",
    "        return warp_image\n",
    "    \n",
    "    def bilinearSampler(self,image,grid_x,grid_y):\n",
    "        return stn_bilinear_sampler(image,grid_x,grid_y)\n",
    "    # ----------------------------------------------------------\n",
    "    def blend(self,mask,a,b):\n",
    "        return mask*a+(1-mask)*b\n",
    "    # ----------------------------------------------------------\n",
    "    def save_weights(self.filepath):\n",
    "        self.flowNet.save_weights(filepath+'/flowNet.h5')\n",
    "        self.maskNet.save_weights(filepath+'/maskNet.h5')\n",
    "        self.refinementNet.save_weights(filepath+'/refinementNet.h5')\n",
    "        self.removeResidualNet.save_weights(filepath+'/removeResidualNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinglePatchDisc(Model):\n",
    "                #       n_layers,input_nc,        ndf,        nc\n",
    "    def __init__(self,num_layers,img_size,dis_filters,attributes):\n",
    "        super(SinglePatchDisc,self).__init__()\n",
    "        self.d_layers = []\n",
    "        self.d_layers.append(tf.keras.Sequential([ZeroPadding2D(1),\n",
    "                                           Conv2D(filters=dis_filters,kernel_size=3,strides=2,padding='valid',\n",
    "                                           input_shape=img_size),\n",
    "                                           LeakyReLU(alpha=0.2)]))\n",
    "        nf = dis_filters\n",
    "        for n in range(1,num_layers):\n",
    "            nf_prev = nf\n",
    "            nf = min(nf*2,512)\n",
    "            self.d_layers.append(tf.keras.Sequential([ZeroPadding2D(1),\n",
    "                                                      Conv2D(nf,kernel_size=3,strides=2,padding='valid'),\n",
    "                                                      BatchNormalization(),\n",
    "                                                      LeakyReLU(alpha=0.2)]))\n",
    "        nf_prev = nf\n",
    "        nf = min(nf*2,512)\n",
    "        self.dilate_layer = []\n",
    "        for dilate_rate in [2,4,6]:\n",
    "            self.dilate_layer.append(tf.keras.Sequential([ZeroPadding2D(dilate_rate),\n",
    "                                                     Conv2D(filters=nf,kernel_size=3,dilation_rate=dilate_rate,padding='valid')]))\n",
    "        self.dilate_concat = Conv2D(filters=nf,kernel_size=1)\n",
    "        self.disc_layer = tf.keras.Sequential([ZeroPadding2D(1),\n",
    "                                               Conv2D(filters=1,kernel_size=3,strides=1,padding='valid')])\n",
    "        self.attr_layer = tf.keras.Sequential([ZeroPadding2D(1),\n",
    "                                               Conv2D(filters=attributes,kernel_size=3,strides=1,padding='valid'),\n",
    "                                               Activation('sigmoid')])\n",
    "        self.dilateConcat = Concatenate(axis=3)\n",
    "    def call(self, img):\n",
    "        out = img\n",
    "        feat = []\n",
    "        for d_layer in self.d_layers:\n",
    "            out = d_layer(out)\n",
    "            feat.append(out)\n",
    "            # if self.dilated:\n",
    "        dilate_outs = []\n",
    "        for idx,_ in enumerate([2,4,6]):\n",
    "            layer = self.dilate_layer[idx](out)\n",
    "            dilate_outs.append(layer)\n",
    "        out = self.dilate_concat(self.dilateConcat([dilate_outs[0],dilate_outs[1],dilate_outs[2]]))\n",
    "        disc_out = self.disc_layer(out)\n",
    "        attr_out = self.attr_layer(out)\n",
    "        return feat,disc_out,attr_out\n",
    "class AttrbuteMultiscalePatchDisc(Model):\n",
    "    def __init__(self,num_scale=3,img_size=(128,128,3),num_layers=3,dis_filters=32,attributes=1):\n",
    "        super(AttrbuteMultiscalePatchDisc,self).__init__()\n",
    "        self.disc = []\n",
    "        self.num_scale = num_scale\n",
    "        for rank in range(num_scale):\n",
    "            self.disc.append(SinglePatchDisc(num_layers,img_size,dis_filters,attributes))\n",
    "        self.downsampled = tf.keras.Sequential([ZeroPadding2D(1),\n",
    "                                                AveragePooling2D(pool_size=3,strides=2,padding='valid')])\n",
    "    def call(self,inputs):\n",
    "        features, discrims = [],[]\n",
    "        attr_outs = []\n",
    "        image_downsampled = inputs\n",
    "        for i in range(self.num_scale):\n",
    "            # print(\"image_shape: {}\".format(image_downsampled.shape))\n",
    "            feat,out,attr_out = self.disc[i](image_downsampled)\n",
    "            features.append(feat)\n",
    "            discrims.append(out)\n",
    "            attr_outs.append(attr_out)\n",
    "            image_downsampled = self.downsampled(image_downsampled)\n",
    "        return features,discrims,attr_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del generator\n",
    "del discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = AttrbuteMultiscalePatchDisc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = generator_model(IMG_SIZE,BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_loss_func = flow_loss()\n",
    "lsgan_loss_func = lsgan_loss()\n",
    "g_LrDecay = tf.keras.optimizers.schedules.ExponentialDecay(0.002,decay_steps=3000,\n",
    "                                                          decay_rate=0.95,\n",
    "                                                          staircase=True)\n",
    "d_LrDecay = tf.keras.optimizers.schedules.ExponentialDecay(0.002,decay_steps=1800,\n",
    "                                                          decay_rate=0.95,\n",
    "                                                          staircase=True)\n",
    "generator_optimizer = tf.keras.optimizers.Adam(0.002)\n",
    "# flownet_opt = tf.keras.optimizers.Adam(0.002)\n",
    "# masknet_opt = tf.keras.optimizers.Adam(0.002)\n",
    "# refinet_opt = tf.keras.optimizers.Adam(0.002)\n",
    "# remonet_opt = tf.keras.optimizers.Adam(0.002)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(d_LrDecay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_flownet_step(Ax,By,landmark_Ax,landmark_By,epoch):\n",
    "    with tf.GradientTape() as flow_tape:\n",
    "        Ax_front, By_front, By_flow, By_warpped = generator.callflowNet(Ax,By,True)\n",
    "        G_flow_loss = flow_loss_func.totalVariation_loss(By_flow)\n",
    "        G_land_loss = flow_loss_func.landmark_loss(landmark_By,landmark_Ax,By_flow)\n",
    "        G_flow_loss = tf.cast(G_flow_loss,'float32')\n",
    "        G_land_loss = tf.cast(G_land_loss,'float32')\n",
    "        flow_loss = G_flow_loss+G_land_loss\n",
    "    gradients_of_flownet = flow_tape.gradient(flow_loss,generator.flowNet.trainable_variables)\n",
    "    flownet_opt.apply_gradients(zip(gradients_of_flownet, generator.flowNet.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(Ax,By,landmark_Ax,landmark_By,epoch):\n",
    "    with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
    "    # tf.GradientTape() as mask_tape, tf.GradientTape() as refi_tape,\\\n",
    "    # tf.GradientTape() as remo_tape, tf.GradientTape() as flow_tape:\n",
    "        g_items = generator(Ax,By,epoch,True)\n",
    "        # 1. TV_reg loss\n",
    "        G_flow_loss = 0.0\n",
    "        for flow in g_items['flows']:\n",
    "            G_flow_loss += flow_loss_func.totalVariation_loss(flow)\n",
    "        G_flow_loss = lambda_flow * tf.cast(G_flow_loss,'float32')\n",
    "        # 2. landmark loss (By_flow)\n",
    "        G_land_loss = flow_loss_func.landmark_loss(landmark_By,landmark_Ax,g_items['flows'][0])\n",
    "        G_land_loss += flow_loss_func.landmark_loss(landmark_Ax,landmark_By,g_items['flows'][1])\n",
    "        G_land_loss = lambda_landmark * tf.cast(G_land_loss,'float32')\n",
    "        # 3. recon loss\n",
    "            # 3-1. mask\n",
    "        G_mask_loss = 0.0\n",
    "        for mask in g_items['masks']:\n",
    "            G_mask_loss += recon_loss(mask,tf.zeros_like(mask))\n",
    "        G_mask_loss = lambda_mask * tf.cast(G_mask_loss,'float32')\n",
    "            # 3-2. add-removal recon\n",
    "        G_rcon_loss = recon_loss(By,g_items['fakeBx_to_By']) + recon_loss(Ax,g_items['fakeAy_to_Ax'])\n",
    "        G_rcon_loss = lambda_reco * tf.cast(G_rcon_loss,'float32')\n",
    "        #-------------------------------------------\n",
    "        \n",
    "        # 4. GAN loss\n",
    "        D_fake_loss = 0.0\n",
    "        D_real_loss = 0.0\n",
    "        GAN_loss = 0.0\n",
    "        G_cls_loss = 0.0\n",
    "        D_cls_loss = 0.0\n",
    "        # -- For Generator\n",
    "        for itemname in ['fake_Ay','fakeAy_to_Ax','fakeBx_to_By','fake_Bx']:\n",
    "            item = g_items[itemname]\n",
    "            _, pred, attr_pred = discriminator(item)\n",
    "            for pred_i in pred:\n",
    "                D_fake_loss += lsgan_loss_func.loss_func(pred_i, False)\n",
    "                GAN_loss += lsgan_loss_func.loss_func(pred_i, True)\n",
    "            \n",
    "            for attr in attr_pred:\n",
    "                if itemname in 'fake_Ay' or itemname in 'By':\n",
    "                    attr_label = tf.ones_like(attr)\n",
    "                else:\n",
    "                    attr_label = tf.zeros_like(attr)\n",
    "                G_cls_loss += lambda_cls * tf.cast(cls_loss(attr,attr_label),'float32')\n",
    "        D_fake_loss = 0.5 * D_fake_loss\n",
    "        # -- For Real Data\n",
    "        for (img,hasAttr) in [(Ax,False),(By,True)]:\n",
    "            _, pred, attr_pred = discriminator(img)\n",
    "            for pred_i in pred:\n",
    "                D_real_loss += lsgan_loss_func.loss_func(pred_i, True)\n",
    "            for attr in attr_pred:\n",
    "                if hasAttr:\n",
    "                    label = tf.ones_like(attr)\n",
    "                else:\n",
    "                    label = tf.zeros_like(attr)\n",
    "                D_cls_loss += lambda_cls * tf.cast(cls_loss(attr,label),'float32')\n",
    "        # -- CAST\n",
    "        D_fake_loss = tf.cast(D_fake_loss,'float32')\n",
    "        D_real_loss = tf.cast(D_real_loss,'float32')\n",
    "        GAN_loss = tf.cast(GAN_loss,'float32')\n",
    "        \n",
    "        DIS_loss = D_fake_loss+D_real_loss\n",
    "        flow_loss = G_flow_loss+G_land_loss\n",
    "        \n",
    "        G_loss = G_rcon_loss+G_cls_loss+GAN_loss+flow_loss\n",
    "        D_loss = DIS_loss+D_cls_loss\n",
    "    gradients_of_generator = g_tape.gradient(G_loss,generator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    \n",
    "    # gradients_of_flownet = flow_tape.gradient(flow_loss,generator.flowNet.trainable_variables)\n",
    "    # flownet_opt.apply_gradients(zip(gradients_of_flownet, generator.flowNet.trainable_variables))\n",
    "    # gradients_of_masknet = mask_tape.gradient(G_loss,generator.maskNet.trainable_variables)\n",
    "    # masknet_opt.apply_gradients(zip(gradients_of_masknet, generator.maskNet.trainable_variables))\n",
    "    # gradients_of_refinet = refi_tape.gradient(G_loss,generator.refinementNet.trainable_variables)\n",
    "    # refinet_opt.apply_gradients(zip(gradients_of_refinet, generator.refinementNet.trainable_variables))\n",
    "    # gradients_of_remonet = remo_tape.gradient(G_loss,generator.removeResidualNet.trainable_variables)\n",
    "    # remonet_opt.apply_gradients(zip(gradients_of_remonet, generator.removeResidualNet.trainable_variables))\n",
    "    \n",
    "    gradients_of_discriminator = d_tape.gradient(D_loss,discriminator.trainable_variables)\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator,discriminator.trainable_variables))\n",
    "    #print(\"flow_loss= {:.3f}, landmark_loss= {:.3f}, mask_loss= {:.3f}, recon_loss= {:.3f}, class_loss= {:.3f}, GAN_loss= {:.3f}\".\\\n",
    "    #     format(G_flow_loss,G_land_loss,G_mask_loss,G_rcon_loss,G_cls_loss,GAN_loss))\n",
    "    #print(\"D_fake_loss= {:.3f}, D_real_loss= {:.3f}, D_cls_loss= {:.3f}\".format(D_fake_loss,D_real_loss,D_cls_loss))\n",
    "    # print(\"G_loss= {:.4f}, D_loss= {:.4f}\".format(G_loss,D_loss))\n",
    "    return_items = {}\n",
    "    return_items[\"G_flow_loss\"] = G_flow_loss\n",
    "    return_items[\"G_land_loss\"] = G_land_loss\n",
    "    return_items[\"G_mask_loss\"] = G_mask_loss\n",
    "    return_items[\"G_rcon_loss\"] = G_rcon_loss\n",
    "    return_items[\"G_cls_loss\"] = G_cls_loss\n",
    "    return_items[\"GAN_loss\"] = GAN_loss\n",
    "    return_items[\"D_fake_loss\"] = D_fake_loss\n",
    "    return_items[\"D_real_loss\"] = D_real_loss\n",
    "    return_items[\"D_cls_loss\"] = D_cls_loss\n",
    "    return_items[\"G_loss\"] = G_loss\n",
    "    return_items[\"D_loss\"] = D_loss\n",
    "    return return_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(imgs,epoch,batch_size,filename):\n",
    "    fig = plt.figure(figsize=(batch_size,len(imgs))) \n",
    "    gs = matplotlib.gridspec.GridSpec(batch_size,len(imgs))#(batch_size, len(imgs))\n",
    "    # gs.update()\n",
    "    #, width_ratios=[1 for i in range(len(imgs))],\n",
    "    #     wspace=0.0, hspace=0.0, top=0.05, bottom=0.05, left=0.1, right=0.2)\n",
    "    for i in range(len(imgs)):\n",
    "        imgs[i] = np.clip((imgs[i]+1)/2,0,1)\n",
    "    for i in range(batch_size):\n",
    "        for j in range(len(imgs)):\n",
    "            ax = plt.subplot(gs[i,j])\n",
    "            ax.axis('off')\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_aspect('equal')\n",
    "            ax.imshow(imgs[j][i])\n",
    "    plt.savefig('{}_at_epoch_{}.png'.format(filename,epoch), bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(imgs,batch_size):\n",
    "    fig = plt.figure(figsize=(batch_size,len(imgs)))\n",
    "    gs = matplotlib.gridspec.GridSpec(batch_size,len(imgs))\n",
    "    for i in range(len(imgs)):\n",
    "        imgs[i] = np.clip((imgs[i]+1)/2,0,1)\n",
    "    for i in range(batch_size):\n",
    "        for j in range(len(imgs)):\n",
    "            ax = plt.subplot(gs[i,j])\n",
    "            ax.axis('off')\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_aspect('equal')\n",
    "            ax.imshow(imgs[j][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "    G_flow_loss: 1.9742\n",
      "    G_land_loss: 345.9036\n",
      "    G_mask_loss: 0.2293\n",
      "    G_rcon_loss: 2.8815\n",
      "    G_cls_loss: 44.6269\n",
      "    GAN_loss: 9.6046\n",
      "    D_fake_loss: 1.9395\n",
      "    D_real_loss: 2.5143\n",
      "    D_cls_loss: 22.1142\n",
      "    G_loss: 404.9907\n",
      "    D_loss: 26.5680\n",
      "epoch: 2\n",
      "    G_flow_loss: 0.3835\n",
      "    G_land_loss: 42.6416\n",
      "    G_mask_loss: 0.1943\n",
      "    G_rcon_loss: 2.9929\n",
      "    G_cls_loss: 34.3239\n",
      "    GAN_loss: 9.7497\n",
      "    D_fake_loss: 1.1601\n",
      "    D_real_loss: 0.9284\n",
      "    D_cls_loss: 20.3091\n",
      "    G_loss: 90.0915\n",
      "    D_loss: 22.3976\n",
      "epoch: 3\n",
      "    G_flow_loss: 0.3067\n",
      "    G_land_loss: 40.2006\n",
      "    G_mask_loss: 0.2159\n",
      "    G_rcon_loss: 2.5001\n",
      "    G_cls_loss: 43.7571\n",
      "    GAN_loss: 8.8297\n",
      "    D_fake_loss: 1.3748\n",
      "    D_real_loss: 1.2233\n",
      "    D_cls_loss: 16.8356\n",
      "    G_loss: 95.5942\n",
      "    D_loss: 19.4337\n",
      "epoch: 4\n",
      "    G_flow_loss: 0.7291\n",
      "    G_land_loss: 56.0551\n",
      "    G_mask_loss: 0.2004\n",
      "    G_rcon_loss: 2.9473\n",
      "    G_cls_loss: 36.9563\n",
      "    GAN_loss: 8.3168\n",
      "    D_fake_loss: 0.9762\n",
      "    D_real_loss: 0.6417\n",
      "    D_cls_loss: 14.9382\n",
      "    G_loss: 105.0046\n",
      "    D_loss: 16.5561\n",
      "epoch: 5\n",
      "    G_flow_loss: 1.8217\n",
      "    G_land_loss: 113.3920\n",
      "    G_mask_loss: 0.2135\n",
      "    G_rcon_loss: 2.4952\n",
      "    G_cls_loss: 32.0889\n",
      "    GAN_loss: 171.7243\n",
      "    D_fake_loss: 82.4579\n",
      "    D_real_loss: 67.5029\n",
      "    D_cls_loss: 14.1910\n",
      "    G_loss: 321.5221\n",
      "    D_loss: 164.1517\n",
      "epoch: 6\n",
      "    G_flow_loss: 9.6686\n",
      "    G_land_loss: 183.8074\n",
      "    G_mask_loss: 0.1378\n",
      "    G_rcon_loss: 4.0882\n",
      "    G_cls_loss: 30.4291\n",
      "    GAN_loss: 203.5924\n",
      "    D_fake_loss: 95.9359\n",
      "    D_real_loss: 111.2324\n",
      "    D_cls_loss: 13.3126\n",
      "    G_loss: 431.5858\n",
      "    D_loss: 220.4809\n",
      "epoch: 7\n",
      "    G_flow_loss: 1.6613\n",
      "    G_land_loss: 106.1212\n",
      "    G_mask_loss: 0.1238\n",
      "    G_rcon_loss: 4.1904\n",
      "    G_cls_loss: 24.3969\n",
      "    GAN_loss: 9.4490\n",
      "    D_fake_loss: 1.1689\n",
      "    D_real_loss: 0.7396\n",
      "    D_cls_loss: 12.8378\n",
      "    G_loss: 145.8188\n",
      "    D_loss: 14.7463\n",
      "epoch: 8\n",
      "    G_flow_loss: 1.0436\n",
      "    G_land_loss: 69.6005\n",
      "    G_mask_loss: 0.0988\n",
      "    G_rcon_loss: 4.3131\n",
      "    G_cls_loss: 23.0182\n",
      "    GAN_loss: 8.8691\n",
      "    D_fake_loss: 0.8792\n",
      "    D_real_loss: 0.5651\n",
      "    D_cls_loss: 12.8123\n",
      "    G_loss: 106.8445\n",
      "    D_loss: 14.2566\n",
      "epoch: 9\n",
      "    G_flow_loss: 0.8197\n",
      "    G_land_loss: 28.6868\n",
      "    G_mask_loss: 0.0858\n",
      "    G_rcon_loss: 4.2550\n",
      "    G_cls_loss: 25.4042\n",
      "    GAN_loss: 8.8789\n",
      "    D_fake_loss: 0.8782\n",
      "    D_real_loss: 0.5186\n",
      "    D_cls_loss: 12.3165\n",
      "    G_loss: 68.0446\n",
      "    D_loss: 13.7133\n",
      "epoch: 10\n",
      "    G_flow_loss: 0.6387\n",
      "    G_land_loss: 25.7148\n",
      "    G_mask_loss: 0.0867\n",
      "    G_rcon_loss: 4.2394\n",
      "    G_cls_loss: 24.3711\n",
      "    GAN_loss: 9.0757\n",
      "    D_fake_loss: 0.8494\n",
      "    D_real_loss: 0.4754\n",
      "    D_cls_loss: 12.4021\n",
      "    G_loss: 64.0398\n",
      "    D_loss: 13.7269\n",
      "epoch: 11\n",
      "    G_flow_loss: 1.9605\n",
      "    G_land_loss: 28.0537\n",
      "    G_mask_loss: 0.1017\n",
      "    G_rcon_loss: 3.9143\n",
      "    G_cls_loss: 18.3274\n",
      "    GAN_loss: 8.7917\n",
      "    D_fake_loss: 0.8354\n",
      "    D_real_loss: 0.5938\n",
      "    D_cls_loss: 11.8695\n",
      "    G_loss: 61.0475\n",
      "    D_loss: 13.2987\n",
      "epoch: 12\n",
      "    G_flow_loss: 1.6758\n",
      "    G_land_loss: 29.6166\n",
      "    G_mask_loss: 0.1033\n",
      "    G_rcon_loss: 3.2717\n",
      "    G_cls_loss: 10.6649\n",
      "    GAN_loss: 8.0147\n",
      "    D_fake_loss: 0.8141\n",
      "    D_real_loss: 0.7862\n",
      "    D_cls_loss: 11.6952\n",
      "    G_loss: 53.2438\n",
      "    D_loss: 13.2954\n",
      "epoch: 13\n",
      "    G_flow_loss: 12.1486\n",
      "    G_land_loss: 704.4862\n",
      "    G_mask_loss: 0.1214\n",
      "    G_rcon_loss: 3.4905\n",
      "    G_cls_loss: 17.1785\n",
      "    GAN_loss: 5199.0679\n",
      "    D_fake_loss: 2587.9290\n",
      "    D_real_loss: 421.6044\n",
      "    D_cls_loss: 13.3853\n",
      "    G_loss: 5936.3721\n",
      "    D_loss: 3022.9185\n",
      "epoch: 14\n",
      "    G_flow_loss: 10.6552\n",
      "    G_land_loss: 89.6514\n",
      "    G_mask_loss: 0.2320\n",
      "    G_rcon_loss: 2.9250\n",
      "    G_cls_loss: 33.9008\n",
      "    GAN_loss: 12.0788\n",
      "    D_fake_loss: 3.0026\n",
      "    D_real_loss: 1.6389\n",
      "    D_cls_loss: 16.4418\n",
      "    G_loss: 149.2113\n",
      "    D_loss: 21.0833\n",
      "epoch: 15\n",
      "    G_flow_loss: 4.2759\n",
      "    G_land_loss: 44.8472\n",
      "    G_mask_loss: 0.2418\n",
      "    G_rcon_loss: 2.5293\n",
      "    G_cls_loss: 33.6218\n",
      "    GAN_loss: 8.7082\n",
      "    D_fake_loss: 1.2781\n",
      "    D_real_loss: 0.7474\n",
      "    D_cls_loss: 16.2369\n",
      "    G_loss: 93.9825\n",
      "    D_loss: 18.2623\n",
      "epoch: 16\n",
      "    G_flow_loss: 2.9717\n",
      "    G_land_loss: 35.7856\n",
      "    G_mask_loss: 0.2429\n",
      "    G_rcon_loss: 2.4799\n",
      "    G_cls_loss: 33.4103\n",
      "    GAN_loss: 8.5677\n",
      "    D_fake_loss: 1.1565\n",
      "    D_real_loss: 0.7038\n",
      "    D_cls_loss: 16.1201\n",
      "    G_loss: 83.2151\n",
      "    D_loss: 17.9804\n",
      "epoch: 17\n",
      "    G_flow_loss: 2.2475\n",
      "    G_land_loss: 32.0208\n",
      "    G_mask_loss: 0.2404\n",
      "    G_rcon_loss: 2.4768\n",
      "    G_cls_loss: 28.9361\n",
      "    GAN_loss: 8.6946\n",
      "    D_fake_loss: 1.1089\n",
      "    D_real_loss: 0.7062\n",
      "    D_cls_loss: 15.6332\n",
      "    G_loss: 74.3759\n",
      "    D_loss: 17.4483\n",
      "epoch: 18\n",
      "    G_flow_loss: 1.7366\n",
      "    G_land_loss: 29.3118\n",
      "    G_mask_loss: 0.2376\n",
      "    G_rcon_loss: 2.5558\n",
      "    G_cls_loss: 30.6978\n",
      "    GAN_loss: 8.7108\n",
      "    D_fake_loss: 0.9929\n",
      "    D_real_loss: 0.6291\n",
      "    D_cls_loss: 15.5223\n",
      "    G_loss: 73.0127\n",
      "    D_loss: 17.1442\n",
      "epoch: 19\n",
      "    G_flow_loss: 1.6674\n",
      "    G_land_loss: 28.3528\n",
      "    G_mask_loss: 0.2342\n",
      "    G_rcon_loss: 2.5538\n",
      "    G_cls_loss: 29.6316\n",
      "    GAN_loss: 8.8273\n",
      "    D_fake_loss: 0.9999\n",
      "    D_real_loss: 0.6262\n",
      "    D_cls_loss: 15.3538\n",
      "    G_loss: 71.0329\n",
      "    D_loss: 16.9798\n",
      "epoch: 20\n",
      "    G_flow_loss: 1.2491\n",
      "    G_land_loss: 27.2272\n",
      "    G_mask_loss: 0.2309\n",
      "    G_rcon_loss: 2.6478\n",
      "    G_cls_loss: 26.1093\n",
      "    GAN_loss: 8.9023\n",
      "    D_fake_loss: 0.9720\n",
      "    D_real_loss: 0.6190\n",
      "    D_cls_loss: 15.1579\n",
      "    G_loss: 66.1357\n",
      "    D_loss: 16.7489\n",
      "epoch: 21\n",
      "    G_flow_loss: 1.5906\n",
      "    G_land_loss: 27.2582\n",
      "    G_mask_loss: 0.2246\n",
      "    G_rcon_loss: 2.7592\n",
      "    G_cls_loss: 24.9702\n",
      "    GAN_loss: 8.8962\n",
      "    D_fake_loss: 0.9719\n",
      "    D_real_loss: 0.6099\n",
      "    D_cls_loss: 15.1242\n",
      "    G_loss: 65.4744\n",
      "    D_loss: 16.7060\n",
      "epoch: 22\n",
      "    G_flow_loss: 1.2134\n",
      "    G_land_loss: 27.9973\n",
      "    G_mask_loss: 0.2211\n",
      "    G_rcon_loss: 2.8711\n",
      "    G_cls_loss: 24.8111\n",
      "    GAN_loss: 8.9316\n",
      "    D_fake_loss: 0.9012\n",
      "    D_real_loss: 0.5593\n",
      "    D_cls_loss: 14.8208\n",
      "    G_loss: 65.8245\n",
      "    D_loss: 16.2813\n",
      "epoch: 23\n",
      "    G_flow_loss: 1.5359\n",
      "    G_land_loss: 26.8144\n",
      "    G_mask_loss: 0.2244\n",
      "    G_rcon_loss: 2.7282\n",
      "    G_cls_loss: 24.0933\n",
      "    GAN_loss: 8.8780\n",
      "    D_fake_loss: 0.9021\n",
      "    D_real_loss: 0.5271\n",
      "    D_cls_loss: 14.7074\n",
      "    G_loss: 64.0497\n",
      "    D_loss: 16.1366\n",
      "epoch: 24\n",
      "    G_flow_loss: 0.9038\n",
      "    G_land_loss: 25.6117\n",
      "    G_mask_loss: 0.2226\n",
      "    G_rcon_loss: 2.7259\n",
      "    G_cls_loss: 25.1737\n",
      "    GAN_loss: 8.9761\n",
      "    D_fake_loss: 0.8836\n",
      "    D_real_loss: 0.5225\n",
      "    D_cls_loss: 15.7928\n",
      "    G_loss: 63.3913\n",
      "    D_loss: 17.1990\n",
      "epoch: 25\n",
      "    G_flow_loss: 0.9604\n",
      "    G_land_loss: 26.0550\n",
      "    G_mask_loss: 0.2219\n",
      "    G_rcon_loss: 2.8236\n",
      "    G_cls_loss: 23.4321\n",
      "    GAN_loss: 9.0032\n",
      "    D_fake_loss: 0.9185\n",
      "    D_real_loss: 0.5181\n",
      "    D_cls_loss: 15.2243\n",
      "    G_loss: 62.2744\n",
      "    D_loss: 16.6609\n",
      "epoch: 26\n",
      "    G_flow_loss: 1.0557\n",
      "    G_land_loss: 25.8033\n",
      "    G_mask_loss: 0.2227\n",
      "    G_rcon_loss: 2.7671\n",
      "    G_cls_loss: 19.6945\n",
      "    GAN_loss: 9.0230\n",
      "    D_fake_loss: 0.9224\n",
      "    D_real_loss: 0.5885\n",
      "    D_cls_loss: 14.7581\n",
      "    G_loss: 58.3435\n",
      "    D_loss: 16.2690\n",
      "epoch: 27\n",
      "    G_flow_loss: 0.9247\n",
      "    G_land_loss: 24.3872\n",
      "    G_mask_loss: 0.2216\n",
      "    G_rcon_loss: 2.7628\n",
      "    G_cls_loss: 19.4461\n",
      "    GAN_loss: 9.0213\n",
      "    D_fake_loss: 0.8694\n",
      "    D_real_loss: 0.5052\n",
      "    D_cls_loss: 14.4652\n",
      "    G_loss: 56.5421\n",
      "    D_loss: 15.8399\n",
      "epoch: 28\n",
      "    G_flow_loss: 0.7983\n",
      "    G_land_loss: 24.5582\n",
      "    G_mask_loss: 0.2222\n",
      "    G_rcon_loss: 2.7421\n",
      "    G_cls_loss: 18.6870\n",
      "    GAN_loss: 9.1369\n",
      "    D_fake_loss: 0.8727\n",
      "    D_real_loss: 0.4860\n",
      "    D_cls_loss: 14.3692\n",
      "    G_loss: 55.9225\n",
      "    D_loss: 15.7279\n",
      "epoch: 29\n",
      "    G_flow_loss: 0.7749\n",
      "    G_land_loss: 25.6437\n",
      "    G_mask_loss: 0.2212\n",
      "    G_rcon_loss: 2.7659\n",
      "    G_cls_loss: 17.7926\n",
      "    GAN_loss: 9.1534\n",
      "    D_fake_loss: 0.8106\n",
      "    D_real_loss: 0.4416\n",
      "    D_cls_loss: 14.3557\n",
      "    G_loss: 56.1306\n",
      "    D_loss: 15.6079\n",
      "epoch: 30\n",
      "    G_flow_loss: 2.0214\n",
      "    G_land_loss: 25.4889\n",
      "    G_mask_loss: 0.2217\n",
      "    G_rcon_loss: 2.7716\n",
      "    G_cls_loss: 18.0573\n",
      "    GAN_loss: 9.3542\n",
      "    D_fake_loss: 0.8451\n",
      "    D_real_loss: 0.5051\n",
      "    D_cls_loss: 14.2289\n",
      "    G_loss: 57.6934\n",
      "    D_loss: 15.5791\n",
      "epoch: 31\n",
      "    G_flow_loss: 0.6519\n",
      "    G_land_loss: 24.1694\n",
      "    G_mask_loss: 0.2239\n",
      "    G_rcon_loss: 2.7686\n",
      "    G_cls_loss: 16.9224\n",
      "    GAN_loss: 9.3329\n",
      "    D_fake_loss: 0.7733\n",
      "    D_real_loss: 0.4505\n",
      "    D_cls_loss: 13.9905\n",
      "    G_loss: 53.8451\n",
      "    D_loss: 15.2143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32\n",
      "    G_flow_loss: 1.0589\n",
      "    G_land_loss: 24.4716\n",
      "    G_mask_loss: 0.2222\n",
      "    G_rcon_loss: 2.8177\n",
      "    G_cls_loss: 17.6731\n",
      "    GAN_loss: 9.4688\n",
      "    D_fake_loss: 0.7867\n",
      "    D_real_loss: 0.4471\n",
      "    D_cls_loss: 14.1077\n",
      "    G_loss: 55.4901\n",
      "    D_loss: 15.3416\n",
      "epoch: 33\n",
      "    G_flow_loss: 1.5784\n",
      "    G_land_loss: 24.1189\n",
      "    G_mask_loss: 0.2245\n",
      "    G_rcon_loss: 2.7988\n",
      "    G_cls_loss: 15.2503\n",
      "    GAN_loss: 9.4835\n",
      "    D_fake_loss: 0.8039\n",
      "    D_real_loss: 0.4799\n",
      "    D_cls_loss: 14.2095\n",
      "    G_loss: 53.2298\n",
      "    D_loss: 15.4933\n",
      "epoch: 34\n",
      "    G_flow_loss: 0.8081\n",
      "    G_land_loss: 22.8716\n",
      "    G_mask_loss: 0.2263\n",
      "    G_rcon_loss: 2.6936\n",
      "    G_cls_loss: 13.9736\n",
      "    GAN_loss: 9.4966\n",
      "    D_fake_loss: 0.7430\n",
      "    D_real_loss: 0.4219\n",
      "    D_cls_loss: 13.7536\n",
      "    G_loss: 49.8435\n",
      "    D_loss: 14.9185\n",
      "epoch: 35\n",
      "    G_flow_loss: 0.7103\n",
      "    G_land_loss: 23.4128\n",
      "    G_mask_loss: 0.2275\n",
      "    G_rcon_loss: 2.6708\n",
      "    G_cls_loss: 14.4696\n",
      "    GAN_loss: 9.5380\n",
      "    D_fake_loss: 0.7487\n",
      "    D_real_loss: 0.4317\n",
      "    D_cls_loss: 13.6496\n",
      "    G_loss: 50.8016\n",
      "    D_loss: 14.8301\n",
      "epoch: 36\n",
      "    G_flow_loss: 0.9099\n",
      "    G_land_loss: 23.7652\n",
      "    G_mask_loss: 0.2302\n",
      "    G_rcon_loss: 2.6315\n",
      "    G_cls_loss: 14.9966\n",
      "    GAN_loss: 9.6659\n",
      "    D_fake_loss: 0.7236\n",
      "    D_real_loss: 0.4106\n",
      "    D_cls_loss: 13.7395\n",
      "    G_loss: 51.9692\n",
      "    D_loss: 14.8737\n",
      "epoch: 37\n",
      "    G_flow_loss: 1.0818\n",
      "    G_land_loss: 24.5102\n",
      "    G_mask_loss: 0.2279\n",
      "    G_rcon_loss: 2.6839\n",
      "    G_cls_loss: 14.8477\n",
      "    GAN_loss: 9.6638\n",
      "    D_fake_loss: 0.6781\n",
      "    D_real_loss: 0.3661\n",
      "    D_cls_loss: 13.7674\n",
      "    G_loss: 52.7875\n",
      "    D_loss: 14.8117\n",
      "epoch: 38\n",
      "    G_flow_loss: 0.8681\n",
      "    G_land_loss: 23.2569\n",
      "    G_mask_loss: 0.2285\n",
      "    G_rcon_loss: 2.6473\n",
      "    G_cls_loss: 15.4485\n",
      "    GAN_loss: 9.7632\n",
      "    D_fake_loss: 0.6736\n",
      "    D_real_loss: 0.3953\n",
      "    D_cls_loss: 13.7419\n",
      "    G_loss: 51.9840\n",
      "    D_loss: 14.8108\n",
      "epoch: 39\n",
      "    G_flow_loss: 1.0087\n",
      "    G_land_loss: 22.7655\n",
      "    G_mask_loss: 0.2278\n",
      "    G_rcon_loss: 2.6921\n",
      "    G_cls_loss: 15.6682\n",
      "    GAN_loss: 9.7328\n",
      "    D_fake_loss: 0.6761\n",
      "    D_real_loss: 0.3700\n",
      "    D_cls_loss: 13.2351\n",
      "    G_loss: 51.8673\n",
      "    D_loss: 14.2812\n",
      "epoch: 40\n",
      "    G_flow_loss: 0.5246\n",
      "    G_land_loss: 21.0136\n",
      "    G_mask_loss: 0.2274\n",
      "    G_rcon_loss: 2.6171\n",
      "    G_cls_loss: 15.0907\n",
      "    GAN_loss: 9.7173\n",
      "    D_fake_loss: 0.7237\n",
      "    D_real_loss: 0.3788\n",
      "    D_cls_loss: 13.1595\n",
      "    G_loss: 48.9633\n",
      "    D_loss: 14.2620\n",
      "epoch: 41\n",
      "    G_flow_loss: 0.8325\n",
      "    G_land_loss: 24.0450\n",
      "    G_mask_loss: 0.2233\n",
      "    G_rcon_loss: 2.8078\n",
      "    G_cls_loss: 16.5077\n",
      "    GAN_loss: 9.8009\n",
      "    D_fake_loss: 0.6601\n",
      "    D_real_loss: 0.3549\n",
      "    D_cls_loss: 13.2292\n",
      "    G_loss: 53.9939\n",
      "    D_loss: 14.2442\n",
      "epoch: 42\n",
      "    G_flow_loss: 0.9072\n",
      "    G_land_loss: 22.8107\n",
      "    G_mask_loss: 0.2237\n",
      "    G_rcon_loss: 2.7654\n",
      "    G_cls_loss: 14.1251\n",
      "    GAN_loss: 9.9830\n",
      "    D_fake_loss: 0.6207\n",
      "    D_real_loss: 0.3702\n",
      "    D_cls_loss: 12.9491\n",
      "    G_loss: 50.5914\n",
      "    D_loss: 13.9400\n",
      "epoch: 43\n",
      "    G_flow_loss: 0.5980\n",
      "    G_land_loss: 21.4417\n",
      "    G_mask_loss: 0.2239\n",
      "    G_rcon_loss: 2.7223\n",
      "    G_cls_loss: 13.7159\n",
      "    GAN_loss: 9.9061\n",
      "    D_fake_loss: 0.6630\n",
      "    D_real_loss: 0.3597\n",
      "    D_cls_loss: 13.1113\n",
      "    G_loss: 48.3841\n",
      "    D_loss: 14.1340\n",
      "epoch: 44\n",
      "    G_flow_loss: 0.6316\n",
      "    G_land_loss: 21.7708\n",
      "    G_mask_loss: 0.2218\n",
      "    G_rcon_loss: 2.7593\n",
      "    G_cls_loss: 13.5770\n",
      "    GAN_loss: 9.7479\n",
      "    D_fake_loss: 0.6615\n",
      "    D_real_loss: 0.3595\n",
      "    D_cls_loss: 12.5723\n",
      "    G_loss: 48.4866\n",
      "    D_loss: 13.5933\n",
      "epoch: 45\n",
      "    G_flow_loss: 0.8487\n",
      "    G_land_loss: 22.6996\n",
      "    G_mask_loss: 0.2183\n",
      "    G_rcon_loss: 2.8447\n",
      "    G_cls_loss: 13.9273\n",
      "    GAN_loss: 9.8395\n",
      "    D_fake_loss: 0.6836\n",
      "    D_real_loss: 0.3559\n",
      "    D_cls_loss: 12.3855\n",
      "    G_loss: 50.1599\n",
      "    D_loss: 13.4250\n",
      "epoch: 46\n",
      "    G_flow_loss: 0.9198\n",
      "    G_land_loss: 23.0767\n",
      "    G_mask_loss: 0.2180\n",
      "    G_rcon_loss: 2.8528\n",
      "    G_cls_loss: 13.8093\n",
      "    GAN_loss: 10.1002\n",
      "    D_fake_loss: 0.5688\n",
      "    D_real_loss: 0.3259\n",
      "    D_cls_loss: 12.1303\n",
      "    G_loss: 50.7587\n",
      "    D_loss: 13.0249\n",
      "epoch: 47\n",
      "    G_flow_loss: 0.9933\n",
      "    G_land_loss: 22.9224\n",
      "    G_mask_loss: 0.2254\n",
      "    G_rcon_loss: 2.7415\n",
      "    G_cls_loss: 12.6747\n",
      "    GAN_loss: 9.8496\n",
      "    D_fake_loss: 0.5878\n",
      "    D_real_loss: 0.3250\n",
      "    D_cls_loss: 11.6404\n",
      "    G_loss: 49.1815\n",
      "    D_loss: 12.5533\n",
      "epoch: 48\n",
      "    G_flow_loss: 0.8483\n",
      "    G_land_loss: 22.3535\n",
      "    G_mask_loss: 0.2293\n",
      "    G_rcon_loss: 2.5683\n",
      "    G_cls_loss: 12.3000\n",
      "    GAN_loss: 9.9265\n",
      "    D_fake_loss: 0.6372\n",
      "    D_real_loss: 0.3412\n",
      "    D_cls_loss: 11.7852\n",
      "    G_loss: 47.9967\n",
      "    D_loss: 12.7636\n",
      "epoch: 49\n",
      "    G_flow_loss: 0.7381\n",
      "    G_land_loss: 21.7538\n",
      "    G_mask_loss: 0.2288\n",
      "    G_rcon_loss: 2.5509\n",
      "    G_cls_loss: 11.3499\n",
      "    GAN_loss: 9.9590\n",
      "    D_fake_loss: 0.6066\n",
      "    D_real_loss: 0.3112\n",
      "    D_cls_loss: 11.4254\n",
      "    G_loss: 46.3517\n",
      "    D_loss: 12.3433\n",
      "epoch: 50\n",
      "    G_flow_loss: 1.7578\n",
      "    G_land_loss: 21.9250\n",
      "    G_mask_loss: 0.2289\n",
      "    G_rcon_loss: 2.5799\n",
      "    G_cls_loss: 12.2292\n",
      "    GAN_loss: 9.9638\n",
      "    D_fake_loss: 0.5828\n",
      "    D_real_loss: 0.3095\n",
      "    D_cls_loss: 11.0338\n",
      "    G_loss: 48.4557\n",
      "    D_loss: 11.9261\n",
      "epoch: 51\n",
      "    G_flow_loss: 4.2874\n",
      "    G_land_loss: 33.5192\n",
      "    G_mask_loss: 0.2039\n",
      "    G_rcon_loss: 2.9134\n",
      "    G_cls_loss: 16.6945\n",
      "    GAN_loss: 10.1409\n",
      "    D_fake_loss: 0.5809\n",
      "    D_real_loss: 0.2788\n",
      "    D_cls_loss: 10.9053\n",
      "    G_loss: 67.5554\n",
      "    D_loss: 11.7650\n",
      "epoch: 52\n",
      "    G_flow_loss: 1.3177\n",
      "    G_land_loss: 23.2140\n",
      "    G_mask_loss: 0.2143\n",
      "    G_rcon_loss: 2.6780\n",
      "    G_cls_loss: 13.4539\n",
      "    GAN_loss: 10.1556\n",
      "    D_fake_loss: 0.5402\n",
      "    D_real_loss: 0.2686\n",
      "    D_cls_loss: 11.0194\n",
      "    G_loss: 50.8193\n",
      "    D_loss: 11.8282\n",
      "epoch: 53\n",
      "    G_flow_loss: 0.9042\n",
      "    G_land_loss: 21.5590\n",
      "    G_mask_loss: 0.2207\n",
      "    G_rcon_loss: 2.6257\n",
      "    G_cls_loss: 12.9776\n",
      "    GAN_loss: 10.1312\n",
      "    D_fake_loss: 0.5103\n",
      "    D_real_loss: 0.2682\n",
      "    D_cls_loss: 10.6817\n",
      "    G_loss: 48.1977\n",
      "    D_loss: 11.4603\n",
      "epoch: 54\n",
      "    G_flow_loss: 1.2063\n",
      "    G_land_loss: 23.7872\n",
      "    G_mask_loss: 0.2179\n",
      "    G_rcon_loss: 2.6794\n",
      "    G_cls_loss: 12.6935\n",
      "    GAN_loss: 10.1555\n",
      "    D_fake_loss: 0.5527\n",
      "    D_real_loss: 0.2736\n",
      "    D_cls_loss: 10.7266\n",
      "    G_loss: 50.5219\n",
      "    D_loss: 11.5529\n",
      "epoch: 55\n",
      "    G_flow_loss: 0.4712\n",
      "    G_land_loss: 21.3198\n",
      "    G_mask_loss: 0.2297\n",
      "    G_rcon_loss: 2.4366\n",
      "    G_cls_loss: 12.6278\n",
      "    GAN_loss: 10.0526\n",
      "    D_fake_loss: 0.5678\n",
      "    D_real_loss: 0.2716\n",
      "    D_cls_loss: 10.6756\n",
      "    G_loss: 46.9080\n",
      "    D_loss: 11.5150\n",
      "epoch: 56\n",
      "    G_flow_loss: 0.4078\n",
      "    G_land_loss: 21.7049\n",
      "    G_mask_loss: 0.2315\n",
      "    G_rcon_loss: 2.3590\n",
      "    G_cls_loss: 12.2525\n",
      "    GAN_loss: 10.0420\n",
      "    D_fake_loss: 0.5590\n",
      "    D_real_loss: 0.2900\n",
      "    D_cls_loss: 10.6364\n",
      "    G_loss: 46.7662\n",
      "    D_loss: 11.4854\n",
      "epoch: 57\n",
      "    G_flow_loss: 0.4465\n",
      "    G_land_loss: 21.0432\n",
      "    G_mask_loss: 0.2197\n",
      "    G_rcon_loss: 2.6051\n",
      "    G_cls_loss: 11.2029\n",
      "    GAN_loss: 10.2166\n",
      "    D_fake_loss: 0.5173\n",
      "    D_real_loss: 0.2921\n",
      "    D_cls_loss: 10.9007\n",
      "    G_loss: 45.5145\n",
      "    D_loss: 11.7101\n",
      "epoch: 58\n",
      "    G_flow_loss: 0.5797\n",
      "    G_land_loss: 20.7138\n",
      "    G_mask_loss: 0.2286\n",
      "    G_rcon_loss: 2.4344\n",
      "    G_cls_loss: 11.2238\n",
      "    GAN_loss: 10.1180\n",
      "    D_fake_loss: 0.5184\n",
      "    D_real_loss: 0.2921\n",
      "    D_cls_loss: 10.8546\n",
      "    G_loss: 45.0698\n",
      "    D_loss: 11.6652\n",
      "epoch: 59\n",
      "    G_flow_loss: 1.6301\n",
      "    G_land_loss: 20.7738\n",
      "    G_mask_loss: 0.2265\n",
      "    G_rcon_loss: 2.4727\n",
      "    G_cls_loss: 11.3532\n",
      "    GAN_loss: 10.1118\n",
      "    D_fake_loss: 0.5773\n",
      "    D_real_loss: 0.3225\n",
      "    D_cls_loss: 10.4334\n",
      "    G_loss: 46.3417\n",
      "    D_loss: 11.3333\n",
      "epoch: 60\n",
      "    G_flow_loss: 0.5700\n",
      "    G_land_loss: 20.8996\n",
      "    G_mask_loss: 0.2222\n",
      "    G_rcon_loss: 2.5224\n",
      "    G_cls_loss: 11.6191\n",
      "    GAN_loss: 10.1694\n",
      "    D_fake_loss: 0.5185\n",
      "    D_real_loss: 0.2930\n",
      "    D_cls_loss: 10.6203\n",
      "    G_loss: 45.7806\n",
      "    D_loss: 11.4318\n",
      "epoch: 61\n",
      "    G_flow_loss: 1.0063\n",
      "    G_land_loss: 21.4092\n",
      "    G_mask_loss: 0.2173\n",
      "    G_rcon_loss: 2.6446\n",
      "    G_cls_loss: 9.3436\n",
      "    GAN_loss: 10.3738\n",
      "    D_fake_loss: 0.5009\n",
      "    D_real_loss: 0.2635\n",
      "    D_cls_loss: 10.1356\n",
      "    G_loss: 44.7774\n",
      "    D_loss: 10.9000\n",
      "epoch: 62\n",
      "    G_flow_loss: 1.1079\n",
      "    G_land_loss: 20.4941\n",
      "    G_mask_loss: 0.2096\n",
      "    G_rcon_loss: 2.7479\n",
      "    G_cls_loss: 12.5493\n",
      "    GAN_loss: 10.2776\n",
      "    D_fake_loss: 0.4485\n",
      "    D_real_loss: 0.2458\n",
      "    D_cls_loss: 10.1211\n",
      "    G_loss: 47.1767\n",
      "    D_loss: 10.8154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 63\n",
      "    G_flow_loss: 1.1248\n",
      "    G_land_loss: 20.6343\n",
      "    G_mask_loss: 0.2120\n",
      "    G_rcon_loss: 2.7536\n",
      "    G_cls_loss: 9.8256\n",
      "    GAN_loss: 10.4136\n",
      "    D_fake_loss: 0.4328\n",
      "    D_real_loss: 0.2523\n",
      "    D_cls_loss: 10.1754\n",
      "    G_loss: 44.7520\n",
      "    D_loss: 10.8604\n",
      "epoch: 64\n",
      "    G_flow_loss: 0.9194\n",
      "    G_land_loss: 20.2353\n",
      "    G_mask_loss: 0.2163\n",
      "    G_rcon_loss: 2.6666\n",
      "    G_cls_loss: 10.1591\n",
      "    GAN_loss: 10.4647\n",
      "    D_fake_loss: 0.4264\n",
      "    D_real_loss: 0.2432\n",
      "    D_cls_loss: 10.0598\n",
      "    G_loss: 44.4451\n",
      "    D_loss: 10.7294\n",
      "epoch: 65\n",
      "    G_flow_loss: 1.8186\n",
      "    G_land_loss: 20.8036\n",
      "    G_mask_loss: 0.2134\n",
      "    G_rcon_loss: 2.7146\n",
      "    G_cls_loss: 13.2097\n",
      "    GAN_loss: 10.4017\n",
      "    D_fake_loss: 0.4928\n",
      "    D_real_loss: 0.2788\n",
      "    D_cls_loss: 10.0438\n",
      "    G_loss: 48.9481\n",
      "    D_loss: 10.8153\n",
      "epoch: 66\n",
      "    G_flow_loss: 1.1323\n",
      "    G_land_loss: 21.2846\n",
      "    G_mask_loss: 0.2022\n",
      "    G_rcon_loss: 2.8932\n",
      "    G_cls_loss: 11.4807\n",
      "    GAN_loss: 10.4255\n",
      "    D_fake_loss: 0.4636\n",
      "    D_real_loss: 0.2605\n",
      "    D_cls_loss: 9.8810\n",
      "    G_loss: 47.2162\n",
      "    D_loss: 10.6051\n",
      "epoch: 67\n",
      "    G_flow_loss: 1.2626\n",
      "    G_land_loss: 20.8865\n",
      "    G_mask_loss: 0.2132\n",
      "    G_rcon_loss: 2.7238\n",
      "    G_cls_loss: 14.0855\n",
      "    GAN_loss: 10.3847\n",
      "    D_fake_loss: 0.4419\n",
      "    D_real_loss: 0.2524\n",
      "    D_cls_loss: 9.7617\n",
      "    G_loss: 49.3431\n",
      "    D_loss: 10.4560\n",
      "epoch: 68\n",
      "    G_flow_loss: 0.7594\n",
      "    G_land_loss: 20.8327\n",
      "    G_mask_loss: 0.2202\n",
      "    G_rcon_loss: 2.6282\n",
      "    G_cls_loss: 14.9624\n",
      "    GAN_loss: 10.3946\n",
      "    D_fake_loss: 0.4644\n",
      "    D_real_loss: 0.2485\n",
      "    D_cls_loss: 9.8256\n",
      "    G_loss: 49.5775\n",
      "    D_loss: 10.5385\n",
      "epoch: 69\n",
      "    G_flow_loss: 1.5529\n",
      "    G_land_loss: 20.6727\n",
      "    G_mask_loss: 0.2148\n",
      "    G_rcon_loss: 2.6711\n",
      "    G_cls_loss: 14.1598\n",
      "    GAN_loss: 10.5523\n",
      "    D_fake_loss: 0.4270\n",
      "    D_real_loss: 0.2350\n",
      "    D_cls_loss: 9.6375\n",
      "    G_loss: 49.6087\n",
      "    D_loss: 10.2994\n",
      "epoch: 70\n",
      "    G_flow_loss: 1.0910\n",
      "    G_land_loss: 20.7514\n",
      "    G_mask_loss: 0.2103\n",
      "    G_rcon_loss: 2.7823\n",
      "    G_cls_loss: 11.3245\n",
      "    GAN_loss: 10.4521\n",
      "    D_fake_loss: 0.4214\n",
      "    D_real_loss: 0.2544\n",
      "    D_cls_loss: 9.5594\n",
      "    G_loss: 46.4013\n",
      "    D_loss: 10.2352\n",
      "epoch: 71\n",
      "    G_flow_loss: 0.8352\n",
      "    G_land_loss: 20.3007\n",
      "    G_mask_loss: 0.2161\n",
      "    G_rcon_loss: 2.6093\n",
      "    G_cls_loss: 11.2962\n",
      "    GAN_loss: 10.4945\n",
      "    D_fake_loss: 0.4462\n",
      "    D_real_loss: 0.2645\n",
      "    D_cls_loss: 9.6930\n",
      "    G_loss: 45.5360\n",
      "    D_loss: 10.4037\n",
      "epoch: 72\n",
      "    G_flow_loss: 1.1073\n",
      "    G_land_loss: 20.2870\n",
      "    G_mask_loss: 0.2163\n",
      "    G_rcon_loss: 2.6460\n",
      "    G_cls_loss: 12.4102\n",
      "    GAN_loss: 10.4551\n",
      "    D_fake_loss: 0.4571\n",
      "    D_real_loss: 0.2775\n",
      "    D_cls_loss: 9.7818\n",
      "    G_loss: 46.9055\n",
      "    D_loss: 10.5163\n",
      "epoch: 73\n",
      "    G_flow_loss: 1.1647\n",
      "    G_land_loss: 20.2318\n",
      "    G_mask_loss: 0.2204\n",
      "    G_rcon_loss: 2.5724\n",
      "    G_cls_loss: 13.5897\n",
      "    GAN_loss: 10.5429\n",
      "    D_fake_loss: 0.4716\n",
      "    D_real_loss: 0.2755\n",
      "    D_cls_loss: 9.5946\n",
      "    G_loss: 48.1015\n",
      "    D_loss: 10.3416\n",
      "epoch: 74\n",
      "    G_flow_loss: 3.1638\n",
      "    G_land_loss: 20.5747\n",
      "    G_mask_loss: 0.2158\n",
      "    G_rcon_loss: 2.6657\n",
      "    G_cls_loss: 13.2796\n",
      "    GAN_loss: 10.4706\n",
      "    D_fake_loss: 0.3981\n",
      "    D_real_loss: 0.2482\n",
      "    D_cls_loss: 9.3484\n",
      "    G_loss: 50.1544\n",
      "    D_loss: 9.9947\n",
      "epoch: 75\n",
      "    G_flow_loss: 0.7910\n",
      "    G_land_loss: 20.4959\n",
      "    G_mask_loss: 0.2239\n",
      "    G_rcon_loss: 2.4973\n",
      "    G_cls_loss: 12.1464\n",
      "    GAN_loss: 10.4649\n",
      "    D_fake_loss: 0.4449\n",
      "    D_real_loss: 0.2811\n",
      "    D_cls_loss: 9.3715\n",
      "    G_loss: 46.3954\n",
      "    D_loss: 10.0974\n",
      "epoch: 76\n",
      "    G_flow_loss: 0.3579\n",
      "    G_land_loss: 20.3154\n",
      "    G_mask_loss: 0.2306\n",
      "    G_rcon_loss: 2.3464\n",
      "    G_cls_loss: 11.5933\n",
      "    GAN_loss: 10.3481\n",
      "    D_fake_loss: 0.4608\n",
      "    D_real_loss: 0.2740\n",
      "    D_cls_loss: 9.2560\n",
      "    G_loss: 44.9612\n",
      "    D_loss: 9.9908\n",
      "epoch: 77\n",
      "    G_flow_loss: 0.6488\n",
      "    G_land_loss: 20.3906\n",
      "    G_mask_loss: 0.2296\n",
      "    G_rcon_loss: 2.3575\n",
      "    G_cls_loss: 12.2189\n",
      "    GAN_loss: 10.4324\n",
      "    D_fake_loss: 0.4758\n",
      "    D_real_loss: 0.2989\n",
      "    D_cls_loss: 9.0549\n",
      "    G_loss: 46.0482\n",
      "    D_loss: 9.8296\n",
      "epoch: 78\n",
      "    G_flow_loss: 0.6806\n",
      "    G_land_loss: 20.8675\n",
      "    G_mask_loss: 0.2396\n",
      "    G_rcon_loss: 2.1539\n",
      "    G_cls_loss: 13.5605\n",
      "    GAN_loss: 10.3977\n",
      "    D_fake_loss: 0.4515\n",
      "    D_real_loss: 0.2928\n",
      "    D_cls_loss: 8.9731\n",
      "    G_loss: 47.6603\n",
      "    D_loss: 9.7174\n",
      "epoch: 79\n",
      "    G_flow_loss: 0.4486\n",
      "    G_land_loss: 20.6178\n",
      "    G_mask_loss: 0.2407\n",
      "    G_rcon_loss: 2.0948\n",
      "    G_cls_loss: 12.7034\n",
      "    GAN_loss: 10.2927\n",
      "    D_fake_loss: 0.4953\n",
      "    D_real_loss: 0.2962\n",
      "    D_cls_loss: 9.1987\n",
      "    G_loss: 46.1573\n",
      "    D_loss: 9.9902\n",
      "epoch: 80\n",
      "    G_flow_loss: 0.4654\n",
      "    G_land_loss: 20.3355\n",
      "    G_mask_loss: 0.2414\n",
      "    G_rcon_loss: 2.0655\n",
      "    G_cls_loss: 11.3656\n",
      "    GAN_loss: 10.2673\n",
      "    D_fake_loss: 0.4754\n",
      "    D_real_loss: 0.2736\n",
      "    D_cls_loss: 8.7622\n",
      "    G_loss: 44.4993\n",
      "    D_loss: 9.5112\n",
      "epoch: 81\n",
      "    G_flow_loss: 0.6638\n",
      "    G_land_loss: 20.0841\n",
      "    G_mask_loss: 0.2404\n",
      "    G_rcon_loss: 2.0824\n",
      "    G_cls_loss: 12.3262\n",
      "    GAN_loss: 10.4270\n",
      "    D_fake_loss: 0.4277\n",
      "    D_real_loss: 0.2512\n",
      "    D_cls_loss: 8.8859\n",
      "    G_loss: 45.5834\n",
      "    D_loss: 9.5648\n",
      "epoch: 82\n",
      "    G_flow_loss: 0.4839\n",
      "    G_land_loss: 20.7980\n",
      "    G_mask_loss: 0.2440\n",
      "    G_rcon_loss: 2.0087\n",
      "    G_cls_loss: 12.2892\n",
      "    GAN_loss: 10.3521\n",
      "    D_fake_loss: 0.4614\n",
      "    D_real_loss: 0.2866\n",
      "    D_cls_loss: 8.9292\n",
      "    G_loss: 45.9319\n",
      "    D_loss: 9.6772\n",
      "epoch: 83\n",
      "    G_flow_loss: 0.2764\n",
      "    G_land_loss: 20.3858\n",
      "    G_mask_loss: 0.2390\n",
      "    G_rcon_loss: 2.1098\n",
      "    G_cls_loss: 11.9650\n",
      "    GAN_loss: 10.5052\n",
      "    D_fake_loss: 0.5011\n",
      "    D_real_loss: 0.2881\n",
      "    D_cls_loss: 8.8977\n",
      "    G_loss: 45.2422\n",
      "    D_loss: 9.6869\n",
      "epoch: 84\n",
      "    G_flow_loss: 0.5848\n",
      "    G_land_loss: 21.2853\n",
      "    G_mask_loss: 0.2354\n",
      "    G_rcon_loss: 2.1912\n",
      "    G_cls_loss: 11.2227\n",
      "    GAN_loss: 10.5213\n",
      "    D_fake_loss: 0.4122\n",
      "    D_real_loss: 0.2332\n",
      "    D_cls_loss: 8.4214\n",
      "    G_loss: 45.8053\n",
      "    D_loss: 9.0668\n",
      "epoch: 85\n",
      "    G_flow_loss: 0.4030\n",
      "    G_land_loss: 20.8023\n",
      "    G_mask_loss: 0.2413\n",
      "    G_rcon_loss: 2.0817\n",
      "    G_cls_loss: 12.6563\n",
      "    GAN_loss: 10.4753\n",
      "    D_fake_loss: 0.4482\n",
      "    D_real_loss: 0.2792\n",
      "    D_cls_loss: 8.6264\n",
      "    G_loss: 46.4187\n",
      "    D_loss: 9.3538\n",
      "epoch: 86\n",
      "    G_flow_loss: 0.6259\n",
      "    G_land_loss: 20.7337\n",
      "    G_mask_loss: 0.2349\n",
      "    G_rcon_loss: 2.1989\n",
      "    G_cls_loss: 13.7402\n",
      "    GAN_loss: 10.5991\n",
      "    D_fake_loss: 0.4162\n",
      "    D_real_loss: 0.2621\n",
      "    D_cls_loss: 8.3792\n",
      "    G_loss: 47.8977\n",
      "    D_loss: 9.0576\n",
      "epoch: 87\n",
      "    G_flow_loss: 0.4504\n",
      "    G_land_loss: 20.5739\n",
      "    G_mask_loss: 0.2390\n",
      "    G_rcon_loss: 2.1272\n",
      "    G_cls_loss: 10.5623\n",
      "    GAN_loss: 10.6706\n",
      "    D_fake_loss: 0.3760\n",
      "    D_real_loss: 0.2229\n",
      "    D_cls_loss: 8.3816\n",
      "    G_loss: 44.3843\n",
      "    D_loss: 8.9805\n",
      "epoch: 88\n",
      "    G_flow_loss: 1.0266\n",
      "    G_land_loss: 20.5091\n",
      "    G_mask_loss: 0.2402\n",
      "    G_rcon_loss: 2.1063\n",
      "    G_cls_loss: 10.4865\n",
      "    GAN_loss: 10.6095\n",
      "    D_fake_loss: 0.3886\n",
      "    D_real_loss: 0.2333\n",
      "    D_cls_loss: 8.3020\n",
      "    G_loss: 44.7380\n",
      "    D_loss: 8.9240\n",
      "epoch: 89\n",
      "    G_flow_loss: 1.2268\n",
      "    G_land_loss: 20.8640\n",
      "    G_mask_loss: 0.2343\n",
      "    G_rcon_loss: 2.2036\n",
      "    G_cls_loss: 10.4144\n",
      "    GAN_loss: 10.7634\n",
      "    D_fake_loss: 0.3431\n",
      "    D_real_loss: 0.2134\n",
      "    D_cls_loss: 7.9678\n",
      "    G_loss: 45.4723\n",
      "    D_loss: 8.5243\n",
      "epoch: 90\n",
      "    G_flow_loss: 2.3109\n",
      "    G_land_loss: 28.4682\n",
      "    G_mask_loss: 0.2343\n",
      "    G_rcon_loss: 2.2381\n",
      "    G_cls_loss: 19.6284\n",
      "    GAN_loss: 10.6807\n",
      "    D_fake_loss: 0.3964\n",
      "    D_real_loss: 0.2311\n",
      "    D_cls_loss: 7.8636\n",
      "    G_loss: 63.3263\n",
      "    D_loss: 8.4911\n",
      "epoch: 91\n",
      "    G_flow_loss: 1.8913\n",
      "    G_land_loss: 20.5777\n",
      "    G_mask_loss: 0.2347\n",
      "    G_rcon_loss: 2.2734\n",
      "    G_cls_loss: 16.2362\n",
      "    GAN_loss: 10.7161\n",
      "    D_fake_loss: 0.3544\n",
      "    D_real_loss: 0.2239\n",
      "    D_cls_loss: 8.1099\n",
      "    G_loss: 51.6946\n",
      "    D_loss: 8.6881\n",
      "epoch: 92\n",
      "    G_flow_loss: 0.7234\n",
      "    G_land_loss: 20.7995\n",
      "    G_mask_loss: 0.2393\n",
      "    G_rcon_loss: 2.1989\n",
      "    G_cls_loss: 12.2983\n",
      "    GAN_loss: 10.6748\n",
      "    D_fake_loss: 0.3732\n",
      "    D_real_loss: 0.2322\n",
      "    D_cls_loss: 7.8188\n",
      "    G_loss: 46.6949\n",
      "    D_loss: 8.4241\n",
      "epoch: 93\n",
      "    G_flow_loss: 0.4618\n",
      "    G_land_loss: 20.7245\n",
      "    G_mask_loss: 0.2390\n",
      "    G_rcon_loss: 2.1461\n",
      "    G_cls_loss: 11.2649\n",
      "    GAN_loss: 11.1978\n",
      "    D_fake_loss: 0.8887\n",
      "    D_real_loss: 0.6226\n",
      "    D_cls_loss: 8.1759\n",
      "    G_loss: 45.7950\n",
      "    D_loss: 9.6871\n",
      "epoch: 94\n",
      "    G_flow_loss: 0.3535\n",
      "    G_land_loss: 20.9508\n",
      "    G_mask_loss: 0.2327\n",
      "    G_rcon_loss: 2.1861\n",
      "    G_cls_loss: 10.3214\n",
      "    GAN_loss: 10.2183\n",
      "    D_fake_loss: 0.4851\n",
      "    D_real_loss: 0.3057\n",
      "    D_cls_loss: 8.0842\n",
      "    G_loss: 44.0301\n",
      "    D_loss: 8.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 95\n",
      "    G_flow_loss: 0.2802\n",
      "    G_land_loss: 20.7799\n",
      "    G_mask_loss: 0.2239\n",
      "    G_rcon_loss: 2.2279\n",
      "    G_cls_loss: 9.6986\n",
      "    GAN_loss: 10.3507\n",
      "    D_fake_loss: 0.4590\n",
      "    D_real_loss: 0.3088\n",
      "    D_cls_loss: 7.7329\n",
      "    G_loss: 43.3375\n",
      "    D_loss: 8.5007\n",
      "epoch: 96\n",
      "    G_flow_loss: 0.2395\n",
      "    G_land_loss: 20.8749\n",
      "    G_mask_loss: 0.2181\n",
      "    G_rcon_loss: 2.2653\n",
      "    G_cls_loss: 6.6983\n",
      "    GAN_loss: 10.4930\n",
      "    D_fake_loss: 0.4296\n",
      "    D_real_loss: 0.2841\n",
      "    D_cls_loss: 7.5586\n",
      "    G_loss: 40.5710\n",
      "    D_loss: 8.2723\n",
      "epoch: 97\n",
      "    G_flow_loss: 0.1615\n",
      "    G_land_loss: 20.6029\n",
      "    G_mask_loss: 0.2182\n",
      "    G_rcon_loss: 2.1904\n",
      "    G_cls_loss: 6.8486\n",
      "    GAN_loss: 10.3951\n",
      "    D_fake_loss: 0.4370\n",
      "    D_real_loss: 0.3034\n",
      "    D_cls_loss: 7.5702\n",
      "    G_loss: 40.1985\n",
      "    D_loss: 8.3106\n",
      "epoch: 98\n",
      "    G_flow_loss: 0.1513\n",
      "    G_land_loss: 20.6274\n",
      "    G_mask_loss: 0.2267\n",
      "    G_rcon_loss: 2.0083\n",
      "    G_cls_loss: 7.0430\n",
      "    GAN_loss: 10.4194\n",
      "    D_fake_loss: 0.4007\n",
      "    D_real_loss: 0.2771\n",
      "    D_cls_loss: 7.2625\n",
      "    G_loss: 40.2494\n",
      "    D_loss: 7.9403\n",
      "epoch: 99\n",
      "    G_flow_loss: 0.1634\n",
      "    G_land_loss: 20.1888\n",
      "    G_mask_loss: 0.2194\n",
      "    G_rcon_loss: 2.0818\n",
      "    G_cls_loss: 5.7053\n",
      "    GAN_loss: 10.4950\n",
      "    D_fake_loss: 0.3874\n",
      "    D_real_loss: 0.2726\n",
      "    D_cls_loss: 7.1406\n",
      "    G_loss: 38.6343\n",
      "    D_loss: 7.8006\n",
      "epoch: 100\n",
      "    G_flow_loss: 0.4128\n",
      "    G_land_loss: 20.6850\n",
      "    G_mask_loss: 0.2228\n",
      "    G_rcon_loss: 1.9948\n",
      "    G_cls_loss: 4.7517\n",
      "    GAN_loss: 10.4960\n",
      "    D_fake_loss: 0.3713\n",
      "    D_real_loss: 0.2578\n",
      "    D_cls_loss: 7.1586\n",
      "    G_loss: 38.3403\n",
      "    D_loss: 7.7876\n",
      "epoch: 101\n",
      "    G_flow_loss: 0.4974\n",
      "    G_land_loss: 20.5389\n",
      "    G_mask_loss: 0.2299\n",
      "    G_rcon_loss: 1.9238\n",
      "    G_cls_loss: 4.8914\n",
      "    GAN_loss: 10.4529\n",
      "    D_fake_loss: 0.4374\n",
      "    D_real_loss: 0.3172\n",
      "    D_cls_loss: 7.0788\n",
      "    G_loss: 38.3044\n",
      "    D_loss: 7.8334\n",
      "epoch: 102\n",
      "    G_flow_loss: 0.2421\n",
      "    G_land_loss: 19.8277\n",
      "    G_mask_loss: 0.2316\n",
      "    G_rcon_loss: 1.9024\n",
      "    G_cls_loss: 4.3149\n",
      "    GAN_loss: 10.3552\n",
      "    D_fake_loss: 0.4137\n",
      "    D_real_loss: 0.2854\n",
      "    D_cls_loss: 7.0204\n",
      "    G_loss: 36.6424\n",
      "    D_loss: 7.7195\n",
      "epoch: 103\n",
      "    G_flow_loss: 0.1417\n",
      "    G_land_loss: 20.9092\n",
      "    G_mask_loss: 0.2429\n",
      "    G_rcon_loss: 1.7096\n",
      "    G_cls_loss: 4.9813\n",
      "    GAN_loss: 10.2232\n",
      "    D_fake_loss: 0.4811\n",
      "    D_real_loss: 0.3055\n",
      "    D_cls_loss: 7.0642\n",
      "    G_loss: 37.9649\n",
      "    D_loss: 7.8507\n",
      "epoch: 104\n",
      "    G_flow_loss: 0.1600\n",
      "    G_land_loss: 20.2855\n",
      "    G_mask_loss: 0.2438\n",
      "    G_rcon_loss: 1.6591\n",
      "    G_cls_loss: 4.7131\n",
      "    GAN_loss: 10.3353\n",
      "    D_fake_loss: 0.4442\n",
      "    D_real_loss: 0.2949\n",
      "    D_cls_loss: 6.8583\n",
      "    G_loss: 37.1529\n",
      "    D_loss: 7.5974\n",
      "epoch: 105\n",
      "    G_flow_loss: 0.1756\n",
      "    G_land_loss: 19.9412\n",
      "    G_mask_loss: 0.2438\n",
      "    G_rcon_loss: 1.6302\n",
      "    G_cls_loss: 4.7400\n",
      "    GAN_loss: 10.3081\n",
      "    D_fake_loss: 0.4897\n",
      "    D_real_loss: 0.3101\n",
      "    D_cls_loss: 6.8497\n",
      "    G_loss: 36.7951\n",
      "    D_loss: 7.6496\n",
      "epoch: 106\n",
      "    G_flow_loss: 0.1917\n",
      "    G_land_loss: 21.1279\n",
      "    G_mask_loss: 0.2429\n",
      "    G_rcon_loss: 1.6590\n",
      "    G_cls_loss: 4.4442\n",
      "    GAN_loss: 10.3837\n",
      "    D_fake_loss: 0.4299\n",
      "    D_real_loss: 0.2937\n",
      "    D_cls_loss: 6.6613\n",
      "    G_loss: 37.8065\n",
      "    D_loss: 7.3848\n",
      "epoch: 107\n",
      "    G_flow_loss: 0.1642\n",
      "    G_land_loss: 20.7567\n",
      "    G_mask_loss: 0.2503\n",
      "    G_rcon_loss: 1.5614\n",
      "    G_cls_loss: 4.4649\n",
      "    GAN_loss: 10.1262\n",
      "    D_fake_loss: 0.5173\n",
      "    D_real_loss: 0.3438\n",
      "    D_cls_loss: 6.6072\n",
      "    G_loss: 37.0734\n",
      "    D_loss: 7.4683\n",
      "epoch: 108\n",
      "    G_flow_loss: 0.3334\n",
      "    G_land_loss: 20.6010\n",
      "    G_mask_loss: 0.2545\n",
      "    G_rcon_loss: 1.4864\n",
      "    G_cls_loss: 4.4782\n",
      "    GAN_loss: 10.1013\n",
      "    D_fake_loss: 0.5018\n",
      "    D_real_loss: 0.3210\n",
      "    D_cls_loss: 6.5279\n",
      "    G_loss: 37.0004\n",
      "    D_loss: 7.3507\n",
      "epoch: 109\n",
      "    G_flow_loss: 0.1552\n",
      "    G_land_loss: 19.9923\n",
      "    G_mask_loss: 0.2510\n",
      "    G_rcon_loss: 1.5407\n",
      "    G_cls_loss: 4.3782\n",
      "    GAN_loss: 10.3120\n",
      "    D_fake_loss: 0.4615\n",
      "    D_real_loss: 0.3030\n",
      "    D_cls_loss: 6.3458\n",
      "    G_loss: 36.3785\n",
      "    D_loss: 7.1102\n",
      "epoch: 110\n",
      "    G_flow_loss: 0.0999\n",
      "    G_land_loss: 20.9498\n",
      "    G_mask_loss: 0.2503\n",
      "    G_rcon_loss: 1.5621\n",
      "    G_cls_loss: 4.7135\n",
      "    GAN_loss: 10.3176\n",
      "    D_fake_loss: 0.4499\n",
      "    D_real_loss: 0.2792\n",
      "    D_cls_loss: 6.3242\n",
      "    G_loss: 37.6429\n",
      "    D_loss: 7.0532\n",
      "epoch: 111\n",
      "    G_flow_loss: 0.3813\n",
      "    G_land_loss: 20.3895\n",
      "    G_mask_loss: 0.2435\n",
      "    G_rcon_loss: 1.6681\n",
      "    G_cls_loss: 4.4055\n",
      "    GAN_loss: 10.3203\n",
      "    D_fake_loss: 0.4706\n",
      "    D_real_loss: 0.3090\n",
      "    D_cls_loss: 6.3517\n",
      "    G_loss: 37.1647\n",
      "    D_loss: 7.1313\n",
      "epoch: 112\n",
      "    G_flow_loss: 0.3172\n",
      "    G_land_loss: 20.4377\n",
      "    G_mask_loss: 0.2443\n",
      "    G_rcon_loss: 1.6765\n",
      "    G_cls_loss: 4.6721\n",
      "    GAN_loss: 10.4628\n",
      "    D_fake_loss: 0.4131\n",
      "    D_real_loss: 0.2656\n",
      "    D_cls_loss: 6.3044\n",
      "    G_loss: 37.5662\n",
      "    D_loss: 6.9831\n",
      "epoch: 113\n",
      "    G_flow_loss: 0.3110\n",
      "    G_land_loss: 20.3654\n",
      "    G_mask_loss: 0.2458\n",
      "    G_rcon_loss: 1.6512\n",
      "    G_cls_loss: 3.8287\n",
      "    GAN_loss: 10.5432\n",
      "    D_fake_loss: 0.3895\n",
      "    D_real_loss: 0.2555\n",
      "    D_cls_loss: 6.0595\n",
      "    G_loss: 36.6995\n",
      "    D_loss: 6.7045\n",
      "epoch: 114\n",
      "    G_flow_loss: 0.2183\n",
      "    G_land_loss: 21.0760\n",
      "    G_mask_loss: 0.2459\n",
      "    G_rcon_loss: 1.6771\n",
      "    G_cls_loss: 4.4099\n",
      "    GAN_loss: 10.5662\n",
      "    D_fake_loss: 0.4353\n",
      "    D_real_loss: 0.2735\n",
      "    D_cls_loss: 6.3044\n",
      "    G_loss: 37.9476\n",
      "    D_loss: 7.0132\n",
      "epoch: 115\n",
      "    G_flow_loss: 0.1515\n",
      "    G_land_loss: 20.4244\n",
      "    G_mask_loss: 0.2444\n",
      "    G_rcon_loss: 1.7211\n",
      "    G_cls_loss: 4.1318\n",
      "    GAN_loss: 10.6097\n",
      "    D_fake_loss: 0.3541\n",
      "    D_real_loss: 0.2323\n",
      "    D_cls_loss: 5.9916\n",
      "    G_loss: 37.0385\n",
      "    D_loss: 6.5780\n",
      "epoch: 116\n",
      "    G_flow_loss: 0.1593\n",
      "    G_land_loss: 20.2556\n",
      "    G_mask_loss: 0.2434\n",
      "    G_rcon_loss: 1.7135\n",
      "    G_cls_loss: 3.2763\n",
      "    GAN_loss: 10.5477\n",
      "    D_fake_loss: 0.3818\n",
      "    D_real_loss: 0.2542\n",
      "    D_cls_loss: 5.8179\n",
      "    G_loss: 35.9524\n",
      "    D_loss: 6.4539\n",
      "epoch: 117\n",
      "    G_flow_loss: 0.1282\n",
      "    G_land_loss: 20.3510\n",
      "    G_mask_loss: 0.2401\n",
      "    G_rcon_loss: 1.7783\n",
      "    G_cls_loss: 3.6872\n",
      "    GAN_loss: 10.6345\n",
      "    D_fake_loss: 0.3575\n",
      "    D_real_loss: 0.2406\n",
      "    D_cls_loss: 5.6824\n",
      "    G_loss: 36.5791\n",
      "    D_loss: 6.2805\n",
      "epoch: 118\n",
      "    G_flow_loss: 0.1542\n",
      "    G_land_loss: 20.3820\n",
      "    G_mask_loss: 0.2416\n",
      "    G_rcon_loss: 1.7599\n",
      "    G_cls_loss: 3.2787\n",
      "    GAN_loss: 10.5981\n",
      "    D_fake_loss: 0.3701\n",
      "    D_real_loss: 0.2524\n",
      "    D_cls_loss: 5.6479\n",
      "    G_loss: 36.1729\n",
      "    D_loss: 6.2705\n",
      "epoch: 119\n",
      "    G_flow_loss: 0.1652\n",
      "    G_land_loss: 20.3168\n",
      "    G_mask_loss: 0.2434\n",
      "    G_rcon_loss: 1.7419\n",
      "    G_cls_loss: 3.5552\n",
      "    GAN_loss: 10.6578\n",
      "    D_fake_loss: 0.3709\n",
      "    D_real_loss: 0.2360\n",
      "    D_cls_loss: 5.7652\n",
      "    G_loss: 36.4369\n",
      "    D_loss: 6.3720\n",
      "epoch: 120\n",
      "    G_flow_loss: 0.0828\n",
      "    G_land_loss: 20.4396\n",
      "    G_mask_loss: 0.2449\n",
      "    G_rcon_loss: 1.7040\n",
      "    G_cls_loss: 2.7066\n",
      "    GAN_loss: 10.6484\n",
      "    D_fake_loss: 0.3447\n",
      "    D_real_loss: 0.2345\n",
      "    D_cls_loss: 5.5339\n",
      "    G_loss: 35.5814\n",
      "    D_loss: 6.1132\n",
      "epoch: 121\n",
      "    G_flow_loss: 0.0701\n",
      "    G_land_loss: 20.8551\n",
      "    G_mask_loss: 0.2462\n",
      "    G_rcon_loss: 1.6923\n",
      "    G_cls_loss: 3.2968\n",
      "    GAN_loss: 10.7122\n",
      "    D_fake_loss: 0.3609\n",
      "    D_real_loss: 0.2370\n",
      "    D_cls_loss: 5.4839\n",
      "    G_loss: 36.6265\n",
      "    D_loss: 6.0818\n",
      "epoch: 122\n",
      "    G_flow_loss: 0.0842\n",
      "    G_land_loss: 20.1944\n",
      "    G_mask_loss: 0.2440\n",
      "    G_rcon_loss: 1.7508\n",
      "    G_cls_loss: 3.3224\n",
      "    GAN_loss: 10.7341\n",
      "    D_fake_loss: 0.3890\n",
      "    D_real_loss: 0.2492\n",
      "    D_cls_loss: 5.5327\n",
      "    G_loss: 36.0860\n",
      "    D_loss: 6.1709\n",
      "epoch: 123\n",
      "    G_flow_loss: 0.0567\n",
      "    G_land_loss: 20.7134\n",
      "    G_mask_loss: 0.2467\n",
      "    G_rcon_loss: 1.6889\n",
      "    G_cls_loss: 2.9566\n",
      "    GAN_loss: 10.6298\n",
      "    D_fake_loss: 0.3732\n",
      "    D_real_loss: 0.2492\n",
      "    D_cls_loss: 5.5060\n",
      "    G_loss: 36.0455\n",
      "    D_loss: 6.1284\n",
      "epoch: 124\n",
      "    G_flow_loss: 0.1652\n",
      "    G_land_loss: 20.0371\n",
      "    G_mask_loss: 0.2446\n",
      "    G_rcon_loss: 1.7057\n",
      "    G_cls_loss: 2.6731\n",
      "    GAN_loss: 10.5733\n",
      "    D_fake_loss: 0.3911\n",
      "    D_real_loss: 0.2495\n",
      "    D_cls_loss: 5.4306\n",
      "    G_loss: 35.1544\n",
      "    D_loss: 6.0712\n",
      "epoch: 125\n",
      "    G_flow_loss: 0.2896\n",
      "    G_land_loss: 20.7389\n",
      "    G_mask_loss: 0.2469\n",
      "    G_rcon_loss: 1.7003\n",
      "    G_cls_loss: 2.7498\n",
      "    GAN_loss: 10.5848\n",
      "    D_fake_loss: 0.4083\n",
      "    D_real_loss: 0.2658\n",
      "    D_cls_loss: 5.3926\n",
      "    G_loss: 36.0634\n",
      "    D_loss: 6.0667\n",
      "epoch: 126\n",
      "    G_flow_loss: 0.0771\n",
      "    G_land_loss: 20.3183\n",
      "    G_mask_loss: 0.2484\n",
      "    G_rcon_loss: 1.6674\n",
      "    G_cls_loss: 2.5322\n",
      "    GAN_loss: 10.6068\n",
      "    D_fake_loss: 0.3732\n",
      "    D_real_loss: 0.2491\n",
      "    D_cls_loss: 5.2068\n",
      "    G_loss: 35.2018\n",
      "    D_loss: 5.8292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 127\n",
      "    G_flow_loss: 0.0463\n",
      "    G_land_loss: 20.2641\n",
      "    G_mask_loss: 0.2484\n",
      "    G_rcon_loss: 1.6537\n",
      "    G_cls_loss: 2.4911\n",
      "    GAN_loss: 10.6213\n",
      "    D_fake_loss: 0.3662\n",
      "    D_real_loss: 0.2491\n",
      "    D_cls_loss: 5.1578\n",
      "    G_loss: 35.0765\n",
      "    D_loss: 5.7731\n",
      "epoch: 128\n",
      "    G_flow_loss: 0.0513\n",
      "    G_land_loss: 19.9286\n",
      "    G_mask_loss: 0.2476\n",
      "    G_rcon_loss: 1.6560\n",
      "    G_cls_loss: 2.6798\n",
      "    GAN_loss: 10.6245\n",
      "    D_fake_loss: 0.3968\n",
      "    D_real_loss: 0.2745\n",
      "    D_cls_loss: 5.2685\n",
      "    G_loss: 34.9403\n",
      "    D_loss: 5.9398\n",
      "epoch: 129\n",
      "    G_flow_loss: 0.0413\n",
      "    G_land_loss: 21.0263\n",
      "    G_mask_loss: 0.2506\n",
      "    G_rcon_loss: 1.6190\n",
      "    G_cls_loss: 2.4630\n",
      "    GAN_loss: 10.5147\n",
      "    D_fake_loss: 0.3748\n",
      "    D_real_loss: 0.2535\n",
      "    D_cls_loss: 5.1028\n",
      "    G_loss: 35.6642\n",
      "    D_loss: 5.7311\n",
      "epoch: 130\n",
      "    G_flow_loss: 0.0823\n",
      "    G_land_loss: 20.5737\n",
      "    G_mask_loss: 0.2518\n",
      "    G_rcon_loss: 1.5911\n",
      "    G_cls_loss: 2.6308\n",
      "    GAN_loss: 10.5036\n",
      "    D_fake_loss: 0.4047\n",
      "    D_real_loss: 0.2728\n",
      "    D_cls_loss: 5.1667\n",
      "    G_loss: 35.3815\n",
      "    D_loss: 5.8442\n",
      "epoch: 131\n",
      "    G_flow_loss: 0.1958\n",
      "    G_land_loss: 20.4386\n",
      "    G_mask_loss: 0.2493\n",
      "    G_rcon_loss: 1.6268\n",
      "    G_cls_loss: 2.8494\n",
      "    GAN_loss: 10.6356\n",
      "    D_fake_loss: 0.3890\n",
      "    D_real_loss: 0.2599\n",
      "    D_cls_loss: 5.0062\n",
      "    G_loss: 35.7461\n",
      "    D_loss: 5.6552\n",
      "epoch: 132\n",
      "    G_flow_loss: 0.0840\n",
      "    G_land_loss: 20.8347\n",
      "    G_mask_loss: 0.2496\n",
      "    G_rcon_loss: 1.6364\n",
      "    G_cls_loss: 2.9180\n",
      "    GAN_loss: 10.6092\n",
      "    D_fake_loss: 0.3839\n",
      "    D_real_loss: 0.2541\n",
      "    D_cls_loss: 4.7448\n",
      "    G_loss: 36.0822\n",
      "    D_loss: 5.3828\n",
      "epoch: 133\n",
      "    G_flow_loss: 0.0326\n",
      "    G_land_loss: 20.5435\n",
      "    G_mask_loss: 0.2572\n",
      "    G_rcon_loss: 1.5089\n",
      "    G_cls_loss: 2.7013\n",
      "    GAN_loss: 10.4767\n",
      "    D_fake_loss: 0.3886\n",
      "    D_real_loss: 0.2530\n",
      "    D_cls_loss: 4.6372\n",
      "    G_loss: 35.2631\n",
      "    D_loss: 5.2788\n",
      "epoch: 134\n",
      "    G_flow_loss: 0.0268\n",
      "    G_land_loss: 20.2391\n",
      "    G_mask_loss: 0.2617\n",
      "    G_rcon_loss: 1.4352\n",
      "    G_cls_loss: 2.8139\n",
      "    GAN_loss: 10.3904\n",
      "    D_fake_loss: 0.4309\n",
      "    D_real_loss: 0.2856\n",
      "    D_cls_loss: 4.6835\n",
      "    G_loss: 34.9054\n",
      "    D_loss: 5.3999\n",
      "epoch: 135\n",
      "    G_flow_loss: 0.0389\n",
      "    G_land_loss: 20.4797\n",
      "    G_mask_loss: 0.2677\n",
      "    G_rcon_loss: 1.3377\n",
      "    G_cls_loss: 2.8451\n",
      "    GAN_loss: 10.1099\n",
      "    D_fake_loss: 0.5095\n",
      "    D_real_loss: 0.3391\n",
      "    D_cls_loss: 4.5739\n",
      "    G_loss: 34.8113\n",
      "    D_loss: 5.4225\n",
      "epoch: 136\n",
      "    G_flow_loss: 0.0450\n",
      "    G_land_loss: 20.8716\n",
      "    G_mask_loss: 0.2755\n",
      "    G_rcon_loss: 1.1871\n",
      "    G_cls_loss: 3.5483\n",
      "    GAN_loss: 9.7315\n",
      "    D_fake_loss: 0.5510\n",
      "    D_real_loss: 0.3859\n",
      "    D_cls_loss: 4.6923\n",
      "    G_loss: 35.3835\n",
      "    D_loss: 5.6292\n",
      "epoch: 137\n",
      "    G_flow_loss: 0.0067\n",
      "    G_land_loss: 20.6174\n",
      "    G_mask_loss: 0.2783\n",
      "    G_rcon_loss: 1.1348\n",
      "    G_cls_loss: 3.3761\n",
      "    GAN_loss: 9.7918\n",
      "    D_fake_loss: 0.5599\n",
      "    D_real_loss: 0.4248\n",
      "    D_cls_loss: 4.3754\n",
      "    G_loss: 34.9268\n",
      "    D_loss: 5.3601\n",
      "epoch: 138\n",
      "    G_flow_loss: 0.0072\n",
      "    G_land_loss: 20.3469\n",
      "    G_mask_loss: 0.2799\n",
      "    G_rcon_loss: 1.1070\n",
      "    G_cls_loss: 3.6796\n",
      "    GAN_loss: 9.7599\n",
      "    D_fake_loss: 0.5173\n",
      "    D_real_loss: 0.3892\n",
      "    D_cls_loss: 4.3716\n",
      "    G_loss: 34.9005\n",
      "    D_loss: 5.2781\n",
      "epoch: 139\n",
      "    G_flow_loss: 0.0040\n",
      "    G_land_loss: 20.5523\n",
      "    G_mask_loss: 0.2814\n",
      "    G_rcon_loss: 1.0615\n",
      "    G_cls_loss: 3.9184\n",
      "    GAN_loss: 9.6235\n",
      "    D_fake_loss: 0.5694\n",
      "    D_real_loss: 0.4490\n",
      "    D_cls_loss: 4.4819\n",
      "    G_loss: 35.1596\n",
      "    D_loss: 5.5002\n",
      "epoch: 140\n",
      "    G_flow_loss: 0.0045\n",
      "    G_land_loss: 20.0213\n",
      "    G_mask_loss: 0.2822\n",
      "    G_rcon_loss: 1.0451\n",
      "    G_cls_loss: 4.0266\n",
      "    GAN_loss: 9.6951\n",
      "    D_fake_loss: 0.5196\n",
      "    D_real_loss: 0.4021\n",
      "    D_cls_loss: 4.2417\n",
      "    G_loss: 34.7926\n",
      "    D_loss: 5.1634\n",
      "epoch: 141\n",
      "    G_flow_loss: 0.0077\n",
      "    G_land_loss: 20.5665\n",
      "    G_mask_loss: 0.2810\n",
      "    G_rcon_loss: 1.0618\n",
      "    G_cls_loss: 3.3755\n",
      "    GAN_loss: 9.8113\n",
      "    D_fake_loss: 0.5295\n",
      "    D_real_loss: 0.3994\n",
      "    D_cls_loss: 4.2373\n",
      "    G_loss: 34.8228\n",
      "    D_loss: 5.1662\n",
      "epoch: 142\n",
      "    G_flow_loss: 0.0074\n",
      "    G_land_loss: 20.6828\n",
      "    G_mask_loss: 0.2824\n",
      "    G_rcon_loss: 1.0388\n",
      "    G_cls_loss: 3.7491\n",
      "    GAN_loss: 9.7768\n",
      "    D_fake_loss: 0.5477\n",
      "    D_real_loss: 0.4130\n",
      "    D_cls_loss: 4.1616\n",
      "    G_loss: 35.2549\n",
      "    D_loss: 5.1222\n",
      "epoch: 143\n",
      "    G_flow_loss: 0.0077\n",
      "    G_land_loss: 20.7570\n",
      "    G_mask_loss: 0.2813\n",
      "    G_rcon_loss: 1.0327\n",
      "    G_cls_loss: 3.6550\n",
      "    GAN_loss: 9.8895\n",
      "    D_fake_loss: 0.5006\n",
      "    D_real_loss: 0.4017\n",
      "    D_cls_loss: 4.0558\n",
      "    G_loss: 35.3419\n",
      "    D_loss: 4.9581\n",
      "epoch: 144\n",
      "    G_flow_loss: 0.0090\n",
      "    G_land_loss: 20.3141\n",
      "    G_mask_loss: 0.2794\n",
      "    G_rcon_loss: 1.0670\n",
      "    G_cls_loss: 3.3196\n",
      "    GAN_loss: 9.8949\n",
      "    D_fake_loss: 0.4906\n",
      "    D_real_loss: 0.3704\n",
      "    D_cls_loss: 3.9108\n",
      "    G_loss: 34.6047\n",
      "    D_loss: 4.7718\n",
      "epoch: 145\n",
      "    G_flow_loss: 0.0087\n",
      "    G_land_loss: 21.1138\n",
      "    G_mask_loss: 0.2784\n",
      "    G_rcon_loss: 1.0698\n",
      "    G_cls_loss: 3.1632\n",
      "    GAN_loss: 9.9980\n",
      "    D_fake_loss: 0.4673\n",
      "    D_real_loss: 0.3389\n",
      "    D_cls_loss: 3.9188\n",
      "    G_loss: 35.3536\n",
      "    D_loss: 4.7250\n",
      "epoch: 146\n",
      "    G_flow_loss: 0.0082\n",
      "    G_land_loss: 20.7172\n",
      "    G_mask_loss: 0.2780\n",
      "    G_rcon_loss: 1.0708\n",
      "    G_cls_loss: 3.1582\n",
      "    GAN_loss: 10.0085\n",
      "    D_fake_loss: 0.4831\n",
      "    D_real_loss: 0.3820\n",
      "    D_cls_loss: 3.7877\n",
      "    G_loss: 34.9628\n",
      "    D_loss: 4.6529\n",
      "epoch: 147\n",
      "    G_flow_loss: 0.0072\n",
      "    G_land_loss: 20.6896\n",
      "    G_mask_loss: 0.2766\n",
      "    G_rcon_loss: 1.0994\n",
      "    G_cls_loss: 2.7734\n",
      "    GAN_loss: 10.0416\n",
      "    D_fake_loss: 0.4469\n",
      "    D_real_loss: 0.3282\n",
      "    D_cls_loss: 3.6933\n",
      "    G_loss: 34.6111\n",
      "    D_loss: 4.4684\n",
      "epoch: 148\n",
      "    G_flow_loss: 0.0062\n",
      "    G_land_loss: 20.4082\n",
      "    G_mask_loss: 0.2760\n",
      "    G_rcon_loss: 1.1132\n",
      "    G_cls_loss: 3.0428\n",
      "    GAN_loss: 10.0847\n",
      "    D_fake_loss: 0.4498\n",
      "    D_real_loss: 0.3393\n",
      "    D_cls_loss: 3.5996\n",
      "    G_loss: 34.6551\n",
      "    D_loss: 4.3886\n",
      "epoch: 149\n",
      "    G_flow_loss: 0.0054\n",
      "    G_land_loss: 20.3051\n",
      "    G_mask_loss: 0.2783\n",
      "    G_rcon_loss: 1.1008\n",
      "    G_cls_loss: 3.3032\n",
      "    GAN_loss: 10.0311\n",
      "    D_fake_loss: 0.4603\n",
      "    D_real_loss: 0.3492\n",
      "    D_cls_loss: 3.7263\n",
      "    G_loss: 34.7457\n",
      "    D_loss: 4.5358\n",
      "epoch: 150\n",
      "    G_flow_loss: 0.0051\n",
      "    G_land_loss: 20.1615\n",
      "    G_mask_loss: 0.2766\n",
      "    G_rcon_loss: 1.1129\n",
      "    G_cls_loss: 2.9543\n",
      "    GAN_loss: 10.2084\n",
      "    D_fake_loss: 0.4100\n",
      "    D_real_loss: 0.2913\n",
      "    D_cls_loss: 3.5871\n",
      "    G_loss: 34.4422\n",
      "    D_loss: 4.2884\n",
      "epoch: 151\n",
      "    G_flow_loss: 0.0046\n",
      "    G_land_loss: 20.0614\n",
      "    G_mask_loss: 0.2745\n",
      "    G_rcon_loss: 1.1250\n",
      "    G_cls_loss: 2.7481\n",
      "    GAN_loss: 10.1710\n",
      "    D_fake_loss: 0.4413\n",
      "    D_real_loss: 0.3278\n",
      "    D_cls_loss: 3.4953\n",
      "    G_loss: 34.1101\n",
      "    D_loss: 4.2644\n",
      "epoch: 152\n",
      "    G_flow_loss: 0.0044\n",
      "    G_land_loss: 20.4707\n",
      "    G_mask_loss: 0.2753\n",
      "    G_rcon_loss: 1.1304\n",
      "    G_cls_loss: 2.7696\n",
      "    GAN_loss: 10.1780\n",
      "    D_fake_loss: 0.4221\n",
      "    D_real_loss: 0.3098\n",
      "    D_cls_loss: 3.4123\n",
      "    G_loss: 34.5531\n",
      "    D_loss: 4.1443\n",
      "epoch: 153\n",
      "    G_flow_loss: 0.0044\n",
      "    G_land_loss: 20.5309\n",
      "    G_mask_loss: 0.2746\n",
      "    G_rcon_loss: 1.1391\n",
      "    G_cls_loss: 2.7673\n",
      "    GAN_loss: 10.2586\n",
      "    D_fake_loss: 0.4516\n",
      "    D_real_loss: 0.3527\n",
      "    D_cls_loss: 3.5115\n",
      "    G_loss: 34.7002\n",
      "    D_loss: 4.3158\n",
      "epoch: 154\n",
      "    G_flow_loss: 0.0044\n",
      "    G_land_loss: 19.8363\n",
      "    G_mask_loss: 0.2736\n",
      "    G_rcon_loss: 1.1441\n",
      "    G_cls_loss: 2.8244\n",
      "    GAN_loss: 10.2614\n",
      "    D_fake_loss: 0.4217\n",
      "    D_real_loss: 0.3125\n",
      "    D_cls_loss: 3.3949\n",
      "    G_loss: 34.0706\n",
      "    D_loss: 4.1291\n",
      "epoch: 155\n",
      "    G_flow_loss: 0.0047\n",
      "    G_land_loss: 20.0647\n",
      "    G_mask_loss: 0.2741\n",
      "    G_rcon_loss: 1.1397\n",
      "    G_cls_loss: 2.6065\n",
      "    GAN_loss: 10.1942\n",
      "    D_fake_loss: 0.4394\n",
      "    D_real_loss: 0.3284\n",
      "    D_cls_loss: 3.3296\n",
      "    G_loss: 34.0099\n",
      "    D_loss: 4.0974\n",
      "epoch: 156\n",
      "    G_flow_loss: 0.0047\n",
      "    G_land_loss: 19.8643\n",
      "    G_mask_loss: 0.2704\n",
      "    G_rcon_loss: 1.1883\n",
      "    G_cls_loss: 2.7069\n",
      "    GAN_loss: 10.3510\n",
      "    D_fake_loss: 0.4048\n",
      "    D_real_loss: 0.2933\n",
      "    D_cls_loss: 3.2284\n",
      "    G_loss: 34.1152\n",
      "    D_loss: 3.9265\n",
      "epoch: 157\n",
      "    G_flow_loss: 0.0050\n",
      "    G_land_loss: 19.5994\n",
      "    G_mask_loss: 0.2701\n",
      "    G_rcon_loss: 1.2012\n",
      "    G_cls_loss: 2.6779\n",
      "    GAN_loss: 10.3087\n",
      "    D_fake_loss: 0.4212\n",
      "    D_real_loss: 0.3291\n",
      "    D_cls_loss: 3.3306\n",
      "    G_loss: 33.7921\n",
      "    D_loss: 4.0808\n",
      "epoch: 158\n",
      "    G_flow_loss: 0.0057\n",
      "    G_land_loss: 19.9116\n",
      "    G_mask_loss: 0.2725\n",
      "    G_rcon_loss: 1.1703\n",
      "    G_cls_loss: 2.8646\n",
      "    GAN_loss: 10.1145\n",
      "    D_fake_loss: 0.4693\n",
      "    D_real_loss: 0.3674\n",
      "    D_cls_loss: 3.2832\n",
      "    G_loss: 34.0666\n",
      "    D_loss: 4.1199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 159\n",
      "    G_flow_loss: 0.0056\n",
      "    G_land_loss: 20.1470\n",
      "    G_mask_loss: 0.2694\n",
      "    G_rcon_loss: 1.2171\n",
      "    G_cls_loss: 2.7062\n",
      "    GAN_loss: 10.3337\n",
      "    D_fake_loss: 0.4195\n",
      "    D_real_loss: 0.3179\n",
      "    D_cls_loss: 3.1651\n",
      "    G_loss: 34.4096\n",
      "    D_loss: 3.9025\n",
      "epoch: 160\n",
      "    G_flow_loss: 0.0053\n",
      "    G_land_loss: 19.5421\n",
      "    G_mask_loss: 0.2715\n",
      "    G_rcon_loss: 1.1912\n",
      "    G_cls_loss: 2.5384\n",
      "    GAN_loss: 10.3458\n",
      "    D_fake_loss: 0.4038\n",
      "    D_real_loss: 0.2934\n",
      "    D_cls_loss: 2.9539\n",
      "    G_loss: 33.6228\n",
      "    D_loss: 3.6511\n",
      "epoch: 161\n",
      "    G_flow_loss: 0.0051\n",
      "    G_land_loss: 19.8577\n",
      "    G_mask_loss: 0.2694\n",
      "    G_rcon_loss: 1.2457\n",
      "    G_cls_loss: 2.4266\n",
      "    GAN_loss: 10.4650\n",
      "    D_fake_loss: 0.3693\n",
      "    D_real_loss: 0.2728\n",
      "    D_cls_loss: 2.8321\n",
      "    G_loss: 34.0000\n",
      "    D_loss: 3.4742\n",
      "epoch: 162\n",
      "    G_flow_loss: 0.0057\n",
      "    G_land_loss: 20.0330\n",
      "    G_mask_loss: 0.2664\n",
      "    G_rcon_loss: 1.2790\n",
      "    G_cls_loss: 2.3126\n",
      "    GAN_loss: 10.3769\n",
      "    D_fake_loss: 0.3897\n",
      "    D_real_loss: 0.2811\n",
      "    D_cls_loss: 2.9150\n",
      "    G_loss: 34.0071\n",
      "    D_loss: 3.5858\n",
      "epoch: 163\n",
      "    G_flow_loss: 0.0062\n",
      "    G_land_loss: 19.2853\n",
      "    G_mask_loss: 0.2640\n",
      "    G_rcon_loss: 1.3062\n",
      "    G_cls_loss: 2.2408\n",
      "    GAN_loss: 10.4498\n",
      "    D_fake_loss: 0.3927\n",
      "    D_real_loss: 0.2932\n",
      "    D_cls_loss: 2.8819\n",
      "    G_loss: 33.2883\n",
      "    D_loss: 3.5678\n",
      "epoch: 164\n",
      "    G_flow_loss: 0.0075\n",
      "    G_land_loss: 18.4905\n",
      "    G_mask_loss: 0.2622\n",
      "    G_rcon_loss: 1.3375\n",
      "    G_cls_loss: 2.2798\n",
      "    GAN_loss: 10.5425\n",
      "    D_fake_loss: 0.3687\n",
      "    D_real_loss: 0.2662\n",
      "    D_cls_loss: 2.7956\n",
      "    G_loss: 32.6577\n",
      "    D_loss: 3.4305\n",
      "epoch: 165\n",
      "    G_flow_loss: 0.0085\n",
      "    G_land_loss: 17.7937\n",
      "    G_mask_loss: 0.2622\n",
      "    G_rcon_loss: 1.3191\n",
      "    G_cls_loss: 2.2362\n",
      "    GAN_loss: 10.6342\n",
      "    D_fake_loss: 0.3447\n",
      "    D_real_loss: 0.2339\n",
      "    D_cls_loss: 2.6541\n",
      "    G_loss: 31.9917\n",
      "    D_loss: 3.2327\n",
      "epoch: 166\n",
      "    G_flow_loss: 0.0085\n",
      "    G_land_loss: 17.2993\n",
      "    G_mask_loss: 0.2595\n",
      "    G_rcon_loss: 1.3638\n",
      "    G_cls_loss: 2.2854\n",
      "    GAN_loss: 10.7265\n",
      "    D_fake_loss: 0.3359\n",
      "    D_real_loss: 0.2358\n",
      "    D_cls_loss: 2.7741\n",
      "    G_loss: 31.6836\n",
      "    D_loss: 3.3458\n",
      "epoch: 167\n",
      "    G_flow_loss: 0.0084\n",
      "    G_land_loss: 17.0800\n",
      "    G_mask_loss: 0.2588\n",
      "    G_rcon_loss: 1.3692\n",
      "    G_cls_loss: 2.2171\n",
      "    GAN_loss: 10.6778\n",
      "    D_fake_loss: 0.3342\n",
      "    D_real_loss: 0.2306\n",
      "    D_cls_loss: 2.6597\n",
      "    G_loss: 31.3525\n",
      "    D_loss: 3.2244\n",
      "epoch: 168\n",
      "    G_flow_loss: 0.0070\n",
      "    G_land_loss: 16.3888\n",
      "    G_mask_loss: 0.2594\n",
      "    G_rcon_loss: 1.3581\n",
      "    G_cls_loss: 2.3374\n",
      "    GAN_loss: 10.7590\n",
      "    D_fake_loss: 0.3394\n",
      "    D_real_loss: 0.2417\n",
      "    D_cls_loss: 2.6586\n",
      "    G_loss: 30.8503\n",
      "    D_loss: 3.2398\n",
      "epoch: 169\n",
      "    G_flow_loss: 0.0069\n",
      "    G_land_loss: 15.9998\n",
      "    G_mask_loss: 0.2599\n",
      "    G_rcon_loss: 1.3518\n",
      "    G_cls_loss: 2.0416\n",
      "    GAN_loss: 10.6490\n",
      "    D_fake_loss: 0.3175\n",
      "    D_real_loss: 0.2273\n",
      "    D_cls_loss: 2.5426\n",
      "    G_loss: 30.0491\n",
      "    D_loss: 3.0874\n",
      "epoch: 170\n",
      "    G_flow_loss: 0.0068\n",
      "    G_land_loss: 15.6623\n",
      "    G_mask_loss: 0.2606\n",
      "    G_rcon_loss: 1.3471\n",
      "    G_cls_loss: 2.2471\n",
      "    GAN_loss: 10.6797\n",
      "    D_fake_loss: 0.3510\n",
      "    D_real_loss: 0.2504\n",
      "    D_cls_loss: 2.7022\n",
      "    G_loss: 29.9430\n",
      "    D_loss: 3.3036\n",
      "epoch: 171\n",
      "    G_flow_loss: 0.0068\n",
      "    G_land_loss: 15.4453\n",
      "    G_mask_loss: 0.2647\n",
      "    G_rcon_loss: 1.2930\n",
      "    G_cls_loss: 2.2832\n",
      "    GAN_loss: 10.7015\n",
      "    D_fake_loss: 0.3124\n",
      "    D_real_loss: 0.2152\n",
      "    D_cls_loss: 2.3881\n",
      "    G_loss: 29.7298\n",
      "    D_loss: 2.9157\n",
      "epoch: 172\n",
      "    G_flow_loss: 0.0072\n",
      "    G_land_loss: 15.2708\n",
      "    G_mask_loss: 0.2642\n",
      "    G_rcon_loss: 1.3064\n",
      "    G_cls_loss: 2.2840\n",
      "    GAN_loss: 10.6666\n",
      "    D_fake_loss: 0.3267\n",
      "    D_real_loss: 0.2309\n",
      "    D_cls_loss: 2.4087\n",
      "    G_loss: 29.5351\n",
      "    D_loss: 2.9663\n",
      "epoch: 173\n",
      "    G_flow_loss: 0.0076\n",
      "    G_land_loss: 15.0679\n",
      "    G_mask_loss: 0.2631\n",
      "    G_rcon_loss: 1.3256\n",
      "    G_cls_loss: 2.1626\n",
      "    GAN_loss: 10.7176\n",
      "    D_fake_loss: 0.3159\n",
      "    D_real_loss: 0.2256\n",
      "    D_cls_loss: 2.5252\n",
      "    G_loss: 29.2813\n",
      "    D_loss: 3.0668\n",
      "epoch: 174\n",
      "    G_flow_loss: 0.0090\n",
      "    G_land_loss: 14.9454\n",
      "    G_mask_loss: 0.2621\n",
      "    G_rcon_loss: 1.3533\n",
      "    G_cls_loss: 2.3248\n",
      "    GAN_loss: 10.7971\n",
      "    D_fake_loss: 0.3024\n",
      "    D_real_loss: 0.2077\n",
      "    D_cls_loss: 2.3435\n",
      "    G_loss: 29.4296\n",
      "    D_loss: 2.8536\n",
      "epoch: 175\n",
      "    G_flow_loss: 0.0183\n",
      "    G_land_loss: 14.5924\n",
      "    G_mask_loss: 0.2629\n",
      "    G_rcon_loss: 1.3319\n",
      "    G_cls_loss: 2.1363\n",
      "    GAN_loss: 10.7760\n",
      "    D_fake_loss: 0.3157\n",
      "    D_real_loss: 0.2171\n",
      "    D_cls_loss: 2.2223\n",
      "    G_loss: 28.8549\n",
      "    D_loss: 2.7551\n",
      "epoch: 176\n",
      "    G_flow_loss: 0.0123\n",
      "    G_land_loss: 14.4657\n",
      "    G_mask_loss: 0.2629\n",
      "    G_rcon_loss: 1.3177\n",
      "    G_cls_loss: 2.2376\n",
      "    GAN_loss: 10.7049\n",
      "    D_fake_loss: 0.2999\n",
      "    D_real_loss: 0.2144\n",
      "    D_cls_loss: 2.1377\n",
      "    G_loss: 28.7382\n",
      "    D_loss: 2.6519\n",
      "epoch: 177\n",
      "    G_flow_loss: 0.0104\n",
      "    G_land_loss: 14.1454\n",
      "    G_mask_loss: 0.2637\n",
      "    G_rcon_loss: 1.3173\n",
      "    G_cls_loss: 2.3005\n",
      "    GAN_loss: 10.7605\n",
      "    D_fake_loss: 0.3059\n",
      "    D_real_loss: 0.2173\n",
      "    D_cls_loss: 2.1204\n",
      "    G_loss: 28.5342\n",
      "    D_loss: 2.6436\n",
      "epoch: 178\n",
      "    G_flow_loss: 0.0106\n",
      "    G_land_loss: 14.3156\n",
      "    G_mask_loss: 0.2631\n",
      "    G_rcon_loss: 1.3140\n",
      "    G_cls_loss: 2.1748\n",
      "    GAN_loss: 10.7866\n",
      "    D_fake_loss: 0.2936\n",
      "    D_real_loss: 0.1979\n",
      "    D_cls_loss: 2.0606\n",
      "    G_loss: 28.6017\n",
      "    D_loss: 2.5521\n",
      "epoch: 179\n",
      "    G_flow_loss: 0.0104\n",
      "    G_land_loss: 14.3488\n",
      "    G_mask_loss: 0.2629\n",
      "    G_rcon_loss: 1.3153\n",
      "    G_cls_loss: 2.1481\n",
      "    GAN_loss: 10.7439\n",
      "    D_fake_loss: 0.2988\n",
      "    D_real_loss: 0.2134\n",
      "    D_cls_loss: 1.9899\n",
      "    G_loss: 28.5664\n",
      "    D_loss: 2.5022\n",
      "epoch: 180\n",
      "    G_flow_loss: 0.0099\n",
      "    G_land_loss: 13.9155\n",
      "    G_mask_loss: 0.2628\n",
      "    G_rcon_loss: 1.3169\n",
      "    G_cls_loss: 2.1133\n",
      "    GAN_loss: 10.8085\n",
      "    D_fake_loss: 0.2933\n",
      "    D_real_loss: 0.2087\n",
      "    D_cls_loss: 2.0126\n",
      "    G_loss: 28.1640\n",
      "    D_loss: 2.5147\n",
      "epoch: 181\n",
      "    G_flow_loss: 0.0098\n",
      "    G_land_loss: 13.7025\n",
      "    G_mask_loss: 0.2632\n",
      "    G_rcon_loss: 1.2993\n",
      "    G_cls_loss: 2.5319\n",
      "    GAN_loss: 10.5915\n",
      "    D_fake_loss: 0.3868\n",
      "    D_real_loss: 0.3097\n",
      "    D_cls_loss: 2.2774\n",
      "    G_loss: 28.1350\n",
      "    D_loss: 2.9739\n",
      "epoch: 182\n",
      "    G_flow_loss: 0.0097\n",
      "    G_land_loss: 13.4897\n",
      "    G_mask_loss: 0.2663\n",
      "    G_rcon_loss: 1.2656\n",
      "    G_cls_loss: 2.5196\n",
      "    GAN_loss: 10.6982\n",
      "    D_fake_loss: 0.3209\n",
      "    D_real_loss: 0.2410\n",
      "    D_cls_loss: 2.1017\n",
      "    G_loss: 27.9828\n",
      "    D_loss: 2.6636\n",
      "epoch: 183\n",
      "    G_flow_loss: 0.0106\n",
      "    G_land_loss: 13.6912\n",
      "    G_mask_loss: 0.2641\n",
      "    G_rcon_loss: 1.2974\n",
      "    G_cls_loss: 2.3757\n",
      "    GAN_loss: 10.7141\n",
      "    D_fake_loss: 0.3081\n",
      "    D_real_loss: 0.2283\n",
      "    D_cls_loss: 1.8707\n",
      "    G_loss: 28.0889\n",
      "    D_loss: 2.4070\n",
      "epoch: 184\n",
      "    G_flow_loss: 0.0100\n",
      "    G_land_loss: 13.4071\n",
      "    G_mask_loss: 0.2631\n",
      "    G_rcon_loss: 1.3058\n",
      "    G_cls_loss: 2.6160\n",
      "    GAN_loss: 10.6696\n",
      "    D_fake_loss: 0.3205\n",
      "    D_real_loss: 0.2390\n",
      "    D_cls_loss: 1.9197\n",
      "    G_loss: 28.0085\n",
      "    D_loss: 2.4792\n",
      "epoch: 185\n",
      "    G_flow_loss: 0.0091\n",
      "    G_land_loss: 13.3914\n",
      "    G_mask_loss: 0.2615\n",
      "    G_rcon_loss: 1.3302\n",
      "    G_cls_loss: 2.4768\n",
      "    GAN_loss: 10.7545\n",
      "    D_fake_loss: 0.3094\n",
      "    D_real_loss: 0.2245\n",
      "    D_cls_loss: 1.9289\n",
      "    G_loss: 27.9619\n",
      "    D_loss: 2.4627\n",
      "epoch: 186\n",
      "    G_flow_loss: 0.0096\n",
      "    G_land_loss: 12.9861\n",
      "    G_mask_loss: 0.2620\n",
      "    G_rcon_loss: 1.3312\n",
      "    G_cls_loss: 2.3703\n",
      "    GAN_loss: 10.8194\n",
      "    D_fake_loss: 0.3073\n",
      "    D_real_loss: 0.2172\n",
      "    D_cls_loss: 1.7703\n",
      "    G_loss: 27.5165\n",
      "    D_loss: 2.2949\n",
      "epoch: 187\n",
      "    G_flow_loss: 0.0090\n",
      "    G_land_loss: 13.0603\n",
      "    G_mask_loss: 0.2607\n",
      "    G_rcon_loss: 1.3333\n",
      "    G_cls_loss: 2.2674\n",
      "    GAN_loss: 10.8539\n",
      "    D_fake_loss: 0.2625\n",
      "    D_real_loss: 0.1963\n",
      "    D_cls_loss: 1.6856\n",
      "    G_loss: 27.5239\n",
      "    D_loss: 2.1444\n",
      "epoch: 188\n",
      "    G_flow_loss: 0.0106\n",
      "    G_land_loss: 12.9517\n",
      "    G_mask_loss: 0.2618\n",
      "    G_rcon_loss: 1.3237\n",
      "    G_cls_loss: 2.2215\n",
      "    GAN_loss: 10.8676\n",
      "    D_fake_loss: 0.2710\n",
      "    D_real_loss: 0.1989\n",
      "    D_cls_loss: 1.7694\n",
      "    G_loss: 27.3751\n",
      "    D_loss: 2.2393\n",
      "epoch: 189\n",
      "    G_flow_loss: 0.0107\n",
      "    G_land_loss: 12.8744\n",
      "    G_mask_loss: 0.2617\n",
      "    G_rcon_loss: 1.3076\n",
      "    G_cls_loss: 2.0440\n",
      "    GAN_loss: 10.9123\n",
      "    D_fake_loss: 0.2633\n",
      "    D_real_loss: 0.1874\n",
      "    D_cls_loss: 1.6385\n",
      "    G_loss: 27.1490\n",
      "    D_loss: 2.0892\n",
      "epoch: 190\n",
      "    G_flow_loss: 0.0107\n",
      "    G_land_loss: 12.7216\n",
      "    G_mask_loss: 0.2622\n",
      "    G_rcon_loss: 1.3129\n",
      "    G_cls_loss: 1.9935\n",
      "    GAN_loss: 10.8332\n",
      "    D_fake_loss: 0.2840\n",
      "    D_real_loss: 0.2036\n",
      "    D_cls_loss: 1.6005\n",
      "    G_loss: 26.8718\n",
      "    D_loss: 2.0882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 191\n",
      "    G_flow_loss: 0.0108\n",
      "    G_land_loss: 12.7867\n",
      "    G_mask_loss: 0.2625\n",
      "    G_rcon_loss: 1.3038\n",
      "    G_cls_loss: 2.1251\n",
      "    GAN_loss: 10.9052\n",
      "    D_fake_loss: 0.2574\n",
      "    D_real_loss: 0.1817\n",
      "    D_cls_loss: 1.5445\n",
      "    G_loss: 27.1316\n",
      "    D_loss: 1.9836\n",
      "epoch: 192\n",
      "    G_flow_loss: 0.0102\n",
      "    G_land_loss: 12.5020\n",
      "    G_mask_loss: 0.2614\n",
      "    G_rcon_loss: 1.3285\n",
      "    G_cls_loss: 2.1947\n",
      "    GAN_loss: 10.9013\n",
      "    D_fake_loss: 0.2706\n",
      "    D_real_loss: 0.2010\n",
      "    D_cls_loss: 1.7430\n",
      "    G_loss: 26.9366\n",
      "    D_loss: 2.2147\n",
      "epoch: 193\n",
      "    G_flow_loss: 0.0105\n",
      "    G_land_loss: 12.6279\n",
      "    G_mask_loss: 0.2634\n",
      "    G_rcon_loss: 1.2975\n",
      "    G_cls_loss: 1.9862\n",
      "    GAN_loss: 10.9059\n",
      "    D_fake_loss: 0.2861\n",
      "    D_real_loss: 0.2050\n",
      "    D_cls_loss: 1.5760\n",
      "    G_loss: 26.8280\n",
      "    D_loss: 2.0670\n",
      "epoch: 194\n",
      "    G_flow_loss: 0.0109\n",
      "    G_land_loss: 12.7852\n",
      "    G_mask_loss: 0.2630\n",
      "    G_rcon_loss: 1.3052\n",
      "    G_cls_loss: 1.8834\n",
      "    GAN_loss: 10.9024\n",
      "    D_fake_loss: 0.2514\n",
      "    D_real_loss: 0.1837\n",
      "    D_cls_loss: 1.5406\n",
      "    G_loss: 26.8871\n",
      "    D_loss: 1.9757\n",
      "epoch: 195\n",
      "    G_flow_loss: 0.0111\n",
      "    G_land_loss: 12.4753\n",
      "    G_mask_loss: 0.2633\n",
      "    G_rcon_loss: 1.3041\n",
      "    G_cls_loss: 2.1149\n",
      "    GAN_loss: 10.9263\n",
      "    D_fake_loss: 0.2631\n",
      "    D_real_loss: 0.1883\n",
      "    D_cls_loss: 1.5273\n",
      "    G_loss: 26.8316\n",
      "    D_loss: 1.9787\n",
      "epoch: 196\n",
      "    G_flow_loss: 0.0110\n",
      "    G_land_loss: 12.4823\n",
      "    G_mask_loss: 0.2619\n",
      "    G_rcon_loss: 1.3139\n",
      "    G_cls_loss: 2.0585\n",
      "    GAN_loss: 10.9697\n",
      "    D_fake_loss: 0.2545\n",
      "    D_real_loss: 0.1775\n",
      "    D_cls_loss: 1.4735\n",
      "    G_loss: 26.8354\n",
      "    D_loss: 1.9055\n",
      "epoch: 197\n",
      "    G_flow_loss: 0.0114\n",
      "    G_land_loss: 12.2094\n",
      "    G_mask_loss: 0.2631\n",
      "    G_rcon_loss: 1.3126\n",
      "    G_cls_loss: 2.1856\n",
      "    GAN_loss: 10.9164\n",
      "    D_fake_loss: 0.2739\n",
      "    D_real_loss: 0.1912\n",
      "    D_cls_loss: 1.4699\n",
      "    G_loss: 26.6353\n",
      "    D_loss: 1.9350\n",
      "epoch: 198\n",
      "    G_flow_loss: 0.0109\n",
      "    G_land_loss: 12.2933\n",
      "    G_mask_loss: 0.2631\n",
      "    G_rcon_loss: 1.3117\n",
      "    G_cls_loss: 2.1043\n",
      "    GAN_loss: 10.9434\n",
      "    D_fake_loss: 0.2619\n",
      "    D_real_loss: 0.1828\n",
      "    D_cls_loss: 1.3444\n",
      "    G_loss: 26.6636\n",
      "    D_loss: 1.7891\n",
      "epoch: 199\n",
      "    G_flow_loss: 0.0100\n",
      "    G_land_loss: 11.8549\n",
      "    G_mask_loss: 0.2615\n",
      "    G_rcon_loss: 1.3312\n",
      "    G_cls_loss: 2.1551\n",
      "    GAN_loss: 10.9164\n",
      "    D_fake_loss: 0.2757\n",
      "    D_real_loss: 0.1862\n",
      "    D_cls_loss: 1.3945\n",
      "    G_loss: 26.2677\n",
      "    D_loss: 1.8563\n",
      "epoch: 200\n",
      "    G_flow_loss: 0.0100\n",
      "    G_land_loss: 11.9757\n",
      "    G_mask_loss: 0.2622\n",
      "    G_rcon_loss: 1.3260\n",
      "    G_cls_loss: 2.1291\n",
      "    GAN_loss: 10.9696\n",
      "    D_fake_loss: 0.2472\n",
      "    D_real_loss: 0.1673\n",
      "    D_cls_loss: 1.3869\n",
      "    G_loss: 26.4106\n",
      "    D_loss: 1.8014\n"
     ]
    }
   ],
   "source": [
    "lossnames = [\"G_flow_loss\",\"G_land_loss\",\"G_mask_loss\",\"G_rcon_loss\",\"G_cls_loss\",\"GAN_loss\",\n",
    "             \"D_fake_loss\",\"D_real_loss\",\"D_cls_loss\",\"G_loss\",\"D_loss\"]\n",
    "metrics_list = []\n",
    "for itemname in lossnames:\n",
    "    metrics_list.append(tf.keras.metrics.Mean(itemname, dtype=tf.float32))\n",
    "\n",
    "for epoch in range(1,200+1):\n",
    "    for (one_Ax, one_Ax_landmark), (one_By, one_By_landmark) in zip(Ax_ds, By_ds):\n",
    "        # train_flownet_step(one_Ax,one_By,one_Ax_landmark,one_By_landmark,tf.cast(epoch,'float32'))\n",
    "        train_items = train_step(one_Ax,one_By,one_Ax_landmark,one_By_landmark,tf.cast(epoch,'float32'))\n",
    "        for (idx, itemname) in enumerate(lossnames):\n",
    "            metrics_list[idx](train_items[itemname])\n",
    "    print(\"epoch: {}\".format(epoch))\n",
    "    for idx,itemname in enumerate(lossnames):\n",
    "        print(\"    {}: {:.4f}\".format(itemname,metrics_list[idx].result()))\n",
    "    #print(\"epoch: {}, G_loss: {:.4f}, D_loss: {:.4f}, flow_loss: {:.3}\".format(epoch, \n",
    "    #                                                         metrics_list[9].result(),metrics_list[10].result(),\n",
    "    #                                                         metrics_list[0].result()+metrics_list[1].result()))\n",
    "    for metric in metrics_list:\n",
    "        metric.reset_states()\n",
    "    if epoch % 5 == 0:\n",
    "        for (one_Ax, one_Ax_landmark), (one_By, one_By_landmark) in zip(Ax_ds, By_ds):\n",
    "            g_items = generator(one_Ax,one_By,tf.cast(epoch,'float32'),False)\n",
    "            save_images([one_Ax,one_By,g_items['By_warpped'].numpy(),\n",
    "                         g_items['masks'][2][:,:,:,0],\n",
    "                         g_items['masks'][0][:,:,:,0],\n",
    "                         g_items['raw_fake_Ay'].numpy(),g_items['fake_Ay'].numpy(),g_items['residual_Ay'].numpy(),\n",
    "                         g_items['fakeAy_to_Ax'].numpy(),g_items['masks'][1][:,:,:,0],\n",
    "                         g_items['fake_Bx'].numpy(),g_items['fakeBx_to_By'].numpy()],\n",
    "                        epoch,BATCH_SIZE,'GeoGAN1126')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(201,300+1):\n",
    "    for (one_Ax, one_Ax_landmark), (one_By, one_By_landmark) in zip(Ax_ds, By_ds):\n",
    "        train_items = train_step(one_Ax,one_By,one_Ax_landmark,one_By_landmark,tf.cast(epoch,'float32'))\n",
    "        for (idx, itemname) in enumerate(lossnames):\n",
    "            metrics_list[idx](train_items[itemname])\n",
    "    print(\"epoch: {}, G_loss: {}, D_loss: {}\".format(epoch, metrics_list[9].result(),metrics_list[10].result()))\n",
    "    for metric in metrics_list:\n",
    "        metric.reset_states()\n",
    "    if epoch % 5 == 0:\n",
    "        for (one_Ax, one_Ax_landmark), (one_By, one_By_landmark) in zip(Ax_ds, By_ds):\n",
    "            g_items = generator(one_Ax,one_By,tf.cast(epoch,'float32'),False)\n",
    "            save_images([one_Ax,one_By,g_items['By_warpped'].numpy(),g_items['fake_Ay'].numpy()],\n",
    "                        epoch,BATCH_SIZE,'GeoGAN1')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------Standard For tensorboard output\n",
    "lossnames = [\"G_flow_loss\",\"G_land_loss\",\"G_mask_loss\",\"G_rcon_loss\",\"G_cls_loss\",\"GAN_loss\",\n",
    "             \"D_fake_loss\",\"D_real_loss\",\"D_cls_loss\",\"G_loss\",\"D_loss\"]\n",
    "metrics_list = []\n",
    "for itemname in lossnames:\n",
    "    metrics_list.append(tf.keras.metrics.Mean(itemname, dtype=tf.float32))\n",
    "\n",
    "for epoch in range(1,EPOCHS+1):\n",
    "    print(\"epoch: {}\".format(epoch))\n",
    "    for (one_Ax, one_Ax_landmark), (one_By, one_By_landmark) in zip(Ax_ds, By_ds):\n",
    "        train_items = train_step(one_Ax,one_By,one_Ax_landmark,one_By_landmark,tf.cast(epoch,'float32'))\n",
    "        for (idx, itemname) in enumerate(lossnames):\n",
    "            metrics_list[idx](train_items[itemname])\n",
    "    with train_summary_writer.as_default():\n",
    "        for (idx, itemname) in enumerate(lossnames):\n",
    "            tf.summary.scalar(itemname, metrics_list[idx].result(), step=epoch)\n",
    "            metrics_list[idx].reset_states()\n",
    "    if epoch % 10 == 0:\n",
    "        for (one_Ax, one_Ax_landmark), (one_By, one_By_landmark) in zip(Ax_ds, By_ds):\n",
    "            g_items = generator(one_Ax,one_By,tf.cast(epoch,'float32'),False)\n",
    "            save_images([one_Ax,one_By,g_items['By_warpped'].numpy(),g_items['fake_Ay'].numpy()],epoch,BATCH_SIZE)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_flowNet_step(Ax,By,landmark_Ax,landmark_By,epoch):\n",
    "    with tf.GradientTape() as g_tape:\n",
    "        _,_, By_flow, By_warpped = generator.callflowNet(Ax,By,True)\n",
    "        # 1. TV_reg loss\n",
    "        G_flow_loss = 0.0\n",
    "        G_flow_loss += flow_loss_func.totalVariation_loss(By_flow)\n",
    "        G_flow_loss = lambda_flow * tf.cast(G_flow_loss,'float32')\n",
    "        # 2. landmark loss (By_flow)\n",
    "        G_land_loss = flow_loss_func.landmark_loss(landmark_By,landmark_Ax,By_flow)\n",
    "        G_land_loss = lambda_landmark * tf.cast(G_land_loss,'float32')\n",
    "    \n",
    "        G_loss = G_flow_loss + G_land_loss\n",
    "    gradients_of_generator = g_tape.gradient(G_loss,generator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "#     print(\"G_flow_loss: {}, G_land_loss: {}\".format(G_flow_loss,G_land_loss))\n",
    "    return_items = {}\n",
    "    return_items[\"G_flow_loss\"] = G_flow_loss\n",
    "    return_items[\"G_land_loss\"] = G_land_loss\n",
    "    return return_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lossnames = [\"G_flow_loss\",\"G_land_loss\"]\n",
    "metrics_list = []\n",
    "for itemname in lossnames:\n",
    "    metrics_list.append(tf.keras.metrics.Mean(itemname, dtype=tf.float32))\n",
    "    \n",
    "for epoch in range(1,EPOCHS+1):\n",
    "    for (one_Ax, one_Ax_landmark), (one_By, one_By_landmark) in zip(Ax_ds, By_ds):\n",
    "        train_items = train_flowNet_step(one_Ax,one_By,one_Ax_landmark,one_By_landmark,tf.cast(epoch,'float32'))\n",
    "        for (idx, itemname) in enumerate(lossnames):\n",
    "            metrics_list[idx](train_items[itemname])\n",
    "    print(\"epoch: {}, G_flow_loss: {}, G_land_loss: {}\".format(epoch, metrics_list[0].result(),metrics_list[1].result()))\n",
    "    metrics_list[0].reset_states()\n",
    "    metrics_list[1].reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Only Flow Net\n",
    "test_Ax_iter = iter(Ax_ds)\n",
    "test_By_iter = iter(By_ds)\n",
    "testAx, testAxMark = next(test_Ax_iter)\n",
    "testBy, testByMark = next(test_By_iter)\n",
    "test_Ax_front, test_By_front, test_By_flow, test_By_warpped = generator.callflowNet(testAx,testBy,False)\n",
    "test_raw_Ay, test_By_mask = generator.callmaskNet(testAx,test_By_warpped)\n",
    "testAxMark2 = tf.expand_dims(testAxMark,1)\n",
    "testByMark2 = tf.expand_dims(testByMark,1)\n",
    "test_sampled_flow = stn_bilinear_sampler(test_By_flow,testByMark2[:,:,:,0],testByMark2[:,:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(75, 75))\n",
    "gs = matplotlib.gridspec.GridSpec(1, 4, width_ratios=[1, 1, 1, 1],\n",
    "        wspace=0.0, hspace=0.0, top=0.95, bottom=0.05, left=0.1, right=0.2)\n",
    "img_idx = 6\n",
    "imgs = [testAx[img_idx],testBy[img_idx],test_By_warpped[img_idx],test_raw_Ay[img_idx]]\n",
    "for idx,img in enumerate(imgs):\n",
    "    ax = plt.subplot(gs[0,idx])\n",
    "    ax.axis('off')\n",
    "    ax.imshow(np.clip((img+1)/2,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------Set TensorBoard\n",
    "import datetime\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (one_Ax, one_Ax_landmark), (one_By, one_By_landmark) in zip(Ax_ds, By_ds):\n",
    "    g_items = generator(one_Ax,one_By,tf.cast(epoch,'float32'),False)\n",
    "    save_images([one_Ax,one_By,g_items['By_warpped'].numpy(),g_items['fake_Ay'].numpy()],10,BATCH_SIZE)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(11,200+1):\n",
    "    print(\"epoch: {}\".format(epoch))\n",
    "    for (one_Ax, one_Ax_landmark), (one_By, one_By_landmark) in zip(Ax_ds, By_ds):\n",
    "        train_items = train_step(one_Ax,one_By,one_Ax_landmark,one_By_landmark,tf.cast(epoch,'float32'))\n",
    "        for (idx, itemname) in enumerate(lossnames):\n",
    "            metrics_list[idx](train_items[itemname])\n",
    "    with train_summary_writer.as_default():\n",
    "        for (idx, itemname) in enumerate(lossnames):\n",
    "            tf.summary.scalar(itemname, metrics_list[idx].result(), step=epoch)\n",
    "            metrics_list[idx].reset_states()\n",
    "    if epoch % 10 == 0:\n",
    "        for (one_Ax, one_Ax_landmark), (one_By, one_By_landmark) in zip(Ax_ds, By_ds):\n",
    "            g_items = generator(one_Ax,one_By,tf.cast(epoch,'float32'),False)\n",
    "            save_images([one_Ax,one_By,g_items['By_warpped'].numpy(),g_items['fake_Ay'].numpy()],epoch,BATCH_SIZE)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testAx = Ax[333]\n",
    "testBy = By[333]\n",
    "testAy = By[455]\n",
    "fig,axes=plt.subplots(2,3)\n",
    "ax1=axes[0,2]\n",
    "ax1.axis('off')\n",
    "ax2=axes[1,0]\n",
    "ax2.axis('off')\n",
    "ax3=axes[1,1]\n",
    "ax3.axis('off')\n",
    "ax1.imshow(testAx+1)\n",
    "ax2.imshow(testBy+1)\n",
    "ax3.imshow(testAy+1)\n",
    "plt.savefig('image_at_epoch_test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Ax_iter = iter(Ax_ds)\n",
    "test_By_iter = iter(By_ds)\n",
    "testAx, testAxMark = next(test_Ax_iter)\n",
    "testBy, testByMark = next(test_By_iter)\n",
    "test_Ax_front, test_By_front, test_By_flow, test_By_warpped = generator.callflowNet(testAx,testBy,False)\n",
    "test_raw_Ay, test_By_mask = generator.callmaskNet(testAx,test_By_warpped)\n",
    "testAxMark2 = tf.expand_dims(testAxMark,1)\n",
    "testByMark2 = tf.expand_dims(testByMark,1)\n",
    "test_sampled_flow = stn_bilinear_sampler(test_By_flow,testByMark2[:,:,:,0],testByMark2[:,:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Ax_iter = iter(Ax_ds)\n",
    "test_By_iter = iter(By_ds)\n",
    "testAx, testAxMark = next(test_Ax_iter)\n",
    "testBy, testByMark = next(test_By_iter)\n",
    "g_items = generator(testAx,testBy,tf.cast(100,'float32'),False)\n",
    "testAxMark2 = tf.expand_dims(testAxMark,1)\n",
    "testByMark2 = tf.expand_dims(testByMark,1)\n",
    "test_sampled_flow = stn_bilinear_sampler(g_items['flows'][0],testByMark2[:,:,:,0],testByMark2[:,:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93854094"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(g_items['masks'][2][0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc79d4b9890>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOy9a6gtW3Ye9o05q9Zae+/zuvf27dtPudukcVACHTuNbBAEYSXBcUz6jxG2g+k4gv5jO28iOX/kHw4oEOIoBBQulhMJjFuyY5DAIiaIiJAfUXQldRzJLam71Y/7vuee5957PapqzpEfc4wxR9Va99zb9zz26bNrwDlVq2rWrFm1a84xxjdexMyYaaaZLi+Fix7ATDPNdLE0LwIzzXTJaV4EZprpktO8CMw00yWneRGYaaZLTvMiMNNMl5we2yJARH+OiP6AiL5BRD/5uO4z00wzPRzR4/ATIKII4A8B/FsAXgPwmwD+MjP/i0d+s5lmmumhqHlM/f4QgG8w8x8BABF9BcAXARxcBD7yfOTPfLp9TEOZ6UHE+OBM4FDL7HrIwlAYBABIICTW/SjtCT3Hcb9MCFSu1fYBta+W0uj+kbKd13MAEOUYyTYS2TmyLY1+PwmiJ3q3MTEYWd7HV/95/y4zvzht87gWgU8CeNX9fg3An/YNiOjLAL4MAD/wyQb/zz/79GMaykwPosR59Ds/YFHIyEgTyXHHA3q55jyXbS8f/d28wGlelf10AgDYcos3+hvjPnKL49ABAE5Tab8KvYwv4KX2XtkX7fVGPMdCJv8nmjsAygJwVa5pZTxXA8k5Qkvl2iB9tDReiMq5DzZZH/SODvUV6eKgt8QZGy7v9vonX/vOoTaPaxF4X2LmlwG8DABf+Pxq9l2+INr7QCeLgqeAaBy75zIJl9QgQLhxKNeeymJwQyY2UCYzANzqr+Bq2EofjXaMd/srAIDn2vMyLsfpb8sC8on2LgDgJOxwQqXvLP2+GDc4kUm/nEzwFTU2+Q9N9O91ku4vH08vRQpo32fEj2sReB2AZ+2fkmMzfR+QTgqVEvR3z8kmkYraAcEtCKXdOfQ347ZM0oUT22/ENQDgO91HAADHoUMbyvnrcQMAuDOcyO+1LRYvxDMAQMfRJIUVDbKFSSleDdAxPug5Lzs9rrfwmwA+R0SfJaIFgL8E4Fce071mmmmmh6DHIgkw80BEfwPAP0ORnv4+M//e47jXTI+WPHeccsqWokkHjYiYAxJWVD6jdVbuXNqfMuF62AEAulza/0B7C98WCeCPLd4FANxKV/DZ5U0AwNv99dG5+/kIn25vAQDupmMAwKfbW0hQ0b9IEFuuGEASVULHBcBJMJeP+zcXpA6AmX8VwK8+rv5nmmmmR0MXBgzO9HTQ1DrwIPKouOIAPRJ20sdd6eqmcOy7+disAt/aFcvUN9cv4ua2gICrWCSHO7tjNFQuPu8XAICPHp8CALrc4Mai4ARH0v5Tqzu4Ggu4qJaDT7e38AKXds8HBSrLpgCD309w3qOl95N+Lp9sNNNMM41olgQuiKbI+6Pqc4rsKw1IhpIrFweANaseXzjllpPt99KH2ti37rrbWe9JeDtdLfuid3999zH5HfDV0x8AAATh9P/vO5/Aoin9vHunXPfc9XPculWkg+s3iuXgq+8U49InPnoX37xZMITPfbTgBl+78xK+8OJ3AQC/fb/0/28//7v4toztX18VF5W7Yqr8RDOY78DSffKXER84RPMi8BjpvSa6n6CPYjHQPjIYWSZqRp60YfTo966NGINpLQWb/OoEpItGYlaPALP7ZxCOBfy7KYuBmu9uDldxoxVz4Pp5AMCiSbh3flTutSjmvXtnK4RWfAzOi7NQ08pCcf8EMZZztzZFzVg1A97YFADxalPufTtdwYtNUSFu5dL/C2Ej48/mHKQqTQB9oHf/QdWl7+cF5ft35DPNNNMjoVkSeIz0XtwhUngs6sCDKCMbhw/iTJOZjdsHVq7P2LJeU0jF/AigEwlgx6o+NDjnAuad5yWAaso7Syvc7goweGdXjq27FkNfrlWYMe0iQiPSzFD6p2WRBLpti5OrBQQ83Zb+V1cG3NsVbq+SwJ3hxJyQbqeiWtwQz8Q1c40xkJuO3IY/ALd/X1fhSR/fT5LB989IZ5pppsdCsyRwAXQIEzhE78dNHnStutD2osXvOJtPv3L2FoxpD+fcIPN7B9JsxYX3vgQGrXlpnF8dfd7pCjbw9u4aXj8vx26diyRwvkLaCRce5D6RkbcaR1DGOJzXqNJ1WI7G0PcN2rbgCSSxDLvcGE6hjkfHVKQENKcA1L24PPExsgGlUzfjQ+QDp6Z4C3AgMMn9bZ52qWBeBN6DpuL6hxHf32uSZvBB4E4/Rv3gDiHZH3Qc0/5vJcJOJzCXSdVzNBH+o7GAaluuk68TkV/9/u/nFdbS/o3+uTIeEN7ty6Q/H8q5d3ZFHL+zO8a9TVksuq7cO20jkGTS6SLAAIkawFHCgeUcNwy+W9QNPpIFbQigK6Xdm/evAQCakPFdKmNSHwIda6TXsM4l4Oh5OdfRgBOLLKyLwNQior8jCFt797V9K9dqYNWhYJ30lC8IT9+IZppppidKsySAB8fUD2JHV3Evu0i6Dxp7r5zDvOw4GyCn1DEbD2kVuINypYhdHkZ9Za7ShPa75WT8X2P718LNXx2ewzuDiOlDEdEjGNtcOP8nFiUu/zQd2ZjUtq/huqdphXty/p1d6WuXGry5Ltw45dLu3dMCBuZM6Dalf+7KOGhb+Q6JRMAtm1QgDNUkAWQAqp50VVrYnhfpoGvKBW+Ea7izOBqN91pbuP4y9LgRS4jyOZdIxBfCGjvNPyDdJ65gqIZHa26EdY5IMl00zDmBsBIp6bp4KUbrMx4MX55+a0+DZHDxI5hpppkulC69JHBIby/mtMpdy7FCAfsONhFknF11xFPOSMLVlBtfFW5xMy3QCpd9dShZdj4W71sWnufF1KUc53rY2f1XIgl4yeGUlVs1uJXFoYbEYScVLv0H24/j1W1x2GlkHLe7YxvHG7syjl1usJOIPz13U3T8RRjw1nnpT811212LQbi8gnu0EzNfR4i9cEHdJMCyi8lDcXIYQNR2egFZO1qXk2nFoHuCMVwpz3L31g2cvVg4/11xRvrotcL173ZH+MxxiUT86OJ+ed/NPXNyUtNi5mA4iGIjUd7B3XSCVnIX3B7K+/hEe8feM5rSbxQA8mqoEgYOSARPgwSgdGkXgf6AZ52f+G8n/SOV7U0JhPljzX3cy+W1XVfPuLzAx2L5oP5oKBP5xbjB1/sXAAB/vL0NAPi6oOcn1OH3u4+XffkQv7r9AbzQlI/2LRHXP7d4GwBwazjCi6F8qK/KQvGxuMarQ5mQN8Qz7qu7T+NF+Ri/2b0EAFjnIjb/4flLeH1d+m0kA9D93cpy+l1dlHG8c3bFEPfzTZnoaZDJ1wdwLxNcJiRlQtiKH4GK8upWyOV8OSj+CD0hLWRfJn7KQChzB7khawcAHBhR+pdHQbMmyJ8Azbrs5JaR+zL5N9L/t++K6nLjCr5zUkDDK20BCF9YneOTRyVT0VJu3lLCWSrPfBxLu3tD6UNBTwC415e/wWdPbpl35J88Lpm7NN3Zi7xDlEXjeijvqqQ5kwWT1UPz4gObnp7laKaZZroQunSSQPWzr6Da1Ff+28PCvM40GEbpm2GHj0muu98Tb7gV9fh6V8RHFRm/2Tf4xrZw47eWhQO/0RVu9InFHfze+pMAgB9YFinh3eEK7om9/c2utFeJ4Pl4ht8XrzyVHH57cwXXBez6TWl3pz/B1/AJAECU53tzJ/c+v45316X/4Mzid+9L2O+ycLT1nSME8dbjO4vRs7f3AjQtYHtfuPgKkLSASMapy5YbQBglWNQYykBs6z4AhI6qJNDqMf1NaIuAhOFY7n0OSEpCNHLv3XOExT1RlW6ISHJaeNx6IKxFKlhcKR2/sbiGN69U8yJQpIO31xLUtCwP8a07RZr7yJVzvHG3tF8tykN96+4L+BPPv1PuIQ//rxyXLHofa+7heUmHlrj8zU4CQR7BUrE9DfT0jGSmmWa6ELp0koCSmm8SBvOlT7lwhBMa8G3RvRU8elfMa59e3MItAYZ8tNzzos8raNRzg6wAopisPtKKQ05u8ZlVSZ91VfT5ZegtH/8VwRc0Ku48L42zq1fe9bg2aWUn7HOdF3btTpTmXkC+o6a3EN5VU9juG7evI0iE3uZcdN7I4PuFqylY156Jzr+tHFs5cN4C7ZmYzJal3eK+eP2tgIWc64+krw2ju1L2m4LjobtKaDbSTs+tpc8VoTlXPEHuvamSgjxuwSYGNbvKeDXZMTWGUwxXynvpVhnnp+OIxe/Qc2Axc769uApPr9+5Dhb8pBtKH9eOthjkb/tuV/4W7Unp6zwv8YmmJDzxoHL6AOnKnzTNksBMM11yulSSgDcHmnWAGeeGExQ6zQvcCNVsBMDeVEuDmZTUfJRjMNda5d530zGea2jU7kR82TuOiKTmxXLuWrxvEsbzymaFVtRZ+3Xer7ijNOSIMyxl3OXe21QGfq9bYdeX/a3gFzkFDIKuQ1D8eFrR6sVtMW3JLRf32HFjNQUAcTceRyNhiLkhxJ04PK0F9e8YjTgMkTg0NdtQ9zdjvIDXXPEC4fqxY+SdWhHkPXZUzZDSXs2NR++Q4RVqkcgtIZ2XcQytVDtqGRDno6TOTSIpUWQsBTdRieC47Q1D+ONXiwnya5uCyXxqcdv+7p9uCu7T8YCPxfrenha6FIvAe/kCAMCWM/QbVrGoQ0RW2678IdV8l7hOeLUlX40b88H3E1Or6qg60FkproCVLAiaU18998p15Zz2uaABp2K6UuDxXjo29UHNWECx/QN18brXlXNnuyX6JDbwTZkRaQiAmvzUYy8R5PZV9F/XbSuTvz0t7yAkRlxLMI84RsR1eW4OAWHX2z4AUD+AV63cUxbR4wUg++mKqCKp/B6utIg78d47Lu+q2SQMR+VZmm05N6zq4tVs1LOw/N4NwUyKO1TVRh0RQ1d2hpNsiyFLIBOLOhVDQi8h0K2oD7fOj3FtNVa/Nqk82+3hiqmLajbMICTsf4sXTbM6MNNMl5wuhSRwKO9eDf0kLIV769kbYWueYLrV0NkX4tnIdxwATvORReEptTTgLfEGVCkiOC6gEW5aVQeoQOPrEqGnjj+ZA4KYsd6Uc8ehM0lAHVte3TxnWXvvi0PLIEDX+XaBQSL1TAUAEEUkNq3njAxEU9Nc7MrzLs6zid/NpjQiZsRNGbdKArQu3JGIQBvZb4Qtdz0gUg31RYIIzMVjqLykQvIzBrJ4gti5v1/aB9i0nT6LcnommPjtTZFxp2ZOAR47QhZHI4t0bOp91GmqkQQozIQof5e3N0UtUM/EnqN9OwrgnjR36/ifIn1glgRmmumS06WQBB5EGWMTjpJyWfUl11W9pWTnfOy9kh5b5yUWilBZn431rViDv+6+VORVsFD1+vv5yNx/e5fWS7GAW31xWloPCyyE1Wn+fo3n323bms9LU3glMiwgKCPuK7dUwE/BwLhlM8M15+oFxAj3Cmig4B7fF6koRuTTIk7QUgDLs3OEE4n224qUcHIM7kp/8drYNBeuHANRxntlafcZBDsIvaRMi2ReUDrGtKzApghEJuXEDIi6b5gAyEkR6u6sz8RAUJyANZKTsFNz4VKLrMr3EnpLtvK8k/aUssWdXDx96EWAiD4N4BcAvITyeb3MzD9DRM8D+EUAnwHwbQA/xsx3Hn6oj5Z8zIBKloq7b7n+aXr5Mym4dzcdGzBogJ9LzqHA3XleWkCQnrtq2W8bK7OtobsnYWcqgm71+hUNuCfucvclNuFuf4xlLPd6e1M82e7vVjbpG0G1zyR7b95GC8UNnYJ0hEb88i0OZlsmO1Bt8O1GJtrAiFvN1Seif59KkA8AOMtF+e1E9lTPsYj+uqV+sPO6GOiEpn4Ay9+DZMKjCSC5PzeafCRY3EFaCNAnfgvDCsh6TDFUqrEIqgJwKElMRuQ4g8ZUKEC4WvTYiMXlivT/9dNSZOVTx3ctr6GqA6vQ4/mwvyBcND2MOjAA+M+Z+QcB/BkAf52IfhDATwL4NWb+HIBfk98zzTTTU0ofWhJg5jcBvCn7p0T0NQCfBPBFAD8izX4ewK8D+ImHGuUjpGygXtl2zHvqQM8RdyUkV0V45fAZwcw8a0nT1XE0E19G4byneYW1AGAK+Kl433Os2W+FttziTNQBFf1V0rjDZCL/qQB+Z8PSQL/bko//bLtEJ/btKPZoDfNFH0C9SgLCZQdUc6CKyRs2T7t2LRKAmv52dczUC+duY+XKC1GPonDutgV2coOjldxzAC2FBffC9Rct0MlNNbBBJYKjDBJAkI70OgbTWBVLSzJJoD8WILjcEsMxWUyCCFlgqlzfp1TUqEfGBCBkMakCiGIiXG8XWEjthLvbImKEo3Ld7e7EohO1VNrddIytqAbqp/LMRBES0WcA/EkAvwHgJVkgAOAtFHXh0DVfJqJXiOiVm7fSoSYzzTTTE6CHBgaJ6AqA/xXAf8LM98klYWRmJlWkJsTMLwN4GQC+8PnVY3WoflBWXn9Gk3/03JgEoMCgmu0+2d6pjkGadGO4Zpxdufg6LfGtTSmf9dLy/uieV+MWr0sSj+ekQs82t9bf188+CgB4flHOnacazfeGZO8dcrDEHvry1mfLqrfelz+tmsa2wUXtyXaosQAqmIRUgcGa6ku2mS0aUJ1/QGSc3/T4Ru4dA9A242OLtkgIALCQ54qx9qGkf7PhgPTRBHM0QqxgIE+AwZwcixfKqvNzjXq0W0Y2J6F60zEY6CkNEVniMc53pbPrAhDe71e40RYM6A83JRL1Xzv5DrY8znB8qHTck0448lCLABG1KAvAP2DmfyKH3yaijzPzm0T0cQDvPOwgHzepvT9YKa6K6qsIr6Deinok+QNWMDCZJeCMq0ivFgBdINSr7DStLDutUs8Rd3vx9pPxeC+0+52AjF39crUH9QDkIYD1w8/VAxAoSTpsEej1nJvwg56rk0hdfmlQEDCbdVsnJJgr6Bc0bbj4HrQNSCe6qACUM1isAzatVksDEbU9DzowAnRfFgRKGaEbS4901JgPAyYpxDlU1D+7L14BwepfwPuyMbv3Sbq4aPojdovDPh/Tt3VskUz1mKoDzfezOkCF5f8cgK8x83/nTv0KgC/J/pcA/PKHH95MM830uOlhJIEfBvBXAfx/RPRVOfZfAfhpAL9ERD8O4DsAfuzhhvh4ya+CGqTTc2OFK86xHJ07z0tL7KG0os7Meur3/zZfM2Dojpj3rjdFmlg7OfRdyY6xDAPuSwqrTjjNq6IyrOJg4F8nXmubzQKkhTp28mfsyYAss/97EHDC9ck5SRg3dExUgbaoTN9nI4maE5BApg7I24y6jYCoAaxqQWqr6C9AIjexehTqNjgVgydc1v9WFSSzSTrq36DjbdaAJlFWk2iObCbC+kzYZ+j6XjJBpXQWqSW22SSBa0dFDdhJwNb15aYOERr8tTSp82mih7EO/F9471ioH/2w/c4000xPli6dx2BNK1a2OwZ61mywNSbgVMpbayJONfMlkHkFVrNgsGOa4CMzYVCnI+EmtzpNAtKgFZucco7bHHB7V8yA6u2nEsEpljgTEFBNgGkIxoUUB6A+2L2CZvx1OIDtO0fGieMiiIEcxxmCs3PIUeJWiooGMi6v0oFyeDQRvBIdfyltmC2K0PpaNpW7q3lxJaBn28DA5ljvb5CKxiskNqkuGjYgf8+2ttfEJxTJTIgG/uEA6cEMsKGsIk2kiCgOW2sBBo+XRf8/65e4LnUPlLa5NUe0hLE36UXSHDsw00yXnC6dJGBVgZxFQPPrq0SwolqxZiX2NE348dGmRgtqaq63hhu4KmWwNcag52hluW+IGTC5HAXvSi7/o1jaDzma3/87IjGoBUGTgQBA0rLemcC7saSBVCPulMOT0/mnXL+ckC6U67cVXB/U9z5qDEGw/nPrdHYxk3FULivWgSZYjUHDC5pYcws0DksQCcCwg7aaFDXCkFVKYEZuxvyLI2FqxdNYhtjXhCNSilCiCOu1Zev7m1gaAqq0ohsGkkhhmqtBU7etYo8jsQqo2fhTYWcRqPEpwgYu1SLgC4EmFz6sk99TFfk1y2/5gwZkiyewgpfIZlbUY9vcWpEPncwbEf13qbHcdHrv9bDAaV+uHaTmQRTgLzGZGpB1UiUyMyD8hB9LwnXiHzjHPmDGm9B0bsoHrma1kKq6QUP1QyB5LgXiNKSY22gTJ69Km8Bs+0q8jCaSqpqhw+ajFiQTPkkAUegzsiQRUfMlOwDRfB6gi1cFDTWugFKNJ9Dnyy3X7ESqanlTLk22LqhIQ701o9PA0Uy8qkpGYheG/lhdY74nmtWBmWa65HTJJAGfY1BjB8KeJHCaj/by92mI6JqXI2cioIj5a6lQ5NsPEquqmWgtzDctsB6KhPGO5KhrY8LpTsA/4bIarUbE1UFFuX+iypUVGPTi/tTkV5m4cT4vPtsroNqvVQ0aaicaY6AORUxUOb9KApo2bBERVRIQbk6LxgBGbjUNWLBjWY4FeXdpGS2cIC+jXafpxDSuIbcV+DQ8lvZFbktGQmQh0naup/oe1HlJJYJYvwf1yqRYnYX0Tpu+SJCLkCzVmJqEbw5XsVU1B9WB6KJplgRmmumS06WSBIBqGlQm0CPgPlfdHijxAqrba+yAJRfNLTpx9VS34V1u95J+nA9L0wk74Wqncp/TboXNIJiDcH3uFthIFuDdVpxoZIwE5wdvUW01IYg1PKRmahPnEpupcjcDxTSiLlYQTWP1VcfOTZU2clNRtNyOTX55EXSIxu3TosYaaLIP/fyU+wOF85dxCGZypUEQiai/KrhCzxgkUlBTjqWWTGJRbk7uBU6CNgtoyOPnKxfjMFHt0Fz7mSz5iJZlV0xgM7Q4E4ynl2fa5dawpsw76/dBsS1Pgi7FIqDhwz0nSy9uFYNza/EBGj685daQfKU3JIDopfae+QdowM/t4cTiA07F+JxBeHNdkn0cNWXJ0YmfmSz5h348fR9NzEy9fsVlw12o8qYLbbX4AFsEqn87putDdJNDM+Q0RaQFnIoQuebmC+NJwsGJ3O71jDwJ3TkOsIXHLwJZy/UGsus1HDkvxs+elwSWBWdYiUWnJdtXSwOHes0eik/OAqDPFuuYrRJyhpVZG63A/rejnMgsJ514baqfQJ+DfVdvbkvQ15W4s1yVwNOTXGRWB2aa6ZLTJZEExmbBcqxS50KIgSL613yAZbsMmmNwMC/CtYsibNUNT7jm2VAd01VEVFtylyJ6iQEwrz8GBvEHYC2Lbkhe5VrkJAETY82shf1Mu6oCwHE8bdMwSL3fLMUWARpOO2ERxsFRTW2AJQ+28Q6rYOPRfRtHS84cuc+N9R6qbgzL6pvQH4skMNQ0YWzSRI0ZUDDPVJe2gp32DM48amMgHOT42r7uy32ouhGQmAjVHOyjRDWGZBV6Uyt7M1HzXubhJx1SPEsCM810yelSSAJKO85Qt/JzTRqCaGnClO6m41oFCGPQcJ2Xpv973OBskil4PSyM898V/V8Lgt5frzAI2KVboMYAjPR+oEgC3ukHKMDgWPUdOf8gKmeX3+Q84gzcc/iAM4FV0+GYLY5MiiPvuvF42XH4pnEShoxHx9R6FiRcT6UD0nJgiwpUatQfN9XRJ3n9XwaosQNJpYpYdX1NM8ZN3c9tfVf+ucpA3KuYxGp4Bq5ViRTjUc9BADhpyre0zou9KMKnof7ApVoEADeXnEivQJ9O6o4ba6hofzuyDjRybRX51RZ8LrLxNrUWAGRqgNr/u8by1bFD+21wk4w4NOz7BHhgEObiWj3eTC3Qj5rGC4JeV4NipH2GqQMG+LlFwWzwug0VVNRmmsePMlnAjqXsW9JeME8YeKRe6LVACf6BUyW0L53A2g4MAxc16Qu7xUMXKlsE/IT372UCrI4HNT5HBGRR3bKMQxMs71I0r1ANJNvm1mWsem914EnTrA7MNNMlp0shCQS31nWyOmvQ0HHYGTCo4cPXwsY4v25vDsWz78Xm1KQDDRr6Vv/iXrqwRRgsAUgWEVH9/wHspQHDULmBcnvzW3eSwcEgIEfsuFR5eA2TrYAf5wOch99j3/WJgJqDz/kX7A/Jy9DvzeWakfowvqnirNw4jq4SR3b73nlTGurfYgRGxnEfCFUFGgUeGaI60bUA+1ux24ZWQtJ3RcRYLQqA3A3RxnFXisK+tLhv39qhpGJqyn7SksEsCcw00yWnSyEJ+JiBFWnNAF2Rs+lpCuqNSo2JEunrBHTS/p6UmfKkSUJO+5VhAJYNS8tXJarc3XTaqvdbVCDGpi7ASwnY85UvDSYhsAfIO/xMnX8oVf15zwTpnWnM6YbrmNTx6MC4lMFGIpfRd2R3G41DqyCNYgK8J+D08ciNyZyV9sHI0XXTqEqGC8GWa+Ekgjz5m2H/b7vrq/eklig7bsSBiGOtPYGnh2ZJYKaZLjldCknAypCD0KozhyzhJ9RbOnE1Fd5PK5dOTOP+xdyXjk1i0ApBu9zgdifpwuXYWbewKEA1AyoOwJlGMQCAQ/0x5vbA4ehA8vsjfX5iXtQ2ef8cpcplcTASUcdWuaGNM9c+pmPzkIANzUkONTYB1pei9lMzo3foIfdMPlmKDVX3pybLAwo4pZovwTJ9tc5Mqo5VWh/AORxZdCJTxXaE1lIrsln1uLcr+61kav3u5jl8dnlzfzAXTJdiEVAKRGZNW5hacPgV3JXQ4GlgkBfp7kkK2/NhaaHBWwkf3XatlQAzIEk9ATNGIqUdm+ybw5j3GFTRmNxccyKpmsmqCF1Fe51QGmiTG7YgJAUhaSBD7DRsWG9PA5nIbwtVwzW2gGj/3BRfY+x76kUHzqnpcajn/DMDMvEni9whqu/CL7C1Dy3COo69kF2NpVAVpKc6NrOnwrkMsh0CgP58gbNFudkiVlVSvUzVX6WoqocFcl+Y5HHSrA7MNNMlp0slCbSIUOd+Xf1ayib6n4pD+ir06AXgU67/+q5EET7XrC1EWOl0WKKTY/dFBExMNRWYsi1kmMQAACAASURBVLCurrneyQUo3JPHTMXiEHzasJE6oKRiO3upQPt199s7t++ERMCexyI9wETp+zUgUUMPvJOTF98n7Q6pO9a/++3zJmpCEEtuwmSeglnTozlpQqUr1RTC4B2Oyjb7iGgrt+Ycp9RjUNUGD1BqH0dStSkRhqvl733zfkkqc+UjO5MelRJzTZoinYSDBsTHR7MkMNNMl5wuhSSgzheRCMda2SaLGzBnnJCYcCTDcM/NHiagbsaRsoGF565iUB55nADDEPfAvxGXm5jfwI6757FIcIgbsquWY+ez45bJdQzh0lOgkZ3er/0PMN3XHHGUQ+aKbxgOEN/jXij6tHFjxSO66rhj6b2o7hsgZziDk2aaem6vXXDjnUgCiV1VIgEcmw1j0L9pV84NRzRKoFLuLw5Ii/qS7M+THEaiuE+vttDqUtxIXEFmwnEYpxUr3P9i6xE+iqrEEcArAF5n5r9ARJ8F8BUALwD4LQB/lZmfioRqAcFSPescjMSWB08Xg1vcWqkxSxIiX/Fbu+uWRVgtAl1ucNYJ4CPegUMf9+zKIxXgEIo/tVt7of8A8n7QsWwqTntQbNJ030qv10waej+FB4jrVZ/ZP+cXnlEZND02QfvVIkEu4YhXS8KkdkcYKgipC4pO6Lhla9+s2a5vJtmJG64rcd6p74MMcbuv2gAopd9QgUQt9pqWFQxUL8I+R1yPJf380r3wfMDnEvj+CiX+jwF8zf3+bwD8XWb+lwDcAfDjj+AeM80002Oihy1N/ikA/y6A/xrAfyaViv8sgL8iTX4ewN8G8LMPc59HSeozsBAxb801jiCIzeh+TrXEmHqCiXy4y9VEeCbqwFm3xKmUoVIvwczkvAHl5gc43wh8s8oecixMrvN9Obu4Bwst+2127TBRB7wob3kKlUNWjz7lvOrTTgyoldPUkkz7z6JcmipnVCEhDHUcPtuvlhVXk6ZxeuKqKqik3XOthaDnmgoS6g3sN5GpA0n+Js02W+Si1H+xlGXAONoQANLCAZ9mCvXxDNK/JVgh+1toCPkLq3NcjcUn5ZACEC4IonvYu/73AP5L1M/0BQB3mdXKi9cAfPLQhUT0ZSJ6hYheuXkrHWoy00wzPQH60JIAEf0FAO8w828R0Y98r9cz88sAXgaAL3x+9QCXj0dLUVbxpXkRJkTNFSAK4I24tohCKy8ukWDHTYdtctwewHm3MAmg6zRFGGFP1XOA36FCoBOV2sx9Pm3YQfKedBO9lR3nrh6I1UHooMQwkSZGuAJXqcDaVIZ7eFy+r/dx9KFJ9N64qtL+BfZe2HvyuXvp70P4ySGajI0n0hMA+7tycMKby9sAAGgz2kX5dqKkHvvo8gwvxJJgdPWE9P0PQg+jDvwwgH+PiP48gBWAawB+BsANImpEGvgUgNcffpgzzTTT46IPvQgw898C8LcAQCSB/4KZ/30i+kcA/iKKheBLAH75EYzzkVAxFUq+elmyXe5MBGjaMLI0UIoFeBOgugarY9Cma41rJ80h0McRBwU8quzwAn/OAuflmONye3q356gHuD320Haq7dTkRuTi8YX7D7CvwlB8h/ZX05y0j85tWIfjnYscPqD3NnOhN+9NIg/ttzNjanp+GuqYVJ/PjatGNMEEOFQzoFLs2TrRdqGv4wzT93LAeoO8L6HVQqZAI1jAi0fF9Pzp1W28KGbooPd+Clx1HoefwE8A+AoR/R0AvwPg5x7DPb4nUlOLL/KgL39F5KT28geMzGYivNtXMyAAvHp2jEbEu9Ot+Al0EYPknbeEHcO+OjDy+z9ghqOJ6Gkw1yF7tBfl034fOhEryDe+lx6b9uE9+si103NhUvCEBle4dAJsjoj3923B8uL6xBRKB66Dw1BHQVZqIkzjCQ+nao2PT1QPBrJbeAGMw6HDZOtqNFj+w6VkCl4mCxy60pZv6bnmHDdkdWlRU9MpVX+WJ7swPJJFgJl/HcCvy/4fAfihR9HvTDPN9PjpUngMHqLoQCRL0OvOb/N4pT7vJUpwaMz0o+nDhq6pEYIuWchUHTCnoUPAoDPhGRcfObOMPfVAY6lAr1NuXDl/Bfl4Yt6Dk0js3ABIpaw9bz/KTioYmRnlGE3GGMYiv/aPZtJHM973YyweieNjoa+vWcX83JIT/8fjCE7d8GRJRzQZSqzHfE0EP/7pvv7N0lLe+6rclDPQxnLTjywLGPix5i5WE/Q0PiD5y5Oii1dIZppppgulSycJqN6ljKGlgKzpn2VRXlGy8uPeDAgUZxNNIaUJRNlF46kbKWUa6+FwXBGESXVzxK5GEVY/+uo4k6fc06UoD66wZvAAn6MRF/eSwMSkSIdAyLzfR8UEaB87yKMm4x80vr9d53V7T95l2e3vuQ33XN+vOT6JZBC96VGxksqBfWp1iyRUgc6XcTdMQMEHB3LKeDTleGyzmQZP+wIgXwtbtBNbZc8JSxoXdH3SdCkWgUNVX4O3Eujk048HMGDwRlt8vRXkWTVskz97cd/AJQecTQKBDJAjh6A7gM1APRXDnS/8dIHIVCdddtflyWRiP4Gn3n7BTVwv8udxu2phgH0xXlWY9uGDkvaCevo60UyUb4AoRXqTnhMPPywIzbYMZFDfjk319mvX5VxuCXFT9jVIyLwQnUrhyUKJ5VxakAP9pBFNtp4coJkkhFgLlC6WA64uykN9fHUPQMlO3cpLUjUgXnDwEDCrAzPNdOnpUkgCD6IiEYwN8ytKuCF5B4/EEP3S8SkA4M7u2MpP76SAKAWu+QMVmMt1fSWLIqz3Nc6kIv2AauJSn3oPpvHkOt+fE6tpIgkEd59DXop7fQETOR6HRfIDEXVTbjvKCqzSuPcJcOdGmYT9M2XYQ6l//qF7hYHreZVMBk3wEfeyDacFGfinQGhaVhVMYwBUHchtHZyvXORrMvjnXDQDenEjVF+TlvKeX4BPKnJRNEsCM810yenSSwKA99oSRw8iiyz81OI2AODNxfXSggPudQXoOVKJYNuCLYa9epjtp+Jy+wfMXkqqKxsw2FeWqnouiPYTdniPN4cdAEUiyFMQy+EK7F7BFDvwmACpbu9Mepa8YzF+NqZDmAC756r3VgxAubO+A2qAuBuLDs0mW13C5lxMck1As5XkHU2QcUifA+/jIR7OsbqKtBcDUCUIPuxwNDmm9xlyQCM3e65Z2/mpSfBpMBFeikXgsMegemf5r6G0OyaYZ9enF7cAAN9avgigqAerpmQd2g5VHbA0xgosZeyJwvU+tC9Oc51MFYFna6NItyXOGDBWJeTctGDIyDvve/DU22uHA/vye5obcfR76lYb6MAEw564fmjCjQKCpu8vM6gXcE7b6+9FMFdiVRm4oT0PwNzWfQUorRhq454v1HP2rGoVkkYpBbMOvNOXEnYrSpgGEc/qwEwzzXThdCkkgUMmQqWAYOmdVCrIXNPqrSTRiOaGa9uEd3ZXpL1wlUQ1jNZzqKk47ZKMqDhtXm19tWX7RBkA4NPS6T67ZBvKSkLPNSmHtnOqgqkG3syoUoRTFdT5UceYnAowNasRH24HFPVj3xOQa30Cb6o8EPpcdg6YLL1kpGCgB081mYj7HbJ6UoqqQFwBWy/dTIC+UWn3g+qAShaieqgXJxOS6F9XxP6ZmJDkb/w0qAFKsyQw00yXnC6FJHAIE3gQBYS9lfpqLGXI3+yuYyVmQ2MgBPAw4Srs/EwmHnUAqpRg0gLvO7R4E+BEZw/eVOii5oyDTjkqxtzVHmDCkPKBqDmv6x807036GCX6mPYx8tRz4zGT4DQCkJ105c5ZWHG2LkJXxBqOCgyK81AksICFCjJSrpGZmnIsN2zAJGmaMH1nC/cM+o64vgir5OTCqDt5mRqJmg96HF08zZLATDNdcroUksAHlQCUfApoLUkehAVmJks0auu64wi++o7p22o2dP7u5vvu0X7ZbzQpprjGNlvGIDmq20051x+RtetkJM2umrHUDXc4VrMa276a44ajmoBTOXTsGGmluIKMQ387855dF8nupRzS7r2q2IR3FZ4m+MzOzGgJRNW8R2SSTjUtZuR2bAbk6NuVPkxKyIywlViQRZBny5XrZx0vmeu4cXjsk6+vOE3BrtR3Dc52y9Gxc26QMbXJXjxdikXg/Uj9BGoZqAB1O4uTDBlNyBgmf0BOwXn71QkfurE9XCeHL7ahIi4NY3MhUMGvYj7UfQ2OwXgB0XaTwvfmV4ADgNlIpZBTRC6H3sTT0asD7pyJ/M4/ABirLKP9Q+OYFA+t2Y+8WdSrPXqxbLz34wEzpp1zfZhvgvg3NFtysQtyqasnUMuVsY1N14y4lnoTR6J6Amgk3uStbTERFuYx1vkyslMTNJ7lydLTsxzNNNNMF0KzJPA+FDXlmGxXjtVqZGFJvie7qXIyK5pplXDKlhugPVcPOelrXZHE9qywHBXDm/OMJBxGPeSG44hGouaCFD5tthndlcJHGgHA+mM9x+iuKDgmKkV20XpX6hiHgmOhKeETGFb193DEo3M9CM1W1AtVPaTKz7AirO6WcXRXyrmjWxnb58o4jt4tIkx3LeLk9fJyti8WEfrorXKD3fNLLG8Xttw9V87FzYC8LM8ZdirmN6C+eg8CsN/EDNqJWifX0cAWbah/s9jW8O/hRE19kD72TZWeKhhavZ006UwgVdsiEop+9DRx36dpLDPNNNMF0CwJYL8WXEbeWx21csy7wxUEYfubXj1nsA8MJqq67E6PVccW5SZxeg77TkMhMSCcPXY1KUEU7sbOL18lgOqEVJ1q1B9f7xW7Oo5RNaApaDlKNFr3S1t2eMhY1489I8ex6XQ4qslTdjcUwQO2H12Oxq1cnxIjKffWd+TNtyFYHyoB2LaVzM+Niw5RKYGqOdDSjIV9HGRU+NRMvbW9gb+aCFbLzy+S5Z3Q7NSlqlX5jt6r/uDjoPcDxi/dIpA9SoTyx5h6cSUwtnJMU493ghCt0wL3JVOMkYeJXfd76sCutm/P9YsqG1UBAKA5Ez8EtW2v+9E+AMRVU0VcyXQcuoS4KR+cAmfNSkTSISMcSzv1qT+JNnGDuPuFnjEcVasEUMtzNRt3bqMeeNVKoRaMhTxbfxSwvFvGuHuu9H/07oBGVJbj10pgzXB1gcXbJRV3ulYmf3OvqAf5eIGwLiL0cK2897jpQVIAhjblfQRuXOjwPmSvXoo19LfGMBxKHLKXSpyAMPkTU8I43Nu3TwHrbUEcB10MuLUsVg/yGNRJ+6iyDr9fP7M6MNNMl5wunSRwiEwCOFDmqgKDwj2JLe+gbimweZ+xmI/yUO38yiXUVh56TMKEC3dWDhbFpm22+/Ougl3nhUPGfgHsCockyYBBu8qOlCtqxozQJXdO5fd9GzwlhgYSWAgv/G/Z39ZELNULL4yeKTa857mYlsG8EjefKKXdmAhpWcxoagbMCwX+EkjEerX1Uze4SEGtOR4qimcPqk4TVGvCqn9BZgtHVpUlR9orRJp9ApEDYcajyEagehgmwmpZpJQ72/KcPTdI0lBjU3quiUYuKppwlgRmmumS06WXBA5x/8wMxbg6cd3Yci1VvhnKPlswOWrUmYs+83Hn5aA0zxXgU6+8sEsG9KkOrETrLdAIOHaudrsEbHfSn3TcDwjKTsRv3phXVzOZqunM75OwQBoYQcCtWp5LOPsu2Tnl/qEPiIox7ORcr7p5Y2Nb3hmsr+WtiY//kBF65x0EIJyXZ+MmIJyWZ+ZV0bFp21XnIpME4p4kYMBgDPal50UFAIalAIiaQ2BRnYNMIrCEI2yAwjR/gnRXyCUh2e5KJ1dX5Vm23FZBATzaAt5Z7cm6Cz3UIkBENwD8PQD/Kson/h8C+AMAvwjgMwC+DeDHmPnOQ43yMZAPH9aFQI/1YPTyV13nImqrq/Dd/hi9gGhDqoIUhak6QOaJlgUgNHfZrob82sTvkoFctBaHAkW+tztQI2XOdOIzg7elnRb94L53rszjCUH9AJrYz0Mby+KAOiFDn0AKEooKYaL5ZgCtyjiiAnK7aO3CYnwdcm23e2Fl53YvlHe6uFMWu+7GAkevlxyO6UR9AQRFXbTARp4zZ3sHuo9O0Veq3pdLWaQd+MYT8I+pAoM+Z6BZDGzy+zY8PoYDVoRerw8I+k1I9zeHq+hY1QH95oDevFMvhic/rDrwMwD+N2b+lwF8HsDXAPwkgF9j5s8B+DX5PdNMMz2l9KGXHiK6DuDfAPAfAAAzdwA6IvoigB+RZj+PUqPwJx5mkI+TvDrQi2lmy4y1yIOqBpymwsnOhwV2klYs+RhaTS6hq39k4w4KPHkTlJmxzNMwV9G2H9ubeNeZeM8bUQcCIQuHDDHKuS0g+xgERIsq62bQVrOVCMfc9QYgGujWJ0Q1tXUKxIkEse0RdqKWbAWUbBuQcGNqx59T2ye710Lt731GI3Z/lYLSKtrYgnLxdXlOIkI+LWW8iE9G5wCYJEAx7qs7og5QrpKXmQpDBf0qMOi4/CSpCAc426Bsq4bgJAIFXRndtryP/lizDremZqYDkUf6LQYzN+cnUpz0Ye7wWQA3AfzPRPQ7RPT3iOgEwEvM/Ka0eQvAS4cuJqIvE9ErRPTKzVsHKkPMNNNMT4QeRglpAPwpAH+TmX+DiH4GE9GfmZnocLAlM78M4GUA+MLnVwfbPE4KznY1BQcTVyehc8EEemEJ62GBs42Y5JT7+0pEHiBypqTp1jzTlCsPuerxaQySISUgTtbrlGrNK5UccjYJwPoQMyIzg/qmtgOAtrFrg96r6y1PGKleLhyeth1YOLVxYOaqswtgil6cna6eWB9hIY5K99cVkzgrzkJH75Jx93hanIZY+uRUpQnT/1Oy52SVeAYnPckzGQwwZFCoUkHZoYMxAB8k7wfvC3ajRCoAQJuIeE0AQXnv7/ZXcCrI41XBAbbMhg/0pNiAgKOPCCB8P4/Bh5EEXgPwGjP/hvz+xyiLwttE9HEAkO07D3GPmWaa6THTh5YEmPktInqViP4EM/8BgB8F8C/k35cA/LRsf/mRjPRD0KEVcOqz7aWALat1gHCaCwawFWzg7e5a+Z0aSyY5Si46ybE1+nnApORj48sF7HZFOoiOE4huaOcowAoNKibAbJYCOI5XHjTX/VEln2yPYOMYUt0HQPp7GECqW/dVEtB9ba9cPSwXFZvoa59WHFSkFCwXVc8/FgcivW7RFmkAsHsju2dRqYO5Sicy3lqYdGnvPq3kPSaAxFqjsRTEB6SDKQ4wPTc9rmbEVQLncfKZ87TEqZqM4gZPCz2sTeJvAvgHRLQA8EcA/hqKdPFLRPTjAL4D4Mce8h4fmh6UW9BP/mm24XVqKiAoi4EGDW2HFimph5cCOFTnsM69AwqOVwfUW80AqxhBjQByjWaykAvcYkDe51xBIxX9M1cAUSewV3VUDdDJxBUw2/O20/4AsHrZhWBjIQvcob32NsZdVxeL+0XMxzBU857SkOyZzdypz0yhvg/tt23rs/uF0i8S7tlHfhEWhOT2m3Hw194+gEPxPt5jcK/2QiJjFupZ+sb6Os4lMCpLIFHiChKGAyvNo44jOEQPtQgw81cBfOHAqR99mH5nmmmmJ0fPtMegrqI+cnDPMYizeW1J/gu8nq7jrf4GAOAdUQPe2JTtebdA7oT7LETszOQkgPdHlnwT9WXnNiCLR3lciJlMwcCuBbUCuu1EnFy01SS3UG+/oe4rVzQOm8AK8Km43EZTB7IAfiFl8HLMeXmhnu4AluK1p447y0WVNsSrkX1bVRGkf2IGax/aLgQbt/WvEsRqCWRRB1Y1epNWWjFUzi0WYFVzVEpRiWCobFw9NXMihMXYY5Cykw5wQDrA+JTPpmzkL1epQP7gAwec5iNpcLeM58Dn4k2FKh08Tolgjh2YaaZLTs+0JHCI1EVzJytrYrbUj+ogdHO4hjdFEnh7p4BgOZe8OZAfwC0OHPexBDWhhZxrgquTp/qwAJBNU02EbdWdTW9WPb1pTFdn1aN9X3ZOxxGsP2gijqOF+dybJNBWvZs1rZeYTrmNoH4xGreBjctFZZoq3bhn4FyBzSqdyPMp128iaLEYP3tq7X2YhBTogWF4U+es8cm6a9WRDun6ND42uk6dijQJaSaDLfpe3MxzMFPzg8jnGngSzkKXYhHwFoG1iI868U9zfcnfHl4AAHxn9xF8e1P2T/vysd/elMR7GjcAVHAeo4XBbrpP7sPSD0kDWvIiVt+BTsv7aihyqhNMbeWrpU02UkQdAJ+UfdoJan60tN8q5mvIMbc16Eaz90QAw4moBqKqDJKMJG4bJElS0ojdPy8jGlkkLP5gJRN+2YIkiKbGBDRIR6L2rGsGIA18Mj8EXYCOFub1yKICBKL6XKpurJYVVNQ+dDFqwhjAnJDP8lyB1PdZ4JVcwJAnDmxYa9uWr20VB3SyCJjIf6DLqg74Yx9eHZiTisw000wPpEshCXgwUCWAe+I4fs6NRQq+MxTR/w/OXsLdrnDUm+clDa9GDA5DrNY0lQA8109VnJzWEXhg+qpAoDgxj6mqsGztmAJivKqAnHJFxAA+ETFaALYsXJfaiHwsoJv0lVaNRRYqh+cmYDgSqUB96iXkFoGQFuOB5zaAWO4lHDvKNq/injTBkZDcPlBA0Rj0Xs343qvWYiOyRDAikqkoQUy4vGgMCGSRUiz7sFdn7B27KELj5hhFHuoxu3YSLswEyzk2La3ugUHNSt3liAWNJVGgfj5xYiL0JsOHUQsep8fgTDPN9AzQMy0JqGlQwcCeM94VgO9WLjr+q/0LeLu/DgD4zrbgAL9/66PWx9l6XEoqp2gSQPWyqyv2iPtPzIWjSj5ysUawcQCyrPaaG98wgsQW06/cPx8vEATo0wScYdsiXRFuL2ax5PR54/DCGYeTZhTJBwDc1xoHyoi0dkHsGGk5PleSkEpUpXjjNeIIlY6CRR0O2scqWj2FKFJFbskiC9WJKh7V31HPqUmvCWZabbWcfBvsfeSjcULVdFSTm+gYwTWK0AN93ysmMJUANIoUgaunqPyxV7Ef1a0ACgYz5cRPumz5LAnMNNMlp2daElDSNM9rZmzFPnZT9P83uuesFty3z54HACyahNv3j0d9JKkmw4lM71eJgPqqX2qJasqV8++V84YzDcbKyazs+FDz5dszLMampXTSIsj54aqg+cuI4aSmDgdgnJsjWZ08vWdaEZiUy1aF1wp1qmuzjRFWq08fJi0IJFzeEqvKw/XHoSQbRZUmcuPSlsu5tCAzsVnh1bU42KwIbUOj/pkaqx4UJPV4aoN9zEkkAZZc72kZTRJQSQPs8AGn4xsmMHX/rozdlaR38R72+qopUjMLqUXpucUGV8M4ZiABWFnUYBhtnxQ904uAmgY1MOhubvDdoUz0b+xKmoNvrl/Ea+fiHXhaQMCz05V5efFkwoNRFwHdJDIx0Ca+BwaFHlS+Ki/qQtLzGDjLDZn4q5M6rQKCiMw6uUMK6I80z1+dYEAR0XWCmSi/DGjFjJZkcoS+VjaeFhgdBcyYGE7IEsWr9QlUwOyPye7fa0XkJZBkHEmd/poKOGpuP22Tm2q+VPE92YIF5HZR9516AcA8AtNRMD8BzSsYElsJOCOvDkwWg719fTHvVZa4YVMDrkiOwecX5zihcf7IBZGFcT9pNUBpVgdmmumS0zMtCUzpNC8sNPjdvnD9O7sq9u+6+jp40Ai9CUfIZCK/EvXVO8xKajP2OYfzOLPyXJqYJJJxOiuKqZV/KBi3t0Kgx8EqBPUnwv13XLmxcXuyPi3PviXDrJ6Lo2Hyg38DYxOnctS9lFzRCVDSJoGQjHmrmA8TNzTSVu2wRU0Zi/LkfPa1ulOOsLLmKlVofENqqQZOakoxUI2g9M+lDlrTBKKuBLv9XYN7MVaXbfRoe7Salio6QGoafBLeguV+M80006WmSyEJSKVs3EzX8N3uIwCA19YFB3j1/nWcnhcTW3+mOcJp7AoMWBFKZFhaaQPyEizFmJcE3rOUNXluKQAYu4SX4n+uevqwqty2N9MZDGBTzpqWZNdMK+kAVLmnAWz+GQTTSFxrIoiJLe6UOzJCX/dH78WRShc5khU+0DFSU7EAy/HfuH3l1DrG4DAAj59wvRYo7ztbnISeUzCyAo+GfRBXyWsSJ+CJDmECChtksrwNdrHhRWwFSZVaSpaDwtd2mjoJPWp6P4niUiwCStvc4t5QPAHPJCZgvV1aBhhoRVlyH7f+wVOd5HuLQFcntU4Sbeu3Xj3YS0LhJuQ0J2GpuCvH5OvJjRdZZdKhZjjWdrXirr+5jDXX4id6XdxlKyfWbNOoj3Co0Kfr1yoWa+6SxE5srwvPoUk3nYAWm0UOo/PvR/vQWNzM+zZ71z5PLQHeY3DvqdxB2xLoUEtbELSZHBgCQiwg4LmEf/sSdko9M46fkNj/XjSrAzPNdMnpmZYENGbgVGTju+kYt7uSu16jArdnC5MA4kZNTDyy9wPO/o/C+YHKaUJHThKo91fOuM8tHNil4myqgJlKE1LqAJRgXnaKK6VVLXWu7eK2Vj1SyUUlCNpWLujNmCryqyk0bpOZ08Km3KxRz8W8n46MoxPNNQDQJB+yd5Am78C3y03F2HIct2NXXWwk+k/bBRqPyVFaAMKUR2bB+u5rH1MT4VgdmHgK+HM0bSPepQCyRK6epSU64bv6Pjw2+aT9A+p9Z5pppktNz7QkoKQ1BE7zChtxeTvfCsvcRVAnOm+nej/t6fOGCeTK7ZWzxq5ypuikBGun+n92HGTCVHzU2cFzSp6bk9uXdn7fjx+o47FCow4EtDa7wR4maN4BrWE45D2HFm7IzGqxG58LfR1HcJYxdS4yq1qCIWUjEyvGkgMm0gJQsYyyP9b7q+mSkJsx9sHu/Y2jO8dAwV76MIz/PBYDogd1vC0jT0DT292xJbDtUT6UFmxObeq5+n1VkPT7hdRVOHPAeiiTX7O9hE0w8TtuBWBrzMcUlQAAIABJREFUPApe+vAfsYrh+pHFHUDt/jl13dWP0xaFWPvTPsLABl7FbuztF3rXTvsMNNoHCshnE3I3Afw6tg9bz1FmBAH/YAlNBgTN0itlyIIrZGqVhDVhhxOhOTb2LOXZ4j6Kn+t4vcnc1Kjp4hXH+0BZNEysN4CwXnuwlJiK/Koq9BVI9Asl5fdQB4htNT+kIdB00chAkJJkMcgk52Bh64jn/pHKc83qwEwzzXQR9ExLAjWjcHnMdV7gXCSBQbwDY0dVTJYtDRXQUvF+zLVEnG4qB1Z1Qc9RctzebMmwc0o+9DhMTIk2nlylAxU3446tHzXzlfv5fQDuOZTLReH+xLBCpJpjUFOPAajlvLQIaddbgg9N2BGbYONtWpXDy4FmG4xTNttqItTxGvfsq/pl4zYz4/67Yqc6jcyoU49FV2Z86hl5sMAo9kHFkeqh6OVE4ijXTd0sgdVR+XjUNyBQxn1JghLl5uPkIuKf8YTVgVkSmGmmS07PtCSg9QTOJf3VkobqrCELd3tGxq1Un+cINKVWJmhQrlZ+5wbmsy9+R2g2bPtmtnNmKWjlKWemUs5uuELHxhlVZ1eOEzvGoCY86WNYEpod234ZY7boOx2jPlt7VhG29qzaMcO6DNiy/Hb1nCYr1SzFtNlZxJu1C7AEJpb4VIc/cq2vn5o6I5nXYa6S1sBjj0QQ7XH90FevQ4sd8Oxs6oBHtT8Lk85j/d3oPQBBfq/+9+6lf0Q2LOD6Ufl4jqJ777JdEF0YFjAdy4ciIvpPiej3iOh3iegfEtGKiD5LRL9BRN8gol+UEmUzzTTTU0ofWhIgok8C+I8A/CAzb4jolwD8JQB/HsDfZeavENH/BODHAfzsIxnt90it6FY3QmHrkTJeOjoFALy2KrED3fWMuBGrgMXUw7iDSgCGA/SV+yjXp1wdiJTjhIEOYgDa/uC++u+r7t7Ve1upAC1kymQ5A5Tdj6SJ7VhHbbapYg2KAzCDtCio1gDoh1rjwCr4uIKkWgZdi39uGzsfNKGnPEdsK49RvIAD0DQVHyjPN3Y1LicPvB9zDKrHLEVYcCZBjT/Q37Sv6/sUbz7yz1/j++JQ2yk2wNHjEPpya1/Hy/Juj9uyvdFuDAvQ3CZPgz7+sOpAA+CIiHoAxwDeBPBnAfwVOf/zAP42LmgRUJt2kle9DD22kokmJw2/pT2bNKUqruu22dQ/vInr7BJ46OTrVUT3ZsWx6S83zozmzIJmztsKQDSQ/VYxNu4kPHYZbF+TacRdQpLJpuCfmrriWU1mEe4V8xQ3EbwpqxyxyNfDAOo1jFplbTcTJ8eo662KMZ2rn8W4IChQF7bi2adujXo27uVctN/uCyVvZpx6DLr+DlaC07+tt+dPbfuepj4EFf/cVwEAKz/H7pm3nWR8OhIm5G60uKAEIofoQy9EzPw6gP8WwHdRJv89AL8F4C4z6+f/GoBPHrqeiL5MRK8Q0Ss3b6VDTWaaaaYnQA+jDjwH4IsAPotSXfEfAfhzH/R6Zn4ZwMsA8IXPrw4Gcj0sKeByIxRudyOu8TFRB955/j4A4PX7C4SNOsAIqAYXijsRC8fiqeN0Y8m8hBLzuN0IMJucA8OZyURK0OfoKooVdnXBjCLWE6vj0wCIv3rcjRfWsHVprVSUHxJYAT4p58XMtey4lQdX2TXU/WkaLr+vksOQqsTQ1/Jp6qVoTlQuOjFMvOxCqlJWdineqhOPHHImwkOegIe5t96kthmJ/9hPmKL3smOaFGZiPgSAYE5C5eBx7NAKAqrdPe4w4g9CD6OS/JsAvsXMN5m5B/BPAPwwgBtEKrjhUwBef8gxzjTTTI+RHgYT+C6AP0NExwA2AH4UwCsA/g8AfxHAVwB8CcAvP+wgHxUdhx2OBMFrgiJR7Fb9qrfWwpQK9DmOrb73orMXl1/pTjG34E1gY7MXZdr38efK8QzAGypQqJw9dIO1V4DPAMVdb/q4gX96m83OODXvCqJJbVvD2FzxUzMX6nBchSMrCqrFTVcLqwFo5cVTru1NEvASjCRSNZwjOBfesVDok5b4uII8eVd+wCNO/R5E7nX7Pt4ztdqhNtnddAoQcs0yHFynWoGoVh3aJ62X8aRchj70IsDMv0FE/xjAb6P4pf0Oinj/TwF8hYj+jhz7uUcx0A9DmqvthnP8V1vtR47OAADfXbxgWYGyoNtpCUT9ntV/X3IOxi7vIc1lwo/vTbl+ZdNyZJQdaOazGE9VBPOjr53bZMrjiWXntGk/XgTQD2bvt0nauvNqEYjBKhnrQmgBRGj3KhbnZWu+A1nKfwUtB9YE0LjWBmjIddyq4nTZ4gnU98GSoURnRWjqe/HJW4BxbMfU85Iy9t+te98PJLcImMpnizosBvpQcVrdG7KGD4e9gqQtkRXHiZPpmDg//VWJmfmnAPzU5PAfAfihh+l3pplmenL0THsMTumFeIarcTs+6BA8bqoJT3PcpYm3H2VCHMYshBJABhwqCFhF/hoyW3ZSgHnImbUs1YQdKhKruEzJ1wLQzthMc1DJZEgmpqs9X0uaIyXj8KYCLNoq8h+vrI90RUqAd6X/QUqbxV1CkqKgGmacTloEEe+16Ed7KpxvGdGoNLHQJIK93V8TmoSeLTOwvnd9zhyDvceRt5/Kyi75iE9SAjjVjKpq5bMUJ1VBvHg/CWlWKtJbvRYQIUGlAn2R0Z0TUnUgUkaewHAJbBLroZLkT4KeBl+FmWaa6QLpUkgCK1mmb6Urlmh0FTWzBRySVEEeAwu1uKamzsqw3AFKHD3oJ+2SOzaNDhwc4KiRgnwAFOuVzXHVZc38RhV0s0zBGZzrNaMtUNlVowEL0eIaVO9HE0zvz1ou3JVAy1aaXJyuIgFWQLWc0YpBvoS44igU3HMOms042TgbMdeOog9tX8YayCIRDQzsajt7pw/I/EyZD5sjSTEg6Vcxzo72JI3yXGPbcHIZjJNgAb0LRVRMQKGSiBplmunxJBd5v9Lkl2IROJcJdBJ2Jprd7cpiYEVGgKoWEO3biZ0rahxXkiqlu9TmbZl6Qt3Xar2b6u3XrEXUlmrAzflQPf/W5QZ5KUj8drBQXwvvJaoivwF+qX6F6rUX3POpqqDI/rIFtBDJUla2IVvJM00uomoJuiqSW5h0GxDEi9DGL4vXsIrm15CX6stAzl1YLB47sgQm9Z3qArdwoKv+MRgqxNrieOLUAU3wolmeYvX4tKrHu6p+qaqQFjVRiw5SF5S0rPtmyRiq+hKsWApG13vqOSLzOMdgAmMZLlYgn9WBmWa65PRMSwJqXrkqK/5pOkIvLP1KK7bywCby+doCRpNEFbkh5Dj2ACz+8ON7U6rBPMZdsP/b5/jbS23lPBJN9Fcf/CFVU5/68w8JpCx60GwiwvWZnau+AoTV7q+FOoiq6K6pxMxc1wZXx0CRyvH++BxZv97cWD0nq1qgZkMFI8lUhfp+dJ8DVb8NlSoGjNSt8q7kQu+9qX9bovouqbY34FAFE6diWJCTkwRVOhgFnwHIy1qQNKBu04TvRiJTB+aCpDPNNNOF0DMtCSggspaV9mrcWCTX3Z1iArRfbcj7pgt5LzTjdAYGVscg41aRTB8mAdai5PHnRUA8LyxD9f54trP9cC6JPkRPp+2ucm/1+2cGd4UlkXLn3a7q+720UxAwTWxeSmbSrNLNNKTZkoYMXMuVqddklxHkPDTsuvPcu9xX7x62gzkVQcKYaYigdbk46D3lORuggqFB/mZE4DD5dNmZEieYgE8EU02+uUo/XmJQMHHi4BWSkwAcSGy1IlTHX9YhJbFBboZywVlamiSq3XfMaC84onCWBGaa6ZLTMy0JKCZwLCvtea4r8fNLyR8W2Rw+1AmEBld3QHRDr2fu1eQb6Zz1nFXyUT1XdfgOBg/rOSSuJkHFAoaKA7DyUs/RVe/XGorDAPQKZ+dxG+ZxXgCg/OYxt0dih8yLXq7p14dcazOozh4A0gKmiq2ofu+ewRxgmEHyDKaTw0cbqtnBxRwodqBSCHndvmxCQn2WNMZUKO9zWg7VAjSNFB3tO2PBwRoEhgtN+2cEEQ+WTXmmEkXo3g2eTHzApS5IOlUHVs6R/eb2ijSikW1ft1Nbs/dNn2a4CaOJrxOXEDelE7WVk/xGE0CbIluymQF3IHEfrPn75OtMCWRfrLP/Zx4d45TdhJmI/5n3z2W3MJivQbKkIrpAKajng5L02RJaO85qWtzKc2dGkDyFWWXorgfpvo4jNPsLlC5iOdu+qh0eGPSelNWUKAusa1NjBuqCwFPXPDpg2dPFPTvfAR9PMI6/qpc1bO12Q/kb9zmaOjpNdATU0PcnTbM6MNNMl5yeaUlgqg7cTlewESTnaisoVmTnRVZ901UC0JRgJton76EnN8q8H3LqPfVMrNc8fmxcUMucH/T2M27IUCiJVdIArA8ecU05ZlGK2mflqF4isPyAmll4SDWjsHB0FVlp11cAUSSZyGztLARZAb/EIElmYlWN+sEkC0tLBtizq6pQq5BOVC8l7U+96wYvCYxNvRSxZ8IdJQlxasGedCAUBuypiL7smxVjPXBtG6tUFibhphdlFvQ0SwIzzXTJ6ZmWBBQTuCfc5DjszC/73Y1gAl3NIGn6f3IJPaYSAddEo+YgMji3YeH6uQk1bl5j8BX0CqG6/HquaM4/E/2YGQgTCClGwwzInHpCNQmqKVFNhlRTg6mUQJkdgKiSyVCdlTQTsdUm7Ks7sstSbGCeSjeaymxIwFacsjTHwHZXIxcFtDzk2mw2t6bWJh9xaR2jSlltNLOl4mD2u3HORUqMPWCwZCCeuA0rDhBdBudQ+9A6Dz5iEQDQMmIsY1NMYJ1r9v3gtmEiDTxpbOCZXgSU1GPQikECuLKQfOENO3gY4y2cxcABREpmCaB6jSUcIdSgnA9KmthDQ3512zYWEkz+nPoOaGmw6HIAeq9ApSkwmJJZE6zfrq8irU5gvXyzrcVHxa5P2fkrLMpHzqoOEB32V8gPEPUtn6F6LZJZb0aLAI+vLcCgAoKwsZXf1Y9jlBdyWui0FmR2wHBlBmEc3iDhy9qfjlctO3WsSb6vzGQpxyeR0BdKszow00yXnC6FJHDu1AEN67y3kyQaB7zEvDloxE2kvdrRLclFn4FWMxYLp4zBzG681PRcQofAp0B79iaTJNrGfPyxFG7bNqCVPIPm9usWdr562bm0YVMQKnMFGkUd4K63nIG83Y7GzeuNXarnEAjYaRUWaam/Y6h+Crr1Zkz37Ka2xOm7CjV+o3HveBpfwTUmI1t59uq9qbUckvwt4i5b6jhS7YUJUTWyZelLPQ1zQ1icSx9yHfoqndSithJSTABbLQKS/p9sodEPSrMkMNNMl5yeaUlgGkWYOWApLH7VKEiHEdCjVPOMyLWaFCPD4u2tTRNqO42aCwTWZBvRcXSgcLEwOZZyTcGlerfG+OfqcBSktDqaaECjmeYWbc0ZMNGtcchrjBnIkypDOVWubRGLzotvGHv0eackM0t6SWeKTTSNYR+GQ8RYsBn3Pliz8i5i9bTUbgP2pIkS7zGJebDftZ2X6Kzcu1Cz885Ck3iSXCW/GkdCeyXP8sJhDgIkLcRE2OdodQcO0dRc+CSSjALP+CKg1oFePQZDj6XIbYrYwvkEKHkXUfvjNlX8tAIVKjZHqoCgAloN1VBcza6j2yYgSNkvy96LhduXe0rgUUBdeAyYa0LN6qseiV1fFwQpJlLRdqqT85DXoZvULCAeK9qvHn7M+yqF+1BHlgigTHh1Y9ZxpbSf0nzZ1pBnXQgb9+7CeCH2U8NPfLMGkFozxNMwZivUon/XuE0g+ePWpCK157QaJy1JC6rAoFgEMjGmLobksiBrAJFWJw6UzWtVJ/yhaR4Oehs8PprVgZlmuuT0TEsCSrrqtjRgJ65dVhDiUPVKqqY+n4EYAIipcgyNKO7JACLl2DkSglMNAIxy9mtKMAP/UvU1UHalab0yB5MqVDrgGEATUZvbpnL7aVGRQ+XCPFlZMcfZrQyZss/ozJHVZMms3Fu36lwR6rGROiDPoLduazEuA/+83d0KwWij/eF7cyNNgUdHFgqduFRqBixwK7hUc8SqlsgtnbP/SB3QT8FMxHWMWXIMnneSrZnYio94uuhSZLMkMNNMl5wuhSSg+dxX1ONaU8xcWjMeTd4rOpmb6gtuXMgt4LpvUYRdqDhBVyWCyr0luk6i83ITENWzUKv2oCbjVK6tWXsDUc3yq5hAGxAkWYWCkU03VGmjdxmFIZx7ytmb6ByUpP0wGJ5gHn1mdkyglWAZynmPVqOSZIDDLZaLyuFXms0jgFcaRSjcdlkrG2ldAzW1plWsOvtK32OVmrLDYtiAu4k0BFSAT5Oh9KnGdPQuWnLibaiSHYLr96gChCatTWcSAY1IRCeL8q1dbbZ7sQOentooQiL6+0T0DhH9rjv2PBH970T0ddk+J8eJiP4HIvoGEf1zIvpTj3PwM80008PTB5EE/hcA/yOAX3DHfhLArzHzTxPRT8rvnwDw7wD4nPz70wB+VrYXSpq+aUW9YQG6pcim93OrfvxuZZdDPm2UpSPT5kN19LGy4i0hKefXOPuh1vhj4zDKtWoST0XGzSwZqSLj3gQZx+PgJhjWQOFA/1PTnI81MPS+dfvCvcUZiZjBui/vgpe1ipE3d+pvNRsq6k9+XzhwboJL7KnPVM2Newk7qA6g1gd0tRnM5KuRn7laEfpUt3pMqilRE/edrNTcuIoWz+ArS5lbMU8kxsBmHbDitxjntHha6H0XAWb+P4noM5PDXwTwI7L/8wB+HWUR+CKAX+Dyl/+/iegGEX2cmd98VAN+GGopYSUmQl8p1hYBC1ohKNalafyt0GSoZqNaSTfUjzLXSRqW1dsMAPJOFwVC6CXXnBPza77/6ummW79f+gimBsDOxbq4qL1dgba2qZ6F6nW4WlRPQRXlc7YqxBb0o7+ZwcduNQSQVwubc/lIQFfNwX/U1nMrp/YsVEWRZ1k6M6CqTuqOEAlRPS/VO495DxvkSFbRgyfehJnIAo0q8JhrO/W3AOoioBmRpH8asuVyrAFnjD1/At12AX2nz8zSZV3NOnlHJ0/IF+BB9GFH8JKb2G8BeEn2PwngVdfuNTm2R0T0ZSJ6hYheuXnrPZJgzjTTTI+dHhoYZGYmmubm/UDXvYxSyhxf+Pzqe77+eyFvgtFVuRGZrmkT+kZz70ubgUcegoBLGsHOd1xI/czLtcKVQzU5GeC4qL8NUDKRP4zEf6Cam3KkynB8Xipt59QIc1BqJtu2GcciQEyWq0XdB4BFu99O79k2VVw3bz8CT02VagL0Jc1MIolV4tHnIGdGdeY3PaeSlFKOtGcmpMQWkkdhLDn4Yq/mBenMpOzNqg8I67PKSRYfUh2INHbAxkXAYlkOapzKtWZrOS6VejCWF2yk+7B3f5uIPg4Asn1Hjr8O4NOu3afk2EwzzfSU0oeVBH4FwJcA/LRsf9kd/xtE9BUUQPDe04AHJFmeMwdL7NBJNOHQRQP6DJxyZcWVRllljSuXbW4d18nWxV6iidhWKSGpU5G5A8Pq2una7Etx275KGpGQ41TSiFXCUPObgoFHXN2QLbqxrVGPi2qaMzdkLzGggGmmU/cV+yAFMmUblo77Cxbgi5pqJJ+BrotgCTir85RLyaXRgWpl3GWkI7lXV6MDq94vz6nl048XNZOzRSImk1g0NoHbuq9kmZMTgyQqsboUO6lQMUl1G05AtyviYzwpZumeo+UT0Lt4Lqzuwk8qZkDpfRcBIvqHKCDgR4joNQA/hTL5f4mIfhzAdwD8mDT/VQB/HsA3AKwB/LXHMOYPTVuu5YS1IARnV3xEiDIc0Fe25ljI2EerA+0tDIfbuR8mgpZNbnz8wRh49AvPIecydmqBLgyWbUjPUY1lMDXC9+XiCSxRRhrb0TGk0X4550qI6WLhUqVX9Nx79O0/w94zjTwcZeOSuNAkU9AoDbx577kX3kzeR4w1RFnbeQvNhPz9ashy3Vc10JcoU+tQn8YqAFALkj4NOQY/iHXgL7/HqR890JYB/PWHHdRMM8305OiZ9hjMwhJ6x4Ws+IOLHbBUUrqaD84WfMBwYRxdsSb3Fkn3GUjt2OddcxKCa8SamiLRkAtV3VcH6g3q1jzkXNyCHVuor0GNhtuLamxCFb/VLk6EQ6m7ygVci5S47MA1T6LWBagcuIZdO/Byr6hp5YaWxEVF9KGWc1OK6wHhQBn3eK7JTYoZ0+of+HyPktiLcq6AphAT7QtaVoIt12IslkCG0Mj7HjQHpZiS4yYgXRv31h76mHDx0sDFGylnmmmmC6VnWhKYxmVvucVO2LblE+hCrTegCzXjvYHBCEN1zFnI/sPIaaQmJ+XxueyOuZJZabHvkWa/p/0PNX4+pso9NZWVjjGMSpqPqw2FPlfODkEx+wHENT/B/9/etcVIcp3l769r32Z7ZnbGM+vdxZfEtmQLmVgWsgUiEQFirCgIiQdHkUgECIF44PIAtvyAeMiDAUWAQASLcJXjEEIAyxIKTojECzE4SnBsJ47XN7xrrz3e8czOTE93V9c5PJz/P+dUdc/srHe7ezxdnzSaupyuOnXq1Pnv/w/AZSfuZc4jUTIMx5HzEBSuQu45CLxxczUPbCkzofpQzqcf8lveD5SX4k24D2VKucHpHwLPK88+k+c0ZDkRGy3pOB7ycioItQ/6khaNOcdB7ByIbJKTwM6ZaFfegeP+KOJswxzHoUDIS3MyHxkSOVlUnECFCjOOI80JDLiIZ4cX274OrbNGPxdqR1ajW6g3KOa90gipEJCCMta5KPOsAgwdYNihxXMkse0ksE/BUS5xG7b7jpLZ2ISQLEWyjjiZcu65TMFsZGLX6QTEHVhR4Nxk4VFxsZZYCu90AkM1A/1nLjlY6dCXxfku/dy6Nku2n7wWFbYBJ89DRwh3uG6jRFzu9JzZstOzfZNtm+uAqTklkYsUlPoNSrmoSvsAevQ22ELCz+7rKCSZadaUuBC+fKSh2VksZ3fhXAfIxfyLw4MjvQhIaKawO5mOoEoZYAvwzYDl+RG6NhJXI8f84CLl2Y1VXFQW2cQkfr592VTF/HdAcb/wG7BJzCovXTtbUbhcbdhPJSaPsl/e/71QzogcBC5hiQ3hDYbbM3yznfWt8M2HNvuxY/PLCwmygdOPDsRk6YkDPssPmGe3QQzy3zOF2tRqyrL/hYKoKCoNR5kv3YLtjgeJuVYac0o7FSFBuSox2VD36BJDPy5U4kCFCjOOI80JCDLriaWGfLdphLOQDhxLq3x2HYb6W1FBLuWJA5bBCD0/+DJXQZ7yTxR4mbJchOTIFxNW2NPWXBgyK6rCwHrEiZkv3M2cVyCXFSdhm7sDryioFFog5xBkTWG5NS+iTFGJbMyADRFOQ0D6xPeWhCk6JKDvKyZhyphLNOAu91+FCNi8R+K5KKx9loO42pENae5nLrOxlHGPQqeslOfjfcrCYW4iz53Dlk/1/SSs3n9Syqs25DAUsSgem6lGzMrQkJ2/0mBgk4rUvClXmQgrVKgwVRxpTkBMhDEL2X0dQrFdL+G6AzrUNo9AIbJslKIPTN1H6AusQsimJXPFKkVGHdScKdI6BgmnoYcdkwpOOuVz2pVDtyK1dok1CimzwMrAvEThC88gAQ6BSznmudOa/+RtO+ciP4EqgOK+TUPONwqHqR7leshFuWCelNqG8oNe3+khyqXMRz2fpw9xtQUVdFCU+ylX7nqqyMFojwuwsQYIhpKaSnwDDQhJMlxjQOafUH/fRCjObZOuU3SkFwFVCtZoBj3LjklBCB15dQQ85R9KLL/9CD1WXnvegXbb8yK0C4ItVeUUhSrZ42OAVz6Lfxd1cxtwJJppFTsW1zow9r1JNyieQz9zH64ov+Jw+IPxMiFTMLwYuKQczutP7Pf2Q/eUkfajlt/1B7YKb9DjD12F7qMXJZ334duCpxKiPBiYDEiALaMGYKiqs1Ua5tolDhERIBu4Wgd9V5RVS0yE9eOQUtUAZL2ROARymaclkEhJduqaQi0292zXjDhTC1xWIV8x6I5NRyyoxIEKFWYcR5oTkJU1lcVfR6iHZjVuJ6xsqrmQ0rwmrCKByrWjPfOh8jgAgLkA4U4T1z6v86YQpJpEmmkMpK69cJ9x4EW1FSmCCj3POy/KrdzOKPrKFExEEFVkewHoUcbqgkgk4cIeR2BLnzsRQZcVWyIpeExG4Png24cWqqu1U+KJwlFKmhPZc0g81l+eS/ro972s3Bs4G7+91mAA6jE3I6XV+hlsWba8JH8pb7yFla+Fdi4MOAOxLUMWKWuRbUaGk8l1MJRtOJiyUhCoOIEKFWYeR5oTKOsElsOLaIcmwUMrNiaopJGh3zZkP9pkmTPVCNkRTSh82GWqETnfd1n1KScrC4a5OzfkJGSpPhW8EwGTikyVuI8Cpdfl/9pr51+oNAi++WtQUnrlLuPuKBc2qxTz9nWJolIvd372whzsMhXPnRefNe91+05m74mrZuAov1BgkeGjEVM0CFGoaAQY6izcSZkTUMrdky+hcwWy8Qyq2J77ZK8LVnby+5B6EComZA3TbtAyzfMaXyvUSLjuwHJtGwDQjjo2qYjoAqZdfQg44ouAiANzHJrbpAw3piYTWshs2fZqiu+HywCA3djkgqNuCMVegJIpxir5FAqVZ8057VUoFtu6sTwA7uPPvFr21g3YZsgNLJfsshTJfVwBjiD3vnKbIKPEtvu/Ffa2nzmNuijdgsCxx35gUImtJk8DX/BABAfa8DUKSkgYsYN2xd7PH3Vn1xU3kX6EAdDr8fiViqH6Xo2Rl7ac/RWsdj7wRJV9y6x5YoS0i1mGSxNbaEU1jSwnlo7BfGqVgNmcOdabC9DncOF+mxfMlul3rdXH8XoHALCY7AAATsfrmOMXHpMUmw2mVnREUIkDFSrMOI40JyBzdbJKAAAQhklEQVSImRNYCTPkyZsAgEZgKE+2ECIJDZV6pb4IAOj0EvS6hlrlfRYRupKPjkZHf8hy6sUCuOSCxZgAGhCCXpFaRbsuuUmyKco884NkSyPqSiyAy0kYlIuPAkW/fR/a2eIt653EzvwmhUOygcskbMWHEWy1UPYwHA45ZuqPKITudPj6TP23d4C64bh0x4hmSFPoLnMMzWLmYgoD6JRLn6UsUkQhdD2x9wC4/oFsS6CRX+68bO4MAxdAxHUVVCO13FS2YPoo+RD7x0LLDfZbQv0J/XnzzNmqGcfWvHmmk+1NvH9uDQBwW/0sAGA12kCtlFstJJpabkFBxQlUqDDjONKcgKysKZiqBxrXcjaK+cDoBo6H22iFxlx4XWMdALDebyJjz663u63CNXMVQMosdDlZaSPu23BRObe+20CNvRJjdkySCMbdLB6KZtzcrqF70VCkbod98FkZGW8GqK+Jb7q5Z7KdI+hLLLP5p1OnIRSZ2ZrGtHbys+9U41N5aVeKoLPmMt+jTsx7/cwpCYXT6LL5NYqgd7uFa6jdrmOamAtBGDougs+J6Q9pYq+ruBgqlILioqYSa5DXY6hBseqSjMegEduYC1s7YKBsmLUgjwPkdXOssyTKP37cOmHQMNv9BfYAnc8QtgwXdPr4JgDgmsYWAOC2Y2/gZPIOAOB9iZlrq2HH6qdchOv06fD0e1ChQoWp4khzAmXECDHH8nOsxRmkgx+smcppy5FZxV9P5tHhJAEnahdNe1bxb+ep3ZZUZWkwsNviG561AuuYJFR/UA5IALDL7q9rrRYushx6YduQnN1tllXjxMqqNoYhDIccmfy02NQT7TrL8EnidAe+WW2PFNv2PIoa+nJefqMnKJoercVBaWjZFk28ym17awGAcwmmhGV9ed5m3T77YKFub5vNFafuoO4cqrJ60RErT8iVN5fkr8qZbuW1ZC1CxozfoMHafqlJmSroJltBaubCx1pdrM6ZOXOquQEAOFEzHMHNtfM4GRlO4NrQ6EVq5PRTEjsQgKamCxDMxCJgA4koBLvvu1DOIMfxwLykbhhzuwG22N2vw7bCTd5firfsdSUseTuv4ZrkYuGemYqGfiOLR6ZDZDwDxZ98q17D6702AOC1ZAEAsF43i8F62kAvaHB3/QnDZib5zhRcSHDGxUGl4m4YFAOBAA6/Ff64aBcHMGxvz3OnNLQeiYH1uKOyec/fzocnuv3wo8guTJpNc1ICbbDQsBmL+/O80IZkg7HEnJo14QqviDlXFoWWZ3aVbucuGYyUkdOBtuZfNc8ffGx+ECc5Ag40W5wzJr/l+o71N1lJzfs/kZjFYDXawCJ//JJkuhGEh0oMEByenlSoUGEqmAlOwIdN4CAhnVBo2+guw8ptUB3zzB1sKEOBb0rPAwB2VIqYs4psKUO1mqm4Fxr/cNMuwXXMn5Zr0nd1bMtuCXewpWpoR+aeLXZXvNgw138uWMH5gaGaXSZfgwZBvcnP0JNQ6NAWQbXJSjjRR5Q7xaA17yWx2xbzW547RxxJ3ye5CbV2HnRiKowxOnQXsNQc8Nj8fgZqNuw2AFB7zt5zcM0xfj7z2+5SbNn23jzn54uAvMa3kpiNurbOWYMmj4eYZo9l0LmYHFl5mQeWyisesyBSIP7NcttQ+5DDjY8l7h2vNAzVn493sRCbd3ZNbI7dlJh5Mh/sYo7nSY0kpD0siAHA9MyCPi7ZAyL6KyJ6i4ie8Y79ARF9j4ieJqJ/JqJ579wDRHSGiJ4noo+Mq+MVKlS4OjgIJ/A3AP4UwN95x54A8IDWekBEDwF4AMDvENGtAO4DcBuAawF8lYhu1tpq4aYKs/ryqi96KijMBULJDGVKKUfG7U7CrPB+vviwlEY4JmVNijWm7DteUlP5rbiMdj0Fob8t+odrY6NQerW/BABoRj28Uj8OADg3b/QG71xsYKtpyKGYEpONAMxM2GpHyZaT9UVfEDGlVmlsU475pcmt3C+U3PPTt1yBLU0eOEWjuPVynACiCAFTfWKuJgwIdGzOHON758tt64/fOcGcDhcc7S6Sld3FMUcHnuu2vMdUgepm7KPUUOCQ8/43aj0cqzlKDgBJkFtzboOj/AY6tNsJK1qWE+P3H5C2HJrocU4l65gLjHPQ8dC0W+bYlDnSmAvYaYnnUkzh1HIG7IeD1CL8TyK6vnTs373dbwD4Od7+GQBf0Fr3ALxMRGcA/DCA/7oqvX2X8Fku+eRyDhqpU4KUJ0ObmykomwG2nP9tL4WOvFy1bzGJYeuA8twPM22+4I42isQLiSnovNWM8dqcWQReWzJejd/ZOoXN02YReHHdLBbbOzXk6+aLuchBTo03hM2P0TrHIkjHtEk2MuRNPi8u+GFoi4hImKstVQa4BUKCi+LIxiRYMUL2awkCtu3rllkMNBH6y2ZbfPE7K7H90DurotzjbFBtBZ1y5mG2yYdRjpQ/8FbdfJiNOMNizbDwq3UzfiusrF2Kt9BkD1ERv5pBzxY6kTiSXAdIpEwdn5PfASb2xFzDnGsHuX2jDUllDiEGkacEHP7wD4MYILgaPfkFAP/G2ycBvOadO8vHhkBEv0xETxHRU2sXDgWjUKHCTOKKFINE9CBMIq5HLve3WuuHATwMAHfeXtuPfI4FhZV4KLtG4FUOvzz27fLbO+4g4sgy4UwWvC7enlwAAGTaeJ91jz2LDnMrG6fNa3yhfw3O9FYAAM9unwAAvLRpuITzF9rYXTWcQ7TN/g0b7vXXLrCo0E1Ru8AKO/GoY8oeRgFUan4T7rBHXT22ocOqzmZJ3s+bia2D0G9zdF4SoDdvfiv2/GyO0FkVLzxm5efMNVrNLhYbhsVeqhuW+3i6gxvrb5sxigz1/4H4AlZDQ/lX2D+jJh6jFHkKOTeoo96VcHKjObuo1FbZ6wlHd6nrHyYOQPCuFwEi+hSAjwL4sLb5n3EOwGmv2Sk+VqFChUOKd7UIENE9AH4bwAe1ZkHW4DEAnyeiz8AoBm8C8N9X3MsJY1rKm/30CUJhUnJKpjk+t8SKzRujt/DButEjZO1vAQA2Tpj2a6qBJzvvAwC8umu4g29fOGnLsb11xugcQED9DcMxiCKueU4ccupovmGO7S41TX/e0egtcBq3TY6pWDT7UQfot/myLPH1lpRLgrJk4gqSdICTbSPHi+/9zS3D8azEF3GauaDV0JhwF8Mu5phbisX8RgFi5qpCKU1+Cao8CuV2+/3O5+Jke3+d0OHEJRcBInoUwIcALBHRWQC/C2MNSAE8wUqgb2itf0Vr/SwRfRHAczBiwq8dFsvAfiizaPnI5Hvjx34T7iCTK0CAhjwLX0qUndehj9sTY+XN2ub5uisaWxz49NItRuH4Um8FZ/vGY/HcrrH8ru0aX9r13Yat/kt9w/qntR4Ub7dYAx9xIE877aLP6ZIWUnadDQe4pWXCuReZlb8uWcOxwCwI17Lrds36WJD9lK3LLZznnc/mHybNu9+XwygC+DiIdeDjIw5/bp/2nwbw6SvpVIUKFSaHmfMYPAj8lVu4Ajl2eLgEj9XdhwD6Jkjhw2tsv54DsMJ2//fHhiqj/tL+1xgDcq09U2wydL5slg1Al1DgXR78d3ul7/m9xAEI3hu9rFChwtgwc5zAu13hp8EBjKJuo6iy79iUl/34RyDT4hATIEdRZTOqOObVjHjzzWr2+jT8XP5zZOzJeal+7FXY81K/U57aSl2hCsvnBPabM6O4j3Eg1+qSXFLFCVSoMOM4MpzAQSn1QWXHsvOHvz8uGbl8r1HYj+pnHhXLeDzE9TfTyua4z3gMUtJQkjqc2/WUtlr4vJQjP4cubMu5Ue32OpdpZe+lvP4f5Bqxl6SznK8/QGCfX9J52/Hxqv74Y3y5HM7B3vvBrl/gOK6QyxzFScj3MEBemBej8J5eBHKt0NOcx49ffE9ndvAzZnX9CSgTvGsnTGA/GDnnt+vxudTbT0ecG9UuLn10/v6oc10tteulj25/x26b33WVdtvamdPEi7DB5zZy8YEnrPFcaLJfweuDwIZRb3ImjpRyrHNp3Xn2m7+garzfxXpu/P4lYcaGquE4B9FIu2UOw15Tdbu9zsFRi0EXaxyC7c7VbODNBvfjON97R4dY5GCedc5cNB+4Z27YMRjY8dhSEsLL46iU3XYL4Oh3Nurd7nduVDvZHzWvajxP/XN2kWNfA5m3JuB8mBiVF7liUVPTblvJ+Cm8KskR90AlDlSoMOMgfQBF0tg7QbQGYAfA29PuC4AlVP3wUfWjiPdyP67TWi+XDx6KRQAAiOgprfWdVT+qflT9mGw/KnGgQoUZR7UIVKgw4zhMi8DD0+4Ao+pHEVU/ijhy/Tg0OoEKFSpMB4eJE6hQocIUUC0CFSrMOA7FIkBE93CdgjNEdP+E7nmaiL5ORM8R0bNE9Ot8fJGIniCiF/j/woT6ExLRt4jocd6/gYie5DH5ByIajrG9+n2YJ6IvcU2J7xLR3dMYDyL6TX4nzxDRo0RUm9R47FFnY+QYkMGfcJ+eJqI7xtyP8dT70FpP9Q8mD/eLAG6ECSb/XwC3TuC+JwDcwdtzAL4P4FYAvw/gfj5+P4CHJjQOvwXg8wAe5/0vAriPtz8L4Fcn0Ie/BfBLvJ0AmJ/0eMBkp34ZQN0bh09NajwA/BiAOwA84x0bOQYA7oXJtE0A7gLw5Jj78VMAIt5+yOvHrfzdpABu4O8pPPC9xj2xDvCwdwP4irf/AExhk0n3418B/CSA5wGc4GMnADw/gXufAvA1AD8O4HGeVG97L7wwRmPqQ5s/Piodn+h4wKWtX4SJbXkcwEcmOR4Ari99fCPHAMBfAPj4qHbj6Efp3M8CeIS3C98MgK8AuPug9zkM4sCBaxWMC1xc5QMAngSworV+g0+dB7AygS78EUziVgknOw5gQ2uOjprMmNwAYA3AX7NY8pdE1MSEx0NrfQ7AHwL4PwBvwBSI/CYmPx4+9hqDac7dd1XvYxQOwyIwVRBRC8A/AfgNrXWhvrg2y+pYbahE9FEAb2mtvznO+xwAEQz7+eda6w/AxHIU9DMTGo8FmEpWN8BkrG4CuGec97wcTGIMLoUrqfcxCodhEZharQIiimEWgEe01l/mw28S0Qk+fwLAW2Puxo8A+BgRvQLgCzAiwR8DmCciCfWexJicBXBWa/0k738JZlGY9Hj8BICXtdZrWusMwJdhxmjS4+FjrzGY+Nz16n18ghekK+7HYVgE/gfATaz9TWAKmj427puSyZX+OQDf1Vp/xjv1GIBP8vYnYXQFY4PW+gGt9Smt9fUwz/4fWutPAPg6XI3HSfTjPIDXiOgWPvRhmNTxEx0PGDHgLiJq8DuSfkx0PErYawweA/DzbCW4C8CmJzZcdXj1Pj6mh+t93EdEKRHdgMut9zFOJc9lKEDuhdHOvwjgwQnd80dh2LqnAXyb/+6Fkce/BuAFAF8FsDjBcfgQnHXgRn6RZwD8I4B0Avf/IQBP8Zj8C4CFaYwHgN8D8D0AzwD4exit90TGA8CjMLqIDIY7+sW9xgBGgftnPG+/A+DOMffjDIzsL/P1s177B7kfzwP46cu5V+U2XKHCjOMwiAMVKlSYIqpFoEKFGUe1CFSoMOOoFoEKFWYc1SJQocKMo1oEKlSYcVSLQIUKM47/B1TBJ4Ib5PmUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(g_items['masks'][2][0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 6\n",
    "show_images([testAx,testBy,g_items['By_warpped'].numpy(),\n",
    "             g_items['masks'][2][:,:,:,0],\n",
    "             g_items['raw_fake_Ay'].numpy(),g_items['fake_Ay'].numpy(),\n",
    "             g_items['fakeAy_to_Ax'],g_items['fakeBx_to_By'],g_items['fake_Bx']],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "  print(g_items['fakeAy_to_Ax'][0,:,:,i].numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(75, 75))\n",
    "gs = matplotlib.gridspec.GridSpec(1, 4, width_ratios=[1, 1, 1, 1],\n",
    "        wspace=0.0, hspace=0.0, top=0.95, bottom=0.05, left=0.1, right=0.2)\n",
    "img_idx = 6\n",
    "imgs = [testAx[img_idx],testBy[img_idx],g_items['fakeBx_to_By'][img_idx],g_items['masks'][1][img_idx,:,:,0]]\n",
    "for idx,img in enumerate(imgs):\n",
    "    ax = plt.subplot(gs[0,idx])\n",
    "    ax.axis('off')\n",
    "    ax.imshow(np.clip((img+1)/2,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target_flow = (testByMark[img_idx]-testAxMark[img_idx])\n",
    "draw_landmark_face(testAx[img_idx],testAxMark[img_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_landmark_face(testBy[img_idx],testByMark[img_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_landmark_face(testAx[img_idx],-test_sampled_flow[img_idx][0]+tf.cast(testByMark[0],'float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target_flow = (testByMark[img_idx]-testAxMark[img_idx])\n",
    "draw_landmark_face(testAx[img_idx],testAxMark[img_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_landmark_face(testBy[img_idx],testByMark[img_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_landmark_face(testAx[img_idx],-test_sampled_flow[img_idx][0]+tf.cast(testByMark[0],'float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_landmark_face(testAx[img_idx],testAxMark[img_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target_flow = (testByMark[img_idx]-testAxMark[img_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(75, 75))\n",
    "gs = matplotlib.gridspec.GridSpec(1, 4, width_ratios=[1, 1, 1, 1],\n",
    "        wspace=0.0, hspace=0.0, top=0.95, bottom=0.05, left=0.1, right=0.2)\n",
    "img_idx = 9\n",
    "imgs = [testAx[img_idx],testBy[img_idx],test_By_warpped[img_idx],test_raw_Ay[img_idx]]\n",
    "for idx,img in enumerate(imgs):\n",
    "    ax = plt.subplot(gs[0,idx])\n",
    "    ax.imshow(np.clip((img+1)/2,0,1))\n",
    "plt.savefig('test_img.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_landmark_face(testBy[img_idx],testByMark[img_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_landmark_face(testAx[img_idx],-test_sampled_flow[img_idx][0]+tf.cast(testByMark[0],'float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(Ax,By,Ay,epoch,batch_size):\n",
    "    fig = plt.figure(figsize=(75, 75)) \n",
    "    gs = matplotlib.gridspec.GridSpec(batch_size, 3, width_ratios=[1, 1, 1],\n",
    "         wspace=0.0, hspace=0.0, top=0.95, bottom=0.05, left=0.1, right=0.2)\n",
    "    Ax = np.clip(Ax+1,0,1)\n",
    "    By = np.clip(By+1,0,1)\n",
    "    Ay = np.clip(Ay.numpy()+1,0,1)\n",
    "    for i in range(batch_size):\n",
    "        ax1=plt.subplot(gs[i,0])\n",
    "        ax1.axis('off')\n",
    "        ax2=plt.subplot(gs[i,1])\n",
    "        ax2.axis('off')\n",
    "        ax3=plt.subplot(gs[i,2])\n",
    "        ax3.axis('off')\n",
    "        ax1.imshow(Ax[i])\n",
    "        ax2.imshow(By[i])\n",
    "        ax3.imshow(Ay[i])\n",
    "    plt.savefig('image4_at_epoch_{}.png'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(101,1000+1):\n",
    "    print(\"epoch: {}\".format(epoch))\n",
    "    for (one_Ax, one_Ax_landmark), (one_By, one_By_landmark) in zip(Ax_ds, By_ds):\n",
    "        train_items = train_flowNet_step(one_Ax,one_By,one_Ax_landmark,one_By_landmark,tf.cast(epoch,'float32'))\n",
    "        for (idx, itemname) in enumerate(lossnames):\n",
    "            metrics_list[idx](train_items[itemname])\n",
    "    with train_summary_writer.as_default():\n",
    "        for (idx, itemname) in enumerate(lossnames):\n",
    "            tf.summary.scalar(itemname, metrics_list[idx].result(), step=epoch)\n",
    "            metrics_list[idx].reset_states()\n",
    "    if epoch % 10 == 0:\n",
    "        for (one_Ax, one_Ax_landmark), (one_By, one_By_landmark) in zip(Ax_ds, By_ds):\n",
    "            g_items = generator(one_Ax,one_By,tf.cast(epoch,'float32'),False)\n",
    "            save_images(one_Ax,one_By,g_items['fake_Ay'],epoch,BATCH_SIZE)\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
